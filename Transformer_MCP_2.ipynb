{"cells":[{"cell_type":"markdown","metadata":{"id":"XTFwKMVqqQhf"},"source":["# BERT- Base"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40012,"status":"ok","timestamp":1661611362761,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"l_90dF7zVODF","outputId":"05ef89a0-3e7a-4713-ed60-1b62800e9f7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["['set_1',\n"," 'checkpoint_epoch_10.pt',\n"," 'loss_epoch_10.png',\n"," 'epoch_10_test.png',\n"," 'checkpoint_epoch_20.pt',\n"," 'loss_epoch_20.png',\n"," 'epoch_20_test.png',\n"," 'checkpoint_epoch_30.pt',\n"," 'loss_epoch_30.png',\n"," 'epoch_30_test.png',\n"," 'checkpoint_epoch_40.pt',\n"," 'loss_epoch_40.png',\n"," 'epoch_40_test.png',\n"," 'checkpoint_epoch_50.pt',\n"," 'loss_epoch_50.png',\n"," 'epoch_50_test.png',\n"," 'checkpoint_epoch_60.pt',\n"," 'loss_epoch_60.png',\n"," 'epoch_60_test.png',\n"," 'checkpoint_epoch_70.pt',\n"," 'loss_epoch_70.png',\n"," 'epoch_70_test.png',\n"," 'checkpoint_epoch_80.pt',\n"," 'loss_epoch_80.png',\n"," 'epoch_80_test.png',\n"," 'checkpoint_epoch_90.pt',\n"," 'loss_epoch_90.png',\n"," 'epoch_90_test.png',\n"," 'bert_val_targets.npy',\n"," 'bert_val_predictions.npy',\n"," 'bert_val_outputs.npy']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","\n","os.chdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base\")\n","os.listdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1661611381788,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"HLFZXmG_AifW","outputId":"0de0b2e1-ba33-405e-af87-4e93866b1233"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Aug 27 14:42:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 产看配置\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":972},"executionInfo":{"elapsed":22558,"status":"ok","timestamp":1661611404880,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"Leh152PAoAif","outputId":"7ea5e2e2-d9d7-4cb9-e69f-88594b89c208"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 33.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Collecting matplotlib\n","  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 4.0 MB/s \n","\u001b[?25hCollecting fonttools>=4.22.0\n","  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n","\u001b[K     |████████████████████████████████| 957 kB 62.6 MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n","Installing collected packages: fonttools, matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","Successfully installed fonttools-4.37.1 matplotlib-3.5.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{}}],"source":["! pip install transformers\n","! pip install -U matplotlib"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1958,"status":"ok","timestamp":1661611414161,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"aRxtGZEXVS06"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","#from d2l import torch as d2l\n","import transformers\n","from transformers import BertTokenizer\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","import pandas as pd\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc,roc_auc_score,f1_score,precision_score,recall_score\n","from sklearn.metrics import precision_recall_curve,average_precision_score,PrecisionRecallDisplay\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6697,"status":"ok","timestamp":1661611421359,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"1pA-D2B2VS6Z","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["424ffc1f80e94a88be61f3d667a8d02e","2b887c8a69ca456497ab421bae486e3b","6145b92afee446e083d40e6a053b7c88","4c67347dc97c4ec798dcdce32529bef0","751ea7c830ea4a089b95f7946f3e3e3e","71ea0a8ae81247b3b8b25b2c41a3296f","4d989676942247c98f839dd40daaa859","da2c9a6c2a584a4db2455709a0cfb7bb","2e74b0c7611242288f4bd6b080f74584","1b5be213fb2b4cc2b557d0a222593d9a","9c88d901fed248d0aa007ab3aa9bcad4","5f933294cf514ab0ab95421d22326555","2008b19b6d124fab9a5a8722ec5ea33f","2685f30dd81d4f7587f3da32c3e0318b","fcbcd3269cf7413691cfe53c816afe18","fb5afa189f684cdb81e70251523127e8","d5d6b7dc358342558e87fcf7e221967e","c803d9f7651847bb8e88e950942c1109","ca55fc37e47b47f792e824749c58f5e6","45fbbb85dfcc45d2b9f422348db4d72b","300ec0a3cec743af8a1d3c7c86abe3f9","8ff6a1dc20e34538abbacd2439e7cced","da4c62ddc6124b5ea8519d2a0fca4378","e5d34f84b6bb4155ab982e8d7a89fa93","b35e85a8c28d472f8f6dd719706515ae","b3dbe711e6404a29b585e44a1864cdce","89d2038822c6491897cd67551e251e97","0a93b292b34d4faab78cca89883ce017","9025f30f6e4d4069a33d8712d3777270","2170bf42d8344d05bfccf344d6e224d8","07aa937dea15426998d0ccb18321dcdf","b0ca47bb50ec4d6dafaa042d706e4ced","12374cf67ff741a39551e84702651ec5"]},"outputId":"21d75698-d1ad-4b6b-f46a-bca8fa33ca19"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424ffc1f80e94a88be61f3d667a8d02e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f933294cf514ab0ab95421d22326555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da4c62ddc6124b5ea8519d2a0fca4378"}},"metadata":{}}],"source":["# Sections of config\n","# Defining some key variables that will be used later on in the training\n","\n","MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 32\n","EPOCHS = 16\n","LEARNING_RATE = 1e-04\n","batch_size = 4\n","start_epochs = 1\n","n_epochs = 16\n","valid_loss_min_input = np.Inf\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtqVBQqsWS0Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HDuQ7GejWTWB"},"source":["# utils"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1661611421841,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"LgWs7rwqAv5x"},"outputs":[],"source":["# 自制数据集\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.title = dataframe['text']\n","        self.targets = dataframe['labels']\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","\n","        ids = inputs['input_ids']  # 将 input 中的词 encode,把一句话变为一个一维的tensor, 向量长度为max-length, 如果文本过段，用0填充。\n","        mask = inputs['attention_mask']  # 用于 truncation\n","        token_type_ids = inputs[\"token_type_ids\"]  # 第几句\n","        #print('target in dataset class',targets)\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),  # 数据 text ，经过encoder后的结果\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1661611421844,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"AwrU9w1wAx44"},"outputs":[],"source":["# 加载模型\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into       \n","    optimizer: optimizer we defined in previous training\n","\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss \n","    return model, optimizer, checkpoint['epoch'], valid_loss_min\n","# 保存模型\n","def save_ckp(state, checkpoint_path):\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n"]},{"cell_type":"markdown","metadata":{"id":"xHRtjpxUafBT"},"source":["# Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11528,"status":"ok","timestamp":1661611435724,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"oX5JFWPTVS30"},"outputs":[],"source":["#################################### prepare data ###############################\n","# load raw data\n","train_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/train_50.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/test_50.csv')\n","val_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/dev_50.csv')\n","\n","# 首先收集所有的 top 50 的标签，做成列表\n","top_50_list = []\n","top_50_code = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv',header=None)\n","idx2code = {0: '038.9', 1: '244.9', 2: '250.00', 3: '272.0', 4: '272.4', 5: '276.1', 6: '276.2', 7: '285.1', 8: '285.9', 9: '287.5', 10: '305.1', 11: '311', 12: '33.24', 13: '36.15', 14: '37.22', 15: '37.23', 16: '38.91', 17: '38.93', 18: '39.61', 19: '39.95', 20: '401.9', \n","            21: '403.90', 22: '410.71', 23: '412', 24: '414.01', 25: '424.0', 26: '427.31', 27: '428.0', 28: '45.13', 29: '486', 30: '496', 31: '507.0', 32: '511.9', 33: '518.81', 34: '530.81', 35: '584.9', 36: '585.9', 37: '599.0', 38: '88.56', 39: '88.72', 40: '96.04', \n","            41: '96.6', 42: '96.71', 43: '96.72', 44: '99.04', 45: '99.15', 46: '995.92', 47: 'V15.82', 48: 'V45.81', 49: 'V58.61'}\n","for index in range(len(top_50_code[0])):\n","  #raw_info = top_50_code.iloc[index]\n","  #top_50_list.append(raw_info[0])\n","  top_50_list.append(idx2code[index])\n","\n","# 讲一条病人的数据，转化为向量\n","def data_2_label(data_text,top_50_list):\n","  label = []\n","  labels = data_text.split(';')\n","  for element in top_50_list:\n","    if element in labels:\n","      label.append(1)\n","    else:\n","      label.append(0)\n","  return label\n","\n","# 制作训练集\n","train_data_list = []\n","for index in range(len(train_data['LABELS'])):\n","  row_info = train_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  train_data_list.append([text,labels])\n","  \n","train_data_df = pd.DataFrame(train_data_list)\n","train_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作验证集\n","val_data_list = []\n","for index in range(len(val_data['LABELS'])):\n","  row_info = val_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  val_data_list.append([text,labels])\n","  \n","val_data_df = pd.DataFrame(val_data_list)\n","val_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作测试集\n","test_data_list = []\n","for index in range(len(test_data['LABELS'])):\n","  row_info = test_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  test_data_list.append([text,labels])\n","  \n","test_data_df = pd.DataFrame(test_data_list)\n","test_data_df.columns = [\"text\", \"labels\"]\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6670,"status":"ok","timestamp":1661611442368,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"ccgNrePc0cxq","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8dc859d6c9a64006a8e9f8d9f4e69618","6974e86e47974224a8fa7f546dd89044","991573bb732c4c04afc37663eedb285c","78722a02ae334b6cb345676661f11538","308157c7b1d040018ff899db34ec63d6","fbf19793168a4df385804beb23c6ce90","1a571bbf282547cd9b68a6f72b56d199","6fcf4821ca66429f8027ad548e49e9fc","7bebc08c412c4268b30b81789ed059d1","11d02a35034c4c3b81fcbc260f75c5e6","e910846a97cf4fa08875249475b162d4"]},"outputId":"cbf84791-5cc9-4094-a735-51e0b586f111"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/455k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dc859d6c9a64006a8e9f8d9f4e69618"}},"metadata":{}}],"source":["#数据集的参数\n","# tokenizer = BertTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","MAX_LEN = 512\n","batch_size = 16\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","# 准备数据集 \n","training_set = CustomDataset(train_data_df, tokenizer, MAX_LEN)\n","val_set = CustomDataset(val_data_df, tokenizer, MAX_LEN)\n","test_set = CustomDataset(test_data_df, tokenizer, MAX_LEN)\n","\n","# 把数据集做成 batch_size 的形式\n","train_iter = torch.utils.data.DataLoader(training_set, batch_size, shuffle=True)\n","val_iter = torch.utils.data.DataLoader(val_set, batch_size)\n","test_iter = torch.utils.data.DataLoader(test_set, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMjMEnPHZd73"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"frN_kPQrZd_i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LHteow7HaiZx"},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661611443763,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"nldYQZrEVT96"},"outputs":[],"source":["# 微调 BERT\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l2 = torch.nn.Dropout(0.2)\n","        self.l3 = torch.nn.Linear(768, 50)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        output_all = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        output_2 = self.l2( output_all[1] )\n","        output = self.l3(output_2)\n","        return self.sigmoid(output)     # 返回sigmoid激活的函数\n","        "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["983fef2602d048b19606fb2e69090c8e","8a32063b385a4eb5b863b0004e7580c9","ba96d2cc0f844e329686f919473a3760","0960ede8e62c47fab64b8b96e9e23357","9c1bfa8e9ddf4a9680eec25ab51c4e8a","08f7b2d1f6f54af1b3be52a27bc6268e","8aa3d225a67b435b944a26881556f620","2fff98c576a446d195f198ae6b496565","14bf2df747294294a296919316761f67","c72ae92f9c964f3dba07b977b7e7a70b","e0b68676ff6d49038e770df43585d424"]},"executionInfo":{"elapsed":22467,"status":"ok","timestamp":1661611468375,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"I4oFCaZRt0YA","outputId":"4fb98cfd-9e1e-4fcf-ff76-7201a7c0bde8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983fef2602d048b19606fb2e69090c8e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.2, inplace=False)\n","  (l3): Linear(in_features=768, out_features=50, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":11}],"source":["model = BERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgKEInRCBfuV"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6T2xIMeaBhjd"},"source":["# 优化器"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1661611470799,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"axZBo02UBjUG"},"outputs":[],"source":["import math\n","import torch\n","from torch.optim import Optimizer\n","from torch.optim.optimizer import required\n","from torch.nn.utils import clip_grad_norm_\n","import logging\n","import abc\n","import sys\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","if sys.version_info >= (3, 4):\n","    ABC = abc.ABC\n","else:\n","    ABC = abc.ABCMeta('ABC', (), {})\n","\n","\n","class _LRSchedule(ABC):\n","    \"\"\" Parent of all LRSchedules here. \"\"\"\n","    warn_t_total = False        # is set to True for schedules where progressing beyond t_total steps doesn't make sense\n","    def __init__(self, warmup=0.002, t_total=-1, **kw):\n","        \"\"\"\n","        :param warmup:  what fraction of t_total steps will be used for linear warmup\n","        :param t_total: how many training steps (updates) are planned\n","        :param kw:\n","        \"\"\"\n","        super(_LRSchedule, self).__init__(**kw)\n","        if t_total < 0:\n","            logger.warning(\"t_total value of {} results in schedule not being applied\".format(t_total))\n","        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n","            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n","        warmup = max(warmup, 0.)\n","        self.warmup, self.t_total = float(warmup), float(t_total)\n","        self.warned_for_t_total_at_progress = -1\n","\n","    def get_lr(self, step, nowarn=False):\n","        \"\"\"\n","        :param step:    which of t_total steps we're on\n","        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n","        :return:        learning rate multiplier for current update\n","        \"\"\"\n","        if self.t_total < 0:\n","            return 1.\n","        progress = float(step) / self.t_total\n","        ret = self.get_lr_(progress)\n","        # warning for exceeding t_total (only active with warmup_linear\n","        if not nowarn and self.warn_t_total and progress > 1. and progress > self.warned_for_t_total_at_progress:\n","            logger.warning(\n","                \"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"\n","                    .format(ret, self.__class__.__name__))\n","            self.warned_for_t_total_at_progress = progress\n","        # end warning\n","        return ret\n","\n","    def get_lr_(self, progress):\n","        \"\"\"\n","        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n","        :return:            learning rate multiplier for current update\n","        \"\"\"\n","        return 1.\n","\n","\n","class ConstantLR(_LRSchedule):\n","    def get_lr_(self, progress):\n","        return 1.\n","\n","\n","class WarmupCosineSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Decreases learning rate from 1. to 0. over remaining `1 - warmup` steps following a cosine curve.\n","    If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n","    \"\"\"\n","    warn_t_total = True\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=.5, **kw):\n","        \"\"\"\n","        :param warmup:      see LRSchedule\n","        :param t_total:     see LRSchedule\n","        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n","        :param kw:\n","        \"\"\"\n","        super(WarmupCosineSchedule, self).__init__(warmup=warmup, t_total=t_total, **kw)\n","        self.cycles = cycles\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)   # progress after warmup\n","            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))\n","\n","\n","class WarmupCosineWithHardRestartsSchedule(WarmupCosineSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n","    learning rate (with hard restarts).\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        super(WarmupCosineWithHardRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","        assert(cycles >= 1.)\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * ((self.cycles * progress) % 1)))\n","            return ret\n","\n","\n","class WarmupCosineWithWarmupRestartsSchedule(WarmupCosineWithHardRestartsSchedule):\n","    \"\"\"\n","    All training progress is divided in `cycles` (default=1.) parts of equal length.\n","    Every part follows a schedule with the first `warmup` fraction of the training steps linearly increasing from 0. to 1.,\n","    followed by a learning rate decreasing from 1. to 0. following a cosine curve.\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        assert(warmup * cycles < 1.)\n","        warmup = warmup * cycles if warmup >= 0 else warmup\n","        super(WarmupCosineWithWarmupRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","\n","    def get_lr_(self, progress):\n","        progress = progress * self.cycles % 1.\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * progress))\n","            return ret\n","\n","\n","class WarmupConstantSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Keeps learning rate equal to 1. after warmup.\n","    \"\"\"\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return 1.\n","\n","\n","class WarmupLinearSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Linearly decreases learning rate from 1. to 0. over remaining `1 - warmup` steps.\n","    \"\"\"\n","    warn_t_total = True\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return max((progress - 1.) / (self.warmup - 1.), 0.)\n","\n","\n","SCHEDULES = {\n","    None:       ConstantLR,\n","    \"none\":     ConstantLR,\n","    \"warmup_cosine\": WarmupCosineSchedule,\n","    \"warmup_constant\": WarmupConstantSchedule,\n","    \"warmup_linear\": WarmupLinearSchedule\n","}\n","\n","\n","class BertAdam(Optimizer):\n","    \"\"\"Implements BERT version of Adam algorithm with weight decay fix.\n","    Params:\n","        lr: learning rate\n","        warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n","        t_total: total number of training steps for the learning\n","            rate schedule, -1  means constant learning rate of 1. (no warmup regardless of warmup setting). Default: -1\n","        schedule: schedule to use for the warmup (see above).\n","            Can be `'warmup_linear'`, `'warmup_constant'`, `'warmup_cosine'`, `'none'`, `None` or a `_LRSchedule` object (see below).\n","            If `None` or `'none'`, learning rate is always kept constant.\n","            Default : `'warmup_linear'`\n","        b1: Adams b1. Default: 0.9\n","        b2: Adams b2. Default: 0.999\n","        e: Adams epsilon. Default: 1e-6\n","        weight_decay: Weight decay. Default: 0.01\n","        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n","    \"\"\"\n","    def __init__(self, params, lr=required, warmup=-1, t_total=-1, schedule='warmup_linear',\n","                 b1=0.9, b2=0.999, e=1e-6, weight_decay=0.01, max_grad_norm=1.0, **kwargs):\n","        if lr is not required and lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n","        if not isinstance(schedule, _LRSchedule) and schedule not in SCHEDULES:\n","            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n","        if not 0.0 <= b1 < 1.0:\n","            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n","        if not 0.0 <= b2 < 1.0:\n","            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n","        if not e >= 0.0:\n","            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n","        # initialize schedule object\n","        if not isinstance(schedule, _LRSchedule):\n","            schedule_type = SCHEDULES[schedule]\n","            schedule = schedule_type(warmup=warmup, t_total=t_total)\n","        else:\n","            if warmup != -1 or t_total != -1:\n","                logger.warning(\"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"\n","                               \"Please specify custom warmup and t_total in _LRSchedule object.\")\n","        defaults = dict(lr=lr, schedule=schedule,\n","                        b1=b1, b2=b2, e=e, weight_decay=weight_decay,\n","                        max_grad_norm=max_grad_norm)\n","        super(BertAdam, self).__init__(params, defaults)\n","\n","    def get_lr(self):\n","        lr = []\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    return [0]\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","                lr.append(lr_scheduled)\n","        return lr\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['next_m'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['next_v'] = torch.zeros_like(p.data)\n","\n","                next_m, next_v = state['next_m'], state['next_v']\n","                beta1, beta2 = group['b1'], group['b2']\n","\n","                # Add grad clipping\n","                if group['max_grad_norm'] > 0:\n","                    clip_grad_norm_(p, group['max_grad_norm'])\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                next_m.mul_(beta1).add_(1 - beta1, grad)\n","                next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                update = next_m / (next_v.sqrt() + group['e'])\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want to decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                if group['weight_decay'] > 0.0:\n","                    update += group['weight_decay'] * p.data\n","\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","\n","                update_with_lr = lr_scheduled * update\n","                p.data.add_(-update_with_lr)\n","\n","                state['step'] += 1\n","\n","                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n","                # No bias correction\n","                # bias_correction1 = 1 - beta1 ** state['step']\n","                # bias_correction2 = 1 - beta2 ** state['step']\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"o4T6iMvZamO4"},"source":["# Train"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2465,"status":"ok","timestamp":1661611470797,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"vFCUoOdDjhGz"},"outputs":[],"source":["import sys\n","import numpy as np\n","sys.path.append(\"/content/drive/My Drive/MIMIC/caml-mimic\")  # 注意，这里改变了地址了\n","import evaluation"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1661611470801,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"DvH6qodsBr6D","outputId":"81df67c4-89c0-48fa-c794-d6f068aba05a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef get_f1_pre_re(y_target,y_output):\\n  # 计算 F1 ， precision , recall\\n  y_output = torch.tensor(y_output)\\n  ones = torch.ones_like(y_output)\\n  zeros = torch.zeros_like(y_output)\\n  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\\n  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\\n  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\\n  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\\n  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\\n  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\\n  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\\n  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\\n  print()\\n  print('The evluation from other code:')\\n  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\\n  print(evaluation.print_metrics(metrics))\\n  \\n  'acc_macro','prec_macro','rec_macro','f1_macro'\\n  'acc_micro','prec_micro','rec_micro','f1_micro',\\n  'rec_at_5','prec_at_5', 'f1_at_5' , \\n  'auc_macro','auc_micro'\\n  \\n  return metrics\\n\\n\\ndef epoch_perform(targets,outputs,name):\\n  performence = get_f1_pre_re(targets,outputs)\\n  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\\n  performence['auc'] = roc_auc\\n  performence['fpr'] = fpr\\n  performence['tpr'] = tpr\\n  print()\\n  print(name+' performence:')\\n  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\\n  print('precision(micro):',performence['precision micro'],\\n        '\\tprecison(macro):',performence['precision macro'],\\n        '\\trecall(micro):',performence['recall micro'],\\n        '\\trecall(macro):',performence['recall macro'],\\n        '\\tf_1 (micro):',performence['f1 micro'],\\n        '\\tf_1 (macro):',performence['f1 macro'])\\n  return performence\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["def get_roc_auc(val_targets,val_outputs):\n","  # input : val_targets 标签 ； val_outputs 模型的输出 (需要np.array类型)\n","  # output: return_fpr (micro,macro) , return_tpr (micro,macro) (list)\n","  # output: return_roc_auc (micro,macro)  (float)\n","  # Compute ROC curve and ROC area for each class\n","  n_classes = len(val_targets[0]) # [num_example,num_class] \n","  fpr = {}\n","  tpr = {}\n","  roc_auc = {}\n","  for i in range(n_classes):\n","    fpr_, tpr_, _ = roc_curve(val_targets[:, i], val_outputs[:, i])\n","    fpr[i] = fpr_.tolist()\n","    tpr[i] = tpr_.tolist()\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","  # Compute micro-average ROC curve and ROC area\n","  fpr_, tpr_, _ = roc_curve(val_targets.ravel(), val_outputs.ravel())\n","  fpr['micro'] = fpr_.tolist()\n","  tpr['micro'] = tpr_.tolist()\n","  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","  # Compute macro-average ROC curve and ROC area\n","  # First aggregate all false positive rates\n","  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","  # Then interpolate all ROC curves at this points\n","  mean_tpr = np.zeros_like(all_fpr)\n","  for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","  # Finally average it and compute AUC\n","  mean_tpr /= n_classes\n","  fpr[\"macro\"] = all_fpr.tolist()\n","  tpr[\"macro\"] = mean_tpr.tolist()\n","  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","  # 返回时，我们只需要micro,macro的信息即可\n","  return_fpr = {'macro':fpr['macro'],'micro':fpr['micro']}\n","  return_tpr = {'macro':tpr['macro'],'micro':tpr['micro']}\n","  return_roc_auc = {'macro':roc_auc['macro'],'micro':roc_auc['micro']}\n","  return return_fpr,return_tpr,return_roc_auc\n","\n","def epoch_perform(y_target,y_output):\n","  # 计算 prediction , 以 0.5 作为阈值\n","  # 输出 mretics\n","  '''\n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro','auc',\n","  'tpr','fpr',\n","  'prec_micro_curve','rec_micro,curve','ave_prec_micro'\n","  '''\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  y_output = y_output.cpu().detach().numpy()\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction.numpy(), y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  # 计算 tpr ,fpr, 用于画出 ROC_AUCROC_AUC\n","  fpr,tpr,roc_auc = get_roc_auc(y_target,y_output)\n","  metrics['auc'] = roc_auc\n","  metrics['fpr'] = fpr\n","  metrics['tpr'] = tpr\n","  print(metrics['auc'])\n","  print()\n","  # 计算 precision,recall ,用于画出 precision-recall curve\n","  precision ={}\n","  recall = {}\n","  average_precision = {}\n","  metrics['prec_micro_curve'], metrics['rec_micro,curve'], _ = precision_recall_curve(y_target.ravel(), y_output.ravel())\n","  metrics['ave_prec_micro'] = average_precision_score(y_target, y_output, average=\"micro\")\n","  return metrics\n","\n","'''\n","def get_f1_pre_re(y_target,y_output):\n","  # 计算 F1 ， precision , recall\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\n","  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\n","  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\n","  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\n","  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\n","  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\n","  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  \n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro'\n","  \n","  return metrics\n","\n","\n","def epoch_perform(targets,outputs,name):\n","  performence = get_f1_pre_re(targets,outputs)\n","  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\n","  performence['auc'] = roc_auc\n","  performence['fpr'] = fpr\n","  performence['tpr'] = tpr\n","  print()\n","  print(name+' performence:')\n","  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\n","  print('precision(micro):',performence['precision micro'],\n","        '\\tprecison(macro):',performence['precision macro'],\n","        '\\trecall(micro):',performence['recall micro'],\n","        '\\trecall(macro):',performence['recall macro'],\n","        '\\tf_1 (micro):',performence['f1 micro'],\n","        '\\tf_1 (macro):',performence['f1 macro'])\n","  return performence\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":619,"status":"ok","timestamp":1661611477856,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"hzIjxmYuBsCF"},"outputs":[],"source":["def draw_pr_roc(test_performence,\n","                y_target,y_output,\n","                save_path,epoch,name,\n","                key):\n","  # fpr, tpr,roc_auc 三个字典，是 get_roc_auc的输出\n","  # y_target 标签 ； y_output 模型的输出\n","  # save_path 保存图片的地址 ； epoch,name 记录是哪一次的信息\n","  # 输出： 两张图表，roc曲线 和 precision_recall曲线\n","  # 画图，首先是左边，roc_auc 曲线\n","  fig, axs = plt.subplots(1, 2, figsize=(21, 10))\n","  axs[0].step(\n","      test_performence['fpr'][\"micro\"],\n","      test_performence['tpr'][\"micro\"],\n","      label=\"micro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  axs[0].step(\n","      test_performence['fpr'][\"macro\"],\n","      test_performence['tpr'][\"macro\"],\n","      label=\"macro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"macro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,\n","    ) \n","  axs[0].plot([0, 1], [0, 1], \"k--\", lw=2)\n","  axs[0].set_xlim([0.0, 1.0])\n","  axs[0].set_ylim([0.0, 1.05])\n","  axs[0].set_xlabel(\"False Positive Rate\")\n","  axs[0].set_ylabel(\"True Positive Rate\")\n","  axs[0].set_title(\"Receiver Operating Characteristic to multiclass\")\n","\n","  # 然后是右边，precision_recall curve\n","  f_scores = np.linspace(0.2, 0.8, num=4)\n","  lines, labels = [], []\n","  for f_score in f_scores:\n","      x = np.linspace(0.01, 1)\n","      y = f_score * x / (2 * x - f_score)\n","      (l,) = axs[1].plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n","      axs[1].annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n","\n","  display = PrecisionRecallDisplay(\n","      recall=test_performence['rec_micro,curve'],\n","      precision=test_performence['prec_micro_curve'],\n","      average_precision = test_performence['prec_micro'],\n","  )\n","  display.plot(ax=axs[1], name=\"Micro-average precision-recall\", \n","               color=\"#f97306\",linewidth=2) \n","\n","  # add the legend for the iso-f1 curves\n","  handles, labels = display.ax_.get_legend_handles_labels()\n","  handles.extend([l])\n","  labels.extend([\"iso-f1 curves\"])\n","  # set the legend and the axes\n","  axs[1].set_xlim([0.0, 1.0])\n","  axs[1].set_ylim([0.0, 1.05])\n","  axs[1].legend(handles=handles, labels=labels, loc=\"best\")\n","  axs[1].set_title(\"Micro-averaged Prcision-Recall Line\")\n","\n","  for ax in axs:\n","    ax.legend(loc=\"lower right\")\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/epoch_'+str(epoch)+'_'+name+'.png')\n","\n","#draw_pr_roc(return_fpr,return_tpr,return_roc_auc,Y,y_score,\n","#            save_path='/content/drive/My Drive/MIMIC',epoch=1,name='val')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661611480768,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"6goOAvmEBwCo"},"outputs":[],"source":["def draw_loss(result_loss,save_path,key):\n","  fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n","  # 可视化 train_loss_batch\n","  x = np.arange(0,len(result_loss['train_loss_batch']),1)\n","  y = np.array(result_loss['train_loss_batch'])\n","  axs[0][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][0].set_xlim([0.0, 1.0])\n","  #axs[0][0].set_ylim([0.0, 1.05])\n","  axs[0][0].set_xlabel(\"epoch\")\n","  axs[0][0].set_ylabel(\"Loss\")\n","  axs[0][0].set_title(\"Train Loss per Batchs\")\n","  \n","  # 可视化 train_loss_epoch\n","  x = np.arange(0,len(result_loss['train_loss_epoch']),1)\n","  y = np.array(result_loss['train_loss_epoch'])\n","  print(x)\n","  print(y)\n","  axs[0][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][1].set_xlim([0.0, 1.0])\n","  #axs[0][1].set_ylim([0.0, 1.05])\n","  axs[0][1].set_xlabel(\"epoch\")\n","  axs[0][1].set_ylabel(\"Loss\")\n","  axs[0][1].set_title(\"Train Loss per Epoch\")\n","  \n","  # 可视化 test_loss_epoch\n","  x = np.arange(0,len(result_loss['test_loss_epoch']),1)\n","  y = np.array(result_loss['test_loss_epoch'])\n","  axs[0][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][0].set_xlim([0.0, 1.0])\n","  #axs[1][0].set_ylim([0.0, 1.05])\n","  axs[0][2].set_xlabel(\"epoch\")\n","  axs[0][2].set_ylabel(\"Loss\")\n","  axs[0][2].set_title(\"Test Loss per Epoch\")\n","  \n","  # 可视化 F 1\n","  x = np.arange(0,len(result_loss['test_macro_f1']),1)\n","  y = np.array(result_loss['test_macro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_f1']),1)\n","  y = np.array(result_loss['test_micro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][0].set_xlabel(\"epoch\")\n","  axs[1][0].set_ylabel(\"F 1 score\")\n","  axs[1][0].set_title(\"F 1 score per Epoch\")\n","  axs[1][0].legend()\n","\n","  # 可视化 Recall\n","  x = np.arange(0,len(result_loss['test_macro_recall']),1)\n","  y = np.array(result_loss['test_macro_recall'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Recall (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_recall']),1)\n","  y = np.array(result_loss['test_micro_recall'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      label = \"Recall (micro)\",\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][1].set_xlabel(\"epoch\")\n","  axs[1][1].set_ylabel(\"Recall score\")\n","  axs[1][1].set_title(\"Recall score per Epoch\")\n","  axs[1][1].legend()\n","  # 可视化 Precision\n","  x = np.arange(0,len(result_loss['test_macro_precision']),1)\n","  y = np.array(result_loss['test_macro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_precision']),1)\n","  y = np.array(result_loss['test_micro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][2].set_xlabel(\"epoch\")\n","  axs[1][2].set_ylabel(\"Precision score\")\n","  axs[1][2].set_title(\"Precision score per Epoch\")\n","  axs[1][2].legend()\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/loss_epoch_'+str(epoch)+'.png')\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":509,"status":"ok","timestamp":1661611485638,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"_QqBWWsRBwFP"},"outputs":[],"source":["# 设置参数\n","checkpoint_path = '/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base'\n","model_name = 'bert_base'\n","\n","LEARNING_RATE = 2e-05\n","\n","start_epochs = 1\n","n_epochs = 100\n","\n","# 损失函数\n","def loss_fn(outputs, targets):\n","    #return torch.nn.functional.cross_entropy(outputs, targets)\n","    return torch.nn.functional.binary_cross_entropy(outputs,targets)\n","\n","# 优化器，使用 warm up ,  AdmaW\n","# optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","# optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n","\n","#optimizer = BertAdam(optimizer_grouped_parameters,\n","#                      lr=LEARNING_RATE,\n","#                      warmup=0.05,\n","#                      t_total=len(train_iter) * n_epochs)\n","#sigmoid = torch.nn.Sigmoid()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"104v9W_4qBF0N9_6Zg9sLLePMaiy01taB"},"id":"vNKhv2asVV_q","outputId":"040f938d-9667-4147-94e0-819e5db94b0f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 正式开始训练\n","result_loss = {'train_loss_batch':[],'train_loss_epoch':[],'test_loss_epoch':[],\n","               'test_macro_f1':[],'test_macro_recall':[],'test_macro_precision':[],\n","               'test_micro_f1':[],'test_micro_recall':[],'test_micro_precision':[],\n","               'test_macro_auc':[],'test_micro_auc':[]}\n","\n","test_loss_min  = np.Inf  # 初始化最小的验证损失函数\n","for epoch in range(start_epochs, n_epochs+1):\n","  key = 0  # 用于提示合适保存图片\n","  test_targets = []\n","  test_outputs = []\n","  train_loss = 0\n","  test_loss = 0\n","\n","  ######################    \n","   # Train the model #\n","  ######################\n","  process_num = 0  \n","  model.train()\n","  print('###############   Epoch {}: Training Start   #############'.format(epoch))\n","  for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)  \n","\n","    optimizer.zero_grad()\n","    loss = loss_fn(outputs, targets)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","    # 记录信息\n","    process_num += batch_size\n","    if process_num % (64*20) == 0:  ############## 这里可以调\n","      print('already deal with '+ str(process_num)+' data','\\tloss:',loss.item())\n","      result_loss['train_loss_batch'].append(loss.item())\n","  train_loss = train_loss/len(train_iter)  # 计算平均训练损失\n","  result_loss['train_loss_epoch'].append(train_loss) # 放到记录字典里\n","  print('Epoch {}: Training End'.format(epoch))\n","\n","  ######################    \n","  # validate the model #\n","  ######################\n","  model.eval()\n","  with torch.no_grad():\n","    # 在 测试集上跑一遍\n","    for batch_idx, data in enumerate(test_iter, 0):\n","      ids = data['ids'].to(device, dtype = torch.long)\n","      mask = data['mask'].to(device, dtype = torch.long)\n","      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","      targets = data['targets'].to(device, dtype = torch.float)\n","\n","      outputs = model(ids, mask, token_type_ids)\n","\n","      loss = loss_fn(outputs, targets)\n","      test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.item() - test_loss))\n","      test_targets.extend(targets.cpu().detach().numpy())\n","      test_outputs.extend(outputs.cpu().detach().numpy())\n","    test_loss = test_loss / len(test_iter)\n","    result_loss['test_loss_epoch'].append(test_loss)\n","    print('Epoch {}: Validation End'.format(epoch))\n","    # 打印一下 三个损失函数 \n","    print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Test Loss: {:.6f}'.format(epoch, train_loss,test_loss))\n","\n","  #####################################\n","  ######### 记录结果, 保存模型  #########\n","  #####################################\n","  test_performence = epoch_perform(np.array(test_targets),np.array(test_outputs)) # 得到模型在test集合上的表现\n","  result_loss['test_macro_f1'].append(test_performence['f1_macro'])\n","  result_loss['test_micro_f1'].append(test_performence['f1_micro'])\n","  result_loss['test_macro_recall'].append(test_performence['rec_macro'])\n","  result_loss['test_micro_recall'].append(test_performence['rec_micro'])\n","  result_loss['test_macro_precision'].append(test_performence['prec_macro'])\n","  result_loss['test_micro_precision'].append(test_performence['prec_micro'])\n","  result_loss['test_macro_auc'].append(test_performence['auc_macro'])\n","  result_loss['test_micro_auc'].append(test_performence['auc_micro'])\n","  # 下面要保存模型\n","  checkpoint = {\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'test_outputs':np.array(test_outputs),\n","            'test_targets':np.array(test_targets),\n","            'loss':result_loss,\n","            'test_performence':test_performence}\n","  if epoch % 10 == 0 :  # 这里是真的要保存了  # 记着设置保存条件\n","    key = 1\n","    # 保存模型\n","    save_ckp(checkpoint, checkpoint_path+'/checkpoint_epoch_'+ str(epoch) + '.pt' )\n","    # 保存test , loss 字典\n","    #test_json = json.dumps(test_performence,sort_keys=False, indent=4, separators=(',', ': '))\n","    #loss_json = json.dumps(result_loss,sort_keys=False, indent=4, separators=(',', ': '))\n","    #f = open(checkpoint_path + '/test_performence_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(test_json)\n","    #f = open(checkpoint_path + '/loss_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(loss_json)\n","\n","  #####################################\n","  ######### 可视化，打印  #########\n","  #####################################\n","  print('Visulization:')\n","  print(\"Loss :\")\n","  print(result_loss)\n","  draw_loss(result_loss,checkpoint_path,key)\n","  print('test: ')\n","  draw_pr_roc(test_performence,\n","              np.array(test_targets),np.array(test_outputs),   # np 优化\n","              checkpoint_path,epoch,'test',\n","              key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzQ8A4wJdsHA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POTaYZql5wAi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35l06vIb5wDI"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_rWdAIecGBot"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8ZkvynoJuGE"},"outputs":[],"source":["! pip install matplotlib==3.1.3"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"CaJ274SmSK4K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661611511531,"user_tz":-480,"elapsed":8608,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"6d38c449-0436-42f2-a4f8-499a3653c8da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}],"source":["checkpoint_fpath = \"/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base/checkpoint_epoch_40.pt\"\n","\n","\n","#load_ckp(checkpoint_fpath, model, optimizer)\n","# load check point\n","checkpoint = torch.load(checkpoint_fpath)\n","#checkpoint['test_outputs'].shape\n","# initialize state_dict from checkpoint to model\n","model.load_state_dict(checkpoint['state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuaWkQ3FSLDm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661269229742,"user_tz":-480,"elapsed":24459,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"f7ec171f-514d-4bc7-ce12-8e209540bd37"},"outputs":[{"output_type":"stream","name":"stdout","text":["valid loss: 0.0037338580890962417\n"]}],"source":["valid_loss = 0\n","val_targets = []\n","val_outputs = []\n","with torch.no_grad():\n","  # 在 测试集上跑一遍\n","  for batch_idx, data in enumerate(val_iter, 0):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","\n","    loss = loss_fn(outputs, targets)\n","    #loss_list.append(loss)\n","    valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","    val_targets.extend( targets.cpu().detach().numpy())\n","    val_outputs.extend( outputs.cpu().detach().numpy()) \n","  valid_loss = valid_loss / len(val_iter)\n","  #result_loss['valid_loss_epoch'].append(valid_loss)\n","  print('valid loss:',valid_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-QRBpZ0SLGm"},"outputs":[],"source":["val_targets = np.array(val_targets)\n","val_outputs = np.array(val_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"haLvEAZ0Of4H"},"outputs":[],"source":["# 利用 output 做出 prediction\n","ones = torch.ones_like(torch.tensor(val_outputs))\n","zeros = torch.zeros_like(torch.tensor(val_outputs))\n","val_prediction = torch.where(torch.tensor(val_outputs) > 0.5 , ones , zeros)\n","val_prediction = np.array(val_prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_vBRVPaWLeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661269237167,"user_tz":-480,"elapsed":7,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"6af5eb0f-109e-47a5-b6fd-eb4f52273339"},"outputs":[{"output_type":"stream","name":"stdout","text":["AUC:\n","macro: 0.8077079449174234\n","micro: 0.8407779902414543\n","F1:\n","macro: 0.457374657907763\n","micro: 0.533236819881771\n"]}],"source":["from sklearn.metrics import roc_auc_score\n","\n","print('AUC:')\n","print('macro:',roc_auc_score(val_targets, val_outputs, average='macro'))\n","print('micro:',roc_auc_score(val_targets, val_outputs, average='micro'))\n","print('F1:')\n","print('macro:',f1_score(val_targets, val_prediction, average='macro'))\n","print('micro:',f1_score(val_targets, val_prediction, average='micro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_mKcaKuY8vFn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661269278448,"user_tz":-480,"elapsed":342,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"46a1f94b-baf3-4386-b333-4aa85704a1f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Finish save rediction by checkpoint\n"]}],"source":["# 保存模型在 valid dataset 上得到的结果\n","path = \"/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base/\"\n","with open(path + 'bert_val_targets.npy', 'wb') as f:  \n","  np.save(f, val_targets)\n","with open(path + 'bert_val_predictions.npy', 'wb') as f:  \n","  np.save(f, val_prediction)\n","with open(path + 'bert_val_outputs.npy', 'wb') as f:  \n","  np.save(f, val_outputs)\n","print('Finish save rediction by checkpoint')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOoVN0nKWpXX"},"outputs":[],"source":["from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","for i in range(0,50):\n","  print('label ',i)\n","  y_true = val_targets[:,i]\n","  y_pred = val_prediction[:,i]\n","\n","  # 混淆矩阵\n","  ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n","  plt.show()\n","  #print(confusion_matrix(y_true, y_pred))\n","\n","  # precision,recall,f1\n","  target_names = ['class 0', 'class 1']\n","  print('report:')\n","  print(classification_report(y_true, y_pred, target_names=target_names))\n","  print()\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1G6_vCfCSLMF"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Fixing random state for reproducibility\n","def scatter_hist(x, y, ax, ax_histx, ax_histy):\n","    # no labels\n","    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n","    ax_histy.tick_params(axis=\"y\", labelleft=False)\n","\n","    # the scatter plot:\n","    ax.scatter(x, y,c=\"#01ff07\",)\n","    ax_histx.hist(x, bins=25)\n","    ax_histy.hist(y, bins=10, orientation='horizontal')\n","\n","for i in range(0,50):\n","  # some random data\n","  #x = np.random.randn(1000)\n","  #y = np.random.randn(1000)\n","  print()\n","  print(\"Below is label \"+ str(i) )\n","  y = val_targets[:,i]\n","  x = val_outputs[:,i]\n","\n","  # definitions for the axes\n","  left, width = 0.1, 0.65\n","  bottom, height = 0.1, 0.65\n","  spacing = 0.005\n","\n","  rect_scatter = [left, bottom, width, height]\n","  rect_histx = [left, bottom + height + spacing, width, 0.2]\n","  rect_histy = [left + width + spacing, bottom, 0.2, height]\n","\n","  # start with a square Figure\n","  fig = plt.figure(figsize=(12, 12))\n","\n","  ax = fig.add_axes(rect_scatter)\n","  ax_histx = fig.add_axes(rect_histx, sharex=ax)\n","  ax_histy = fig.add_axes(rect_histy, sharey=ax)\n","\n","  # use the previously defined function\n","  scatter_hist(x, y, ax, ax_histx, ax_histy)\n","\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j91FMx36wOFM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eCn6lEtdKOdT"},"source":["# Find Suitable Evaluation "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyjWYMHqwORl"},"outputs":[],"source":["import sys\n","import numpy as np\n","sys.path.append(\"/content/drive/My Drive/MIMIC/caml-mimic\")  # 注意，这里改变了地址了\n","import evaluation\n","\n","yhat = np.load(\"/content/drive/My Drive/MIMIC/caml-mimic/predictions/CAML_mimic3_50/test_50_predictions.npy\")\n","y = np.load(\"/content/drive/My Drive/MIMIC/caml-mimic/predictions/CAML_mimic3_50/test_50_targets.npy\")\n","yhat_raw= np.load(\"/content/drive/My Drive/MIMIC/caml-mimic/predictions/CAML_mimic3_50/test_50_outputs.npy\")\n","#metrics = evaluation.all_metrics(yhat, y, k=5, yhat_raw=yhat_raw)\n","metrics = evaluation.all_metrics(yhat, y, k=5, yhat_raw=yhat_raw)\n","evaluation.print_metrics(metrics)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jem-UaQHWJyp"},"outputs":[],"source":["metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hknuw1XbWJ1O"},"outputs":[],"source":["import numpy as np\n","path = \"/content/drive/My Drive/MIMIC/caml-mimic/predictions/CAML_mimic3_50/process_result/\"\n","\n","with open(path + 'test_full_outputs_epoch_10.npy', 'rb') as f:  \n","  outputs = np.load(f)\n","  print(outputs)\n","  print(outputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uG6gZj4rWJ6g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sm_OWCFkwOUO"},"outputs":[],"source":["#{0: '038.9', 1: '244.9', 2: '250.00', 3: '272.0', 4: '272.4', 5: '276.1', 6: '276.2', 7: '285.1', 8: '285.9', 9: '287.5', 10: '305.1', 11: '311', 12: '33.24', 13: '36.15', 14: '37.22', 15: '37.23', 16: '38.91', 17: '38.93', 18: '39.61', 19: '39.95', 20: '401.9', 21: '403.90', 22: '410.71', 23: '412', 24: '414.01', 25: '424.0', 26: '427.31', 27: '428.0', 28: '45.13', 29: '486', 30: '496', 31: '507.0', 32: '511.9', 33: '518.81', 34: '530.81', 35: '584.9', 36: '585.9', 37: '599.0', 38: '88.56', 39: '88.72', 40: '96.04', 41: '96.6', 42: '96.71', 43: '96.72', 44: '99.04', 45: '99.15', 46: '995.92', 47: 'V15.82', 48: 'V45.81', 49: 'V58.61'})\n","#{'038.9': 0, '244.9': 1, '250.00': 2, '272.0': 3, '272.4': 4, '276.1': 5, '276.2': 6, '285.1': 7, '285.9': 8, '287.5': 9, '305.1': 10, '311': 11, '33.24': 12, '36.15': 13, '37.22': 14, '37.23': 15, '38.91': 16, '38.93': 17, '39.61': 18, '39.95': 19, '401.9': 20, '403.90': 21, '410.71': 22, '412': 23, '414.01': 24, '424.0': 25, '427.31': 26, '428.0': 27, '45.13': 28, '486': 29, '496': 30, '507.0': 31, '511.9': 32, '518.81': 33, '530.81': 34, '584.9': 35, '585.9': 36, '599.0': 37, '88.56': 38, '88.72': 39, '96.04': 40, '96.6': 41, '96.71': 42, '96.72': 43, '99.04': 44, '99.15': 45, '995.92': 46, 'V15.82': 47, 'V45.81': 48, 'V58.61': 49}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J15VVCw-WJ81"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-2OXJbYWJ_Y"},"outputs":[],"source":["from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","y_true = val_targets[:,0]\n","y_pred = val_prediction[:,0]\n","\n","# 混淆矩阵\n","ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n","plt.show()\n","#print(confusion_matrix(y_true, y_pred))\n","\n","# precision,recall,f1\n","target_names = ['class 0', 'class 1']\n","print('report:')\n","print(classification_report(y_true, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0nY8vrkWKCD"},"outputs":[],"source":["con_me = classification_report(y_true, y_pred, target_names = ['class 0', 'class 1'])\n","my_clean_list = []\n","for ele in con_me.split('\\n'):\n","  my_clean_list.append(ele.strip())\n","my_clean_list"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"8y-xMVWaWKEl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661611935644,"user_tz":-480,"elapsed":145406,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"a33ad6bd-daa3-4e7c-ae0d-220675477194"},"outputs":[{"output_type":"stream","name":"stdout","text":["train loss: 6.187173619073185e-05\n"]}],"source":["# 在 训练集 上再跑一边，为了最后的 bar distribution \n","train_iter = torch.utils.data.DataLoader(training_set, batch_size)  # 目的是不用 shuffle\n","train_loss = 0\n","train_targets = []\n","train_outputs = []\n","with torch.no_grad():\n","  # 在 测试集上跑一遍\n","  for batch_idx, data in enumerate(train_iter, 0):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","\n","    loss = loss_fn(outputs, targets)\n","    #loss_list.append(loss)\n","    train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","    train_targets.extend( targets.cpu().detach().numpy())\n","    train_outputs.extend( outputs.cpu().detach().numpy()) \n","  train_loss = train_loss / len(train_iter)\n","  print('train loss:',train_loss)\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"UXkPWFxsWKHH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661612158260,"user_tz":-480,"elapsed":1701,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"b8316823-d545-4759-e9bc-277b33e377ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["AUC:\n","macro: 0.999426548242369\n","micro: 0.9996870332686334\n","F1:\n","macro: 0.9684428738050221\n","micro: 0.9797955580741483\n","Finish save rediction by checkpoint\n"]}],"source":["train_targets = np.array(train_targets)\n","train_outputs = np.array(train_outputs)\n","\n","# 利用 output 做出 prediction\n","ones = torch.ones_like(torch.tensor(train_outputs))\n","zeros = torch.zeros_like(torch.tensor(train_outputs))\n","train_prediction = torch.where(torch.tensor(train_outputs) > 0.5 , ones , zeros)\n","train_prediction = np.array(train_prediction)\n","\n","# 计算在训练集上的 AUC F-1\n","from sklearn.metrics import roc_auc_score\n","print('AUC:')\n","print('macro:',roc_auc_score(train_targets, train_outputs, average='macro'))\n","print('micro:',roc_auc_score(train_targets, train_outputs, average='micro'))\n","print('F1:')\n","print('macro:',f1_score(train_targets, train_prediction, average='macro'))\n","print('micro:',f1_score(train_targets, train_prediction, average='micro'))\n","\n","# 保存模型在 valid dataset 上得到的结果\n","path = \"/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base/\"\n","with open(path + 'bert_train_targets.npy', 'wb') as f:  \n","  np.save(f, train_targets)\n","with open(path + 'bert_train_predictions.npy', 'wb') as f:  \n","  np.save(f, train_prediction)\n","with open(path + 'bert_train_outputs.npy', 'wb') as f:  \n","  np.save(f, train_outputs)\n","print('Finish save rediction by checkpoint')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dT_wVniSWKJe"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjOgM0DjwOXN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["6T2xIMeaBhjd"],"name":"Transformer_MCP_2.ipynb","provenance":[],"authorship_tag":"ABX9TyNAnhxXKmFtAxh6o12A8HC/"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"424ffc1f80e94a88be61f3d667a8d02e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b887c8a69ca456497ab421bae486e3b","IPY_MODEL_6145b92afee446e083d40e6a053b7c88","IPY_MODEL_4c67347dc97c4ec798dcdce32529bef0"],"layout":"IPY_MODEL_751ea7c830ea4a089b95f7946f3e3e3e"}},"2b887c8a69ca456497ab421bae486e3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71ea0a8ae81247b3b8b25b2c41a3296f","placeholder":"​","style":"IPY_MODEL_4d989676942247c98f839dd40daaa859","value":"Downloading vocab.txt: 100%"}},"6145b92afee446e083d40e6a053b7c88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2c9a6c2a584a4db2455709a0cfb7bb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e74b0c7611242288f4bd6b080f74584","value":231508}},"4c67347dc97c4ec798dcdce32529bef0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b5be213fb2b4cc2b557d0a222593d9a","placeholder":"​","style":"IPY_MODEL_9c88d901fed248d0aa007ab3aa9bcad4","value":" 226k/226k [00:00&lt;00:00, 219kB/s]"}},"751ea7c830ea4a089b95f7946f3e3e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71ea0a8ae81247b3b8b25b2c41a3296f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d989676942247c98f839dd40daaa859":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da2c9a6c2a584a4db2455709a0cfb7bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e74b0c7611242288f4bd6b080f74584":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b5be213fb2b4cc2b557d0a222593d9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c88d901fed248d0aa007ab3aa9bcad4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f933294cf514ab0ab95421d22326555":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2008b19b6d124fab9a5a8722ec5ea33f","IPY_MODEL_2685f30dd81d4f7587f3da32c3e0318b","IPY_MODEL_fcbcd3269cf7413691cfe53c816afe18"],"layout":"IPY_MODEL_fb5afa189f684cdb81e70251523127e8"}},"2008b19b6d124fab9a5a8722ec5ea33f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d6b7dc358342558e87fcf7e221967e","placeholder":"​","style":"IPY_MODEL_c803d9f7651847bb8e88e950942c1109","value":"Downloading tokenizer_config.json: 100%"}},"2685f30dd81d4f7587f3da32c3e0318b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca55fc37e47b47f792e824749c58f5e6","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45fbbb85dfcc45d2b9f422348db4d72b","value":28}},"fcbcd3269cf7413691cfe53c816afe18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_300ec0a3cec743af8a1d3c7c86abe3f9","placeholder":"​","style":"IPY_MODEL_8ff6a1dc20e34538abbacd2439e7cced","value":" 28.0/28.0 [00:00&lt;00:00, 221B/s]"}},"fb5afa189f684cdb81e70251523127e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d6b7dc358342558e87fcf7e221967e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c803d9f7651847bb8e88e950942c1109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca55fc37e47b47f792e824749c58f5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45fbbb85dfcc45d2b9f422348db4d72b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"300ec0a3cec743af8a1d3c7c86abe3f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ff6a1dc20e34538abbacd2439e7cced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da4c62ddc6124b5ea8519d2a0fca4378":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5d34f84b6bb4155ab982e8d7a89fa93","IPY_MODEL_b35e85a8c28d472f8f6dd719706515ae","IPY_MODEL_b3dbe711e6404a29b585e44a1864cdce"],"layout":"IPY_MODEL_89d2038822c6491897cd67551e251e97"}},"e5d34f84b6bb4155ab982e8d7a89fa93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a93b292b34d4faab78cca89883ce017","placeholder":"​","style":"IPY_MODEL_9025f30f6e4d4069a33d8712d3777270","value":"Downloading config.json: 100%"}},"b35e85a8c28d472f8f6dd719706515ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2170bf42d8344d05bfccf344d6e224d8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07aa937dea15426998d0ccb18321dcdf","value":570}},"b3dbe711e6404a29b585e44a1864cdce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ca47bb50ec4d6dafaa042d706e4ced","placeholder":"​","style":"IPY_MODEL_12374cf67ff741a39551e84702651ec5","value":" 570/570 [00:00&lt;00:00, 8.29kB/s]"}},"89d2038822c6491897cd67551e251e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a93b292b34d4faab78cca89883ce017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9025f30f6e4d4069a33d8712d3777270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2170bf42d8344d05bfccf344d6e224d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07aa937dea15426998d0ccb18321dcdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0ca47bb50ec4d6dafaa042d706e4ced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12374cf67ff741a39551e84702651ec5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dc859d6c9a64006a8e9f8d9f4e69618":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6974e86e47974224a8fa7f546dd89044","IPY_MODEL_991573bb732c4c04afc37663eedb285c","IPY_MODEL_78722a02ae334b6cb345676661f11538"],"layout":"IPY_MODEL_308157c7b1d040018ff899db34ec63d6"}},"6974e86e47974224a8fa7f546dd89044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf19793168a4df385804beb23c6ce90","placeholder":"​","style":"IPY_MODEL_1a571bbf282547cd9b68a6f72b56d199","value":"Downloading tokenizer.json: 100%"}},"991573bb732c4c04afc37663eedb285c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fcf4821ca66429f8027ad548e49e9fc","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bebc08c412c4268b30b81789ed059d1","value":466062}},"78722a02ae334b6cb345676661f11538":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11d02a35034c4c3b81fcbc260f75c5e6","placeholder":"​","style":"IPY_MODEL_e910846a97cf4fa08875249475b162d4","value":" 455k/455k [00:00&lt;00:00, 601kB/s]"}},"308157c7b1d040018ff899db34ec63d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf19793168a4df385804beb23c6ce90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a571bbf282547cd9b68a6f72b56d199":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fcf4821ca66429f8027ad548e49e9fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bebc08c412c4268b30b81789ed059d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11d02a35034c4c3b81fcbc260f75c5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e910846a97cf4fa08875249475b162d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"983fef2602d048b19606fb2e69090c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a32063b385a4eb5b863b0004e7580c9","IPY_MODEL_ba96d2cc0f844e329686f919473a3760","IPY_MODEL_0960ede8e62c47fab64b8b96e9e23357"],"layout":"IPY_MODEL_9c1bfa8e9ddf4a9680eec25ab51c4e8a"}},"8a32063b385a4eb5b863b0004e7580c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f7b2d1f6f54af1b3be52a27bc6268e","placeholder":"​","style":"IPY_MODEL_8aa3d225a67b435b944a26881556f620","value":"Downloading pytorch_model.bin: 100%"}},"ba96d2cc0f844e329686f919473a3760":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fff98c576a446d195f198ae6b496565","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14bf2df747294294a296919316761f67","value":440473133}},"0960ede8e62c47fab64b8b96e9e23357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c72ae92f9c964f3dba07b977b7e7a70b","placeholder":"​","style":"IPY_MODEL_e0b68676ff6d49038e770df43585d424","value":" 420M/420M [00:14&lt;00:00, 31.1MB/s]"}},"9c1bfa8e9ddf4a9680eec25ab51c4e8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08f7b2d1f6f54af1b3be52a27bc6268e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa3d225a67b435b944a26881556f620":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fff98c576a446d195f198ae6b496565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14bf2df747294294a296919316761f67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c72ae92f9c964f3dba07b977b7e7a70b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b68676ff6d49038e770df43585d424":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
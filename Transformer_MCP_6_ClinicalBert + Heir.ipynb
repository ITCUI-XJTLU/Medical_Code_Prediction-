{"cells":[{"cell_type":"markdown","metadata":{"id":"d-Jva_flsVvc"},"source":["# Long Text Classification ----- ClinicalBert + Heir"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3512,"status":"ok","timestamp":1662343705365,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"qpTwNDERsMdq","outputId":"cad2f8d2-3b09-44bf-c74b-ba9dfaaa465c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["['set_1',\n"," '3BERT _2Transformer_lr2e-5',\n"," '3BERT_2Transformer_lr1e-5',\n"," '6BERT_CNN',\n"," '6BERT_DPCNN']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","\n","os.chdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_bert_heir\")\n","os.listdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_bert_heir\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1662343705367,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"19LzaQLusNUc","outputId":"d57446d0-fbf6-4a78-b2fe-8768d093c6d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep  5 02:08:22 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 产看配置\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7948,"status":"ok","timestamp":1662343713300,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"AGicJQzhsNMD","outputId":"b55faeba-4480-470c-b1a1-61f0df6f382b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib_inline in /usr/local/lib/python3.7/dist-packages (0.1.6)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from matplotlib_inline) (5.1.1)\n"]}],"source":["! pip install transformers\n","# ! pip install d2l\n","! pip install matplotlib_inline"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1662343714499,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"jTJDytJosNR_"},"outputs":[],"source":["import math\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","#from d2l import torch as d2l\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import transformers\n","from transformers import BertTokenizer,AutoTokenizer\n","from torch.utils.data import Dataset\n","import json\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc,roc_auc_score,f1_score,precision_score,recall_score\n","from sklearn.metrics import precision_recall_curve,average_precision_score,PrecisionRecallDisplay\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1662343714501,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"5SWdiYZtsNWs"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qqhemoXvtBBm"},"source":["# utils"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1662343714503,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"Mps25VTRsNZb"},"outputs":[],"source":["# 自制数据集\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.title = dataframe['text']\n","        self.targets = dataframe['labels']\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","\n","        ids = inputs['input_ids']  # 将 input 中的词 encode,把一句话变为一个一维的tensor, 向量长度为max-length, 如果文本过段，用0填充。\n","        mask = inputs['attention_mask']  # 用于 truncation\n","        token_type_ids = inputs[\"token_type_ids\"]  # 第几句话\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),  # 数据 text ，经过encoder后的结果\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1662343714505,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"L6TErK4OsNb-"},"outputs":[],"source":["# 加载模型\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into       \n","    optimizer: optimizer we defined in previous training\n","\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss \n","    return model, optimizer, checkpoint['epoch'], valid_loss_min\n","# 保存模型\n","def save_ckp(state, checkpoint_path):\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n"]},{"cell_type":"markdown","metadata":{"id":"H0E2GlQztKnJ"},"source":["# Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2857,"status":"ok","timestamp":1662343717348,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"0azNCy7rsNeT"},"outputs":[],"source":["#################################### prepare data ###############################\n","# load raw data\n","train_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/train_50.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/test_50.csv')\n","val_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/dev_50.csv')\n","\n","# 首先收集所有的 top 50 的标签，做成列表\n","top_50_list = []\n","top_50_code = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv',header=None)\n","idx2code = {0: '038.9', 1: '244.9', 2: '250.00', 3: '272.0', 4: '272.4', 5: '276.1', 6: '276.2', 7: '285.1', 8: '285.9', 9: '287.5', 10: '305.1', 11: '311', 12: '33.24', 13: '36.15', 14: '37.22', 15: '37.23', 16: '38.91', 17: '38.93', 18: '39.61', 19: '39.95', 20: '401.9', \n","            21: '403.90', 22: '410.71', 23: '412', 24: '414.01', 25: '424.0', 26: '427.31', 27: '428.0', 28: '45.13', 29: '486', 30: '496', 31: '507.0', 32: '511.9', 33: '518.81', 34: '530.81', 35: '584.9', 36: '585.9', 37: '599.0', 38: '88.56', 39: '88.72', 40: '96.04', \n","            41: '96.6', 42: '96.71', 43: '96.72', 44: '99.04', 45: '99.15', 46: '995.92', 47: 'V15.82', 48: 'V45.81', 49: 'V58.61'}\n","for index in range(len(top_50_code[0])):\n","  #raw_info = top_50_code.iloc[index]\n","  #top_50_list.append(raw_info[0])\n","  top_50_list.append(idx2code[index])\n","\n","# 讲一条病人的数据，转化为向量\n","def data_2_label(data_text,top_50_list):\n","  label = []\n","  labels = data_text.split(';')\n","  for element in top_50_list:\n","    if element in labels:\n","      label.append(1)\n","    else:\n","      label.append(0)\n","  return label\n","\n","# 制作训练集\n","train_data_list = []\n","for index in range(len(train_data['LABELS'])):\n","  row_info = train_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  train_data_list.append([text,labels])\n","  \n","train_data_df = pd.DataFrame(train_data_list)\n","train_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作验证集\n","val_data_list = []\n","for index in range(len(val_data['LABELS'])):\n","  row_info = val_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  val_data_list.append([text,labels])\n","  \n","val_data_df = pd.DataFrame(val_data_list)\n","val_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作测试集\n","test_data_list = []\n","for index in range(len(test_data['LABELS'])):\n","  row_info = test_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  test_data_list.append([text,labels])\n","  \n","test_data_df = pd.DataFrame(test_data_list)\n","test_data_df.columns = [\"text\", \"labels\"]\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1662343717350,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"RbxDo1SusNhV","outputId":"278f29fa-d6c2-4b17-a03d-e01c07dd4a9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["8066 1573 1729\n"]}],"source":["print(len(train_data_df),len(val_data_df),len(test_data_df))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2147,"status":"ok","timestamp":1662343719484,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"NmX3tj-psNkV"},"outputs":[],"source":["#数据集的参数\n","tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","MAX_LEN = 1000\n","batch_size = 6\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","# 准备数据集 \n","training_set = CustomDataset(train_data_df, tokenizer, MAX_LEN)\n","val_set = CustomDataset(val_data_df, tokenizer, MAX_LEN)\n","test_set = CustomDataset(test_data_df, tokenizer, MAX_LEN)\n","\n","# 把数据集做成 batch_size 的形式\n","train_iter = torch.utils.data.DataLoader(training_set, batch_size, shuffle=True)\n","val_iter = torch.utils.data.DataLoader(val_set, batch_size)\n","test_iter = torch.utils.data.DataLoader(test_set, batch_size)"]},{"cell_type":"markdown","metadata":{"id":"AOAK9a8ZtgVm"},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1662343719486,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"MlyqBsFmsNpU","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"9653fab9-b07f-49ae-cd79-ebabb5c78960"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# 使用 Does Bert Magic ... 论文的调参模型\\nclass BERTClass(torch.nn.Module):\\n    def __init__(self):\\n        super(BERTClass, self).__init__()\\n        self.l1_bert1 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert2 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert3 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert4 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert5 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert6 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        # transformer 层,concat 后 的大小为： [batch_size, 3 , num_hidden(768)]\\n        #self.l2 = d2l.EncoderBlock(768,768,768,768,[3,768],768,768*2,8,0.2)\\n        encoder_layers = nn.TransformerEncoderLayer(d_model=768, nhead=8)\\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\\n        \\n        self.l3 = torch.nn.Dropout(0.2)\\n        self.l4 = torch.nn.Linear(768, 50)\\n        self.l5 = torch.nn.Sigmoid()\\n\\n    def forward(self, ids, mask, token_type_ids):\\n      # 使用三个Bert读取文本\\n      bert_length = 100\\n      output_all_bert1 = self.l1_bert1(ids[:,0:bert_length*1], \\n                                       attention_mask = mask[:,0:bert_length*1], \\n                                       token_type_ids = token_type_ids[:,0:bert_length*1])\\n      output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\\n      \\n      output_all_bert2 = self.l1_bert2(ids[:,bert_length*1:bert_length*2], \\n                                       attention_mask = mask[:,bert_length*1:bert_length*2], \\n                                       token_type_ids = token_type_ids[:,bert_length*1:bert_length*2])\\n      output_bert2 = output_all_bert2[0]\\n      \\n      output_all_bert3 = self.l1_bert3(ids[:,bert_length*2:bert_length*3], \\n                                       attention_mask = mask[:,bert_length*2:bert_length*3], \\n                                       token_type_ids = token_type_ids[:,bert_length*2:bert_length*3])\\n      output_bert3 = output_all_bert3[0]\\n      \\n      output_all_bert4 = self.l1_bert4(ids[:,bert_length*3:bert_length*4], \\n                                       attention_mask = mask[:,bert_length*3:bert_length*4], \\n                                       token_type_ids = token_type_ids[:,bert_length*3:bert_length*4])\\n      output_bert4 = output_all_bert4[0]\\n      \\n      output_all_bert5 = self.l1_bert5(ids[:,bert_length*4:bert_length*5], \\n                                       attention_mask = mask[:,bert_length*4:bert_length*5], \\n                                       token_type_ids = token_type_ids[:,bert_length*4:bert_length*5])\\n      output_bert5 = output_all_bert5[0]\\n      \\n      output_all_bert6 = self.l1_bert6(ids[:,bert_length*5:bert_length*6], \\n                                       attention_mask = mask[:,bert_length*5:bert_length*6], \\n                                       token_type_ids = token_type_ids[:,bert_length*5:bert_length*6])\\n      output_bert6 = output_all_bert6[0]\\n      # 拼接3个BERT的结果\\n      output_l1 = torch.cat([output_bert1,output_bert2,output_bert3,output_bert4,output_bert5,output_bert6],dim=1)  # output_bert4\\n      # 进入transformer层\\n      #valid_len = (torch.tensor([3.0]) * torch.ones(output_l1.size()[0])).to(device)\\n      #output_l2 = self.l2(output_l1,valid_len)\\n      #output_l1 = output_l1.permute(0,2,1)\\n      output_l1 = output_l1.permute(0,2,1)\\n      output_l1 = output_l1.permute(2,0,1)\\n      transformer_output = self.transformer_encoder(output_l1)\\n      transformer_output = transformer_output.permute(1,0,2)\\n      transformer_output = transformer_output.max(dim=1)[0]\\n      # 进入全连接层\\n      #output_l2_view = output_l2.view(output_l2.size()[0],-1)\\n      output_l3 = self.l3(transformer_output)\\n      output_l4 = self.l4(output_l3)\\n      output_l5 = self.l5(output_l4)\\n      return output_l5\\n '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["# 微调 BERT\n","'''# 使用 Does Bert Magic ... 论文的调参模型\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1_bert1 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert2 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert3 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert4 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert5 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert6 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        # transformer 层,concat 后 的大小为： [batch_size, 3 , num_hidden(768)]\n","        #self.l2 = d2l.EncoderBlock(768,768,768,768,[3,768],768,768*2,8,0.2)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=768, nhead=8)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n","        \n","        self.l3 = torch.nn.Dropout(0.2)\n","        self.l4 = torch.nn.Linear(768, 50)\n","        self.l5 = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","      # 使用三个Bert读取文本\n","      bert_length = 100\n","      output_all_bert1 = self.l1_bert1(ids[:,0:bert_length*1], \n","                                       attention_mask = mask[:,0:bert_length*1], \n","                                       token_type_ids = token_type_ids[:,0:bert_length*1])\n","      output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","      \n","      output_all_bert2 = self.l1_bert2(ids[:,bert_length*1:bert_length*2], \n","                                       attention_mask = mask[:,bert_length*1:bert_length*2], \n","                                       token_type_ids = token_type_ids[:,bert_length*1:bert_length*2])\n","      output_bert2 = output_all_bert2[0]\n","      \n","      output_all_bert3 = self.l1_bert3(ids[:,bert_length*2:bert_length*3], \n","                                       attention_mask = mask[:,bert_length*2:bert_length*3], \n","                                       token_type_ids = token_type_ids[:,bert_length*2:bert_length*3])\n","      output_bert3 = output_all_bert3[0]\n","      \n","      output_all_bert4 = self.l1_bert4(ids[:,bert_length*3:bert_length*4], \n","                                       attention_mask = mask[:,bert_length*3:bert_length*4], \n","                                       token_type_ids = token_type_ids[:,bert_length*3:bert_length*4])\n","      output_bert4 = output_all_bert4[0]\n","      \n","      output_all_bert5 = self.l1_bert5(ids[:,bert_length*4:bert_length*5], \n","                                       attention_mask = mask[:,bert_length*4:bert_length*5], \n","                                       token_type_ids = token_type_ids[:,bert_length*4:bert_length*5])\n","      output_bert5 = output_all_bert5[0]\n","      \n","      output_all_bert6 = self.l1_bert6(ids[:,bert_length*5:bert_length*6], \n","                                       attention_mask = mask[:,bert_length*5:bert_length*6], \n","                                       token_type_ids = token_type_ids[:,bert_length*5:bert_length*6])\n","      output_bert6 = output_all_bert6[0]\n","      # 拼接3个BERT的结果\n","      output_l1 = torch.cat([output_bert1,output_bert2,output_bert3,output_bert4,output_bert5,output_bert6],dim=1)  # output_bert4\n","      # 进入transformer层\n","      #valid_len = (torch.tensor([3.0]) * torch.ones(output_l1.size()[0])).to(device)\n","      #output_l2 = self.l2(output_l1,valid_len)\n","      #output_l1 = output_l1.permute(0,2,1)\n","      output_l1 = output_l1.permute(0,2,1)\n","      output_l1 = output_l1.permute(2,0,1)\n","      transformer_output = self.transformer_encoder(output_l1)\n","      transformer_output = transformer_output.permute(1,0,2)\n","      transformer_output = transformer_output.max(dim=1)[0]\n","      # 进入全连接层\n","      #output_l2_view = output_l2.view(output_l2.size()[0],-1)\n","      output_l3 = self.l3(transformer_output)\n","      output_l4 = self.l4(output_l3)\n","      output_l5 = self.l5(output_l4)\n","      return output_l5\n"," '''       "]},{"cell_type":"code","source":["# 微调 BERT + CNN\n","'''\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1_bert1 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert2 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert3 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert4 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert5 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert6 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        for param in self.l1_bert1.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert2.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert3.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert4.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert5.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert6.parameters():\n","            param.requires_grad = True\n","        # 这里设置 CNN 的关键参数\n","        self.convs = nn.ModuleList([nn.Conv2d(1, 256, (k, 768)) for k in (2, 3, 4)])\n","        self.dropout = nn.Dropout(0.2)\n","\n","        self.fc_cnn = nn.Linear(256 * 3, 50)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def conv_and_pool(self, x, conv):\n","        x = F.relu(conv(x)).squeeze(3)\n","        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n","        return x\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # 使用三个Bert读取文本\n","        bert_length = 100\n","        output_all_bert1 = self.l1_bert1(ids[:,0:bert_length*1], \n","                                       attention_mask = mask[:,0:bert_length*1], \n","                                       token_type_ids = token_type_ids[:,0:bert_length*1])\n","        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","      \n","        output_all_bert2 = self.l1_bert2(ids[:,bert_length*1:bert_length*2], \n","                                       attention_mask = mask[:,bert_length*1:bert_length*2], \n","                                       token_type_ids = token_type_ids[:,bert_length*1:bert_length*2])\n","        output_bert2 = output_all_bert2[0]\n","      \n","        output_all_bert3 = self.l1_bert3(ids[:,bert_length*2:bert_length*3], \n","                                       attention_mask = mask[:,bert_length*2:bert_length*3], \n","                                       token_type_ids = token_type_ids[:,bert_length*2:bert_length*3])\n","        output_bert3 = output_all_bert3[0]\n","      \n","        output_all_bert4 = self.l1_bert4(ids[:,bert_length*3:bert_length*4], \n","                                       attention_mask = mask[:,bert_length*3:bert_length*4], \n","                                       token_type_ids = token_type_ids[:,bert_length*3:bert_length*4])\n","        output_bert4 = output_all_bert4[0]\n","      \n","        output_all_bert5 = self.l1_bert5(ids[:,bert_length*4:bert_length*5], \n","                                       attention_mask = mask[:,bert_length*4:bert_length*5], \n","                                       token_type_ids = token_type_ids[:,bert_length*4:bert_length*5])\n","        output_bert5 = output_all_bert5[0]\n","      \n","        output_all_bert6 = self.l1_bert6(ids[:,bert_length*5:bert_length*6], \n","                                       attention_mask = mask[:,bert_length*5:bert_length*6], \n","                                       token_type_ids = token_type_ids[:,bert_length*5:bert_length*6])\n","        output_bert6 = output_all_bert6[0]\n","        # 拼接3个BERT的结果\n","        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3,output_bert4,output_bert5,output_bert6],dim=1)  # output_bert4\n","        # 开始进入 卷积层\n","        out = output_l1.unsqueeze(1)  #[batch_size, 1, sequence_length, hiden_dimmension]\n","        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n","        out = self.dropout(out)\n","        out = self.fc_cnn(out)\n","        out = self.sigmoid(out)\n","        return out\n","'''"],"metadata":{"id":"tXb_67ecode_","executionInfo":{"status":"ok","timestamp":1662343719488,"user_tz":-480,"elapsed":25,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"142dd868-22ad-416d-d494-a0ae0f8ea90a"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nclass BERTClass(torch.nn.Module):\\n    def __init__(self):\\n        super(BERTClass, self).__init__()\\n        self.l1_bert1 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert2 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert3 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert4 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert5 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        self.l1_bert6 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\\n        for param in self.l1_bert1.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert2.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert3.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert4.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert5.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert6.parameters():\\n            param.requires_grad = True\\n        # 这里设置 CNN 的关键参数\\n        self.convs = nn.ModuleList([nn.Conv2d(1, 256, (k, 768)) for k in (2, 3, 4)])\\n        self.dropout = nn.Dropout(0.2)\\n\\n        self.fc_cnn = nn.Linear(256 * 3, 50)\\n        self.sigmoid = torch.nn.Sigmoid()\\n\\n    def conv_and_pool(self, x, conv):\\n        x = F.relu(conv(x)).squeeze(3)\\n        x = F.max_pool1d(x, x.size(2)).squeeze(2)\\n        return x\\n\\n    def forward(self, ids, mask, token_type_ids):\\n        # 使用三个Bert读取文本\\n        bert_length = 100\\n        output_all_bert1 = self.l1_bert1(ids[:,0:bert_length*1], \\n                                       attention_mask = mask[:,0:bert_length*1], \\n                                       token_type_ids = token_type_ids[:,0:bert_length*1])\\n        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\\n      \\n        output_all_bert2 = self.l1_bert2(ids[:,bert_length*1:bert_length*2], \\n                                       attention_mask = mask[:,bert_length*1:bert_length*2], \\n                                       token_type_ids = token_type_ids[:,bert_length*1:bert_length*2])\\n        output_bert2 = output_all_bert2[0]\\n      \\n        output_all_bert3 = self.l1_bert3(ids[:,bert_length*2:bert_length*3], \\n                                       attention_mask = mask[:,bert_length*2:bert_length*3], \\n                                       token_type_ids = token_type_ids[:,bert_length*2:bert_length*3])\\n        output_bert3 = output_all_bert3[0]\\n      \\n        output_all_bert4 = self.l1_bert4(ids[:,bert_length*3:bert_length*4], \\n                                       attention_mask = mask[:,bert_length*3:bert_length*4], \\n                                       token_type_ids = token_type_ids[:,bert_length*3:bert_length*4])\\n        output_bert4 = output_all_bert4[0]\\n      \\n        output_all_bert5 = self.l1_bert5(ids[:,bert_length*4:bert_length*5], \\n                                       attention_mask = mask[:,bert_length*4:bert_length*5], \\n                                       token_type_ids = token_type_ids[:,bert_length*4:bert_length*5])\\n        output_bert5 = output_all_bert5[0]\\n      \\n        output_all_bert6 = self.l1_bert6(ids[:,bert_length*5:bert_length*6], \\n                                       attention_mask = mask[:,bert_length*5:bert_length*6], \\n                                       token_type_ids = token_type_ids[:,bert_length*5:bert_length*6])\\n        output_bert6 = output_all_bert6[0]\\n        # 拼接3个BERT的结果\\n        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3,output_bert4,output_bert5,output_bert6],dim=1)  # output_bert4\\n        # 开始进入 卷积层\\n        out = output_l1.unsqueeze(1)  #[batch_size, 1, sequence_length, hiden_dimmension]\\n        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\\n        out = self.dropout(out)\\n        out = self.fc_cnn(out)\\n        out = self.sigmoid(out)\\n        return out\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 3 BERT + DPCNN 深度金字塔卷积\n","\n","class BERTClass(nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        # 加载 BERT \n","        self.l1_bert1 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert2 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert3 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert4 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert5 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        self.l1_bert6 = transformers.BertModel.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")\n","        for param in self.l1_bert1.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert2.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert3.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert4.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert5.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert6.parameters():\n","            param.requires_grad = True\n","        \n","        # self.fc = nn.Linear(config.hidden_size, config.num_classes)\n","        self.conv_region = nn.Conv2d(1, 250, (3, 768), stride=1)\n","        self.conv = nn.Conv2d(250, 250, (3, 1), stride=1)\n","        self.max_pool = nn.MaxPool2d(kernel_size=(3, 1), stride=2)\n","        self.padding1 = nn.ZeroPad2d((0, 0, 1, 1))  # top bottom\n","        self.padding2 = nn.ZeroPad2d((0, 0, 0, 1))  # bottom\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(250*2, 50)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # 使用 6 个Bert读取文本\n","        bert_length = 100\n","        output_all_bert1 = self.l1_bert1(ids[:,0:bert_length*1], \n","                                       attention_mask = mask[:,0:bert_length*1], \n","                                       token_type_ids = token_type_ids[:,0:bert_length*1])\n","        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","      \n","        output_all_bert2 = self.l1_bert2(ids[:,bert_length*1:bert_length*2], \n","                                       attention_mask = mask[:,bert_length*1:bert_length*2], \n","                                       token_type_ids = token_type_ids[:,bert_length*1:bert_length*2])\n","        output_bert2 = output_all_bert2[0]\n","      \n","        output_all_bert3 = self.l1_bert3(ids[:,bert_length*2:bert_length*3], \n","                                       attention_mask = mask[:,bert_length*2:bert_length*3], \n","                                       token_type_ids = token_type_ids[:,bert_length*2:bert_length*3])\n","        output_bert3 = output_all_bert3[0]\n","      \n","        output_all_bert4 = self.l1_bert4(ids[:,bert_length*3:bert_length*4], \n","                                       attention_mask = mask[:,bert_length*3:bert_length*4], \n","                                       token_type_ids = token_type_ids[:,bert_length*3:bert_length*4])\n","        output_bert4 = output_all_bert4[0]\n","      \n","        output_all_bert5 = self.l1_bert5(ids[:,bert_length*4:bert_length*5], \n","                                       attention_mask = mask[:,bert_length*4:bert_length*5], \n","                                       token_type_ids = token_type_ids[:,bert_length*4:bert_length*5])\n","        output_bert5 = output_all_bert5[0]\n","      \n","        output_all_bert6 = self.l1_bert6(ids[:,bert_length*5:bert_length*6], \n","                                       attention_mask = mask[:,bert_length*5:bert_length*6], \n","                                       token_type_ids = token_type_ids[:,bert_length*5:bert_length*6])\n","        output_bert6 = output_all_bert6[0]\n","        # 拼接 6 个BERT的结果\n","        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3,output_bert4,output_bert5,output_bert6],dim=1)  # output_bert4\n","      \n","        # 进入 DPCNN 卷积层        \n","        x = output_l1.unsqueeze(1)  # [batch_size, 1, seq_len, embed]\n","        x = self.conv_region(x)  # [batch_size, 250, seq_len-3+1, 1]\n","\n","        x = self.padding1(x)  # [batch_size, 250, seq_len, 1]\n","        x = self.relu(x)\n","        x = self.conv(x)  # [batch_size, 250, seq_len-3+1, 1]\n","        x = self.padding1(x)  # [batch_size, 250, seq_len, 1]\n","        x = self.relu(x)\n","        x = self.conv(x)  # [batch_size, 250, seq_len-3+1, 1]\n","        while x.size()[2] > 2:\n","            x = self._block(x)\n","        x = x.view(x.size()[0],-1)  # [batch_size, num_filters(250)*2]\n","        x = self.fc(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","    def _block(self, x):\n","        x = self.padding2(x)\n","        px = self.max_pool(x)\n","        x = self.padding1(px)\n","        x = F.relu(x)\n","        x = self.conv(x)\n","        x = self.padding1(x)\n","        x = F.relu(x)\n","        x = self.conv(x)\n","        x = x + px  # short cut\n","        return x\n"],"metadata":{"id":"074Umb3aBftQ","executionInfo":{"status":"ok","timestamp":1662343719489,"user_tz":-480,"elapsed":22,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19628,"status":"ok","timestamp":1662343739096,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"NatbHmIssNr7","outputId":"b08a8a26-de88-4d50-8a65-ee607f84580c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (l1_bert1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert2): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert3): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert4): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert5): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert6): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (conv_region): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n","  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n","  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (padding1): ZeroPad2d((0, 0, 1, 1))\n","  (padding2): ZeroPad2d((0, 0, 0, 1))\n","  (relu): ReLU()\n","  (fc): Linear(in_features=500, out_features=50, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":13}],"source":["model = BERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1662343739097,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"VKPuWXjS0vaX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_lEoFmQBRFZn"},"source":["# 优化器"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1662343739098,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"FESl9L_-RHSz"},"outputs":[],"source":["import math\n","import torch\n","from torch.optim import Optimizer\n","from torch.optim.optimizer import required\n","from torch.nn.utils import clip_grad_norm_\n","import logging\n","import abc\n","import sys\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","if sys.version_info >= (3, 4):\n","    ABC = abc.ABC\n","else:\n","    ABC = abc.ABCMeta('ABC', (), {})\n","\n","\n","class _LRSchedule(ABC):\n","    \"\"\" Parent of all LRSchedules here. \"\"\"\n","    warn_t_total = False        # is set to True for schedules where progressing beyond t_total steps doesn't make sense\n","    def __init__(self, warmup=0.002, t_total=-1, **kw):\n","        \"\"\"\n","        :param warmup:  what fraction of t_total steps will be used for linear warmup\n","        :param t_total: how many training steps (updates) are planned\n","        :param kw:\n","        \"\"\"\n","        super(_LRSchedule, self).__init__(**kw)\n","        if t_total < 0:\n","            logger.warning(\"t_total value of {} results in schedule not being applied\".format(t_total))\n","        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n","            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n","        warmup = max(warmup, 0.)\n","        self.warmup, self.t_total = float(warmup), float(t_total)\n","        self.warned_for_t_total_at_progress = -1\n","\n","    def get_lr(self, step, nowarn=False):\n","        \"\"\"\n","        :param step:    which of t_total steps we're on\n","        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n","        :return:        learning rate multiplier for current update\n","        \"\"\"\n","        if self.t_total < 0:\n","            return 1.\n","        progress = float(step) / self.t_total\n","        ret = self.get_lr_(progress)\n","        # warning for exceeding t_total (only active with warmup_linear\n","        if not nowarn and self.warn_t_total and progress > 1. and progress > self.warned_for_t_total_at_progress:\n","            logger.warning(\n","                \"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"\n","                    .format(ret, self.__class__.__name__))\n","            self.warned_for_t_total_at_progress = progress\n","        # end warning\n","        return ret\n","\n","    def get_lr_(self, progress):\n","        \"\"\"\n","        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n","        :return:            learning rate multiplier for current update\n","        \"\"\"\n","        return 1.\n","\n","\n","class ConstantLR(_LRSchedule):\n","    def get_lr_(self, progress):\n","        return 1.\n","\n","\n","class WarmupCosineSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Decreases learning rate from 1. to 0. over remaining `1 - warmup` steps following a cosine curve.\n","    If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n","    \"\"\"\n","    warn_t_total = True\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=.5, **kw):\n","        \"\"\"\n","        :param warmup:      see LRSchedule\n","        :param t_total:     see LRSchedule\n","        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n","        :param kw:\n","        \"\"\"\n","        super(WarmupCosineSchedule, self).__init__(warmup=warmup, t_total=t_total, **kw)\n","        self.cycles = cycles\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)   # progress after warmup\n","            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))\n","\n","\n","class WarmupCosineWithHardRestartsSchedule(WarmupCosineSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n","    learning rate (with hard restarts).\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        super(WarmupCosineWithHardRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","        assert(cycles >= 1.)\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * ((self.cycles * progress) % 1)))\n","            return ret\n","\n","\n","class WarmupCosineWithWarmupRestartsSchedule(WarmupCosineWithHardRestartsSchedule):\n","    \"\"\"\n","    All training progress is divided in `cycles` (default=1.) parts of equal length.\n","    Every part follows a schedule with the first `warmup` fraction of the training steps linearly increasing from 0. to 1.,\n","    followed by a learning rate decreasing from 1. to 0. following a cosine curve.\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        assert(warmup * cycles < 1.)\n","        warmup = warmup * cycles if warmup >= 0 else warmup\n","        super(WarmupCosineWithWarmupRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","\n","    def get_lr_(self, progress):\n","        progress = progress * self.cycles % 1.\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * progress))\n","            return ret\n","\n","\n","class WarmupConstantSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Keeps learning rate equal to 1. after warmup.\n","    \"\"\"\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return 1.\n","\n","\n","class WarmupLinearSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Linearly decreases learning rate from 1. to 0. over remaining `1 - warmup` steps.\n","    \"\"\"\n","    warn_t_total = True\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return max((progress - 1.) / (self.warmup - 1.), 0.)\n","\n","\n","SCHEDULES = {\n","    None:       ConstantLR,\n","    \"none\":     ConstantLR,\n","    \"warmup_cosine\": WarmupCosineSchedule,\n","    \"warmup_constant\": WarmupConstantSchedule,\n","    \"warmup_linear\": WarmupLinearSchedule\n","}\n","\n","\n","class BertAdam(Optimizer):\n","    \"\"\"Implements BERT version of Adam algorithm with weight decay fix.\n","    Params:\n","        lr: learning rate\n","        warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n","        t_total: total number of training steps for the learning\n","            rate schedule, -1  means constant learning rate of 1. (no warmup regardless of warmup setting). Default: -1\n","        schedule: schedule to use for the warmup (see above).\n","            Can be `'warmup_linear'`, `'warmup_constant'`, `'warmup_cosine'`, `'none'`, `None` or a `_LRSchedule` object (see below).\n","            If `None` or `'none'`, learning rate is always kept constant.\n","            Default : `'warmup_linear'`\n","        b1: Adams b1. Default: 0.9\n","        b2: Adams b2. Default: 0.999\n","        e: Adams epsilon. Default: 1e-6\n","        weight_decay: Weight decay. Default: 0.01\n","        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n","    \"\"\"\n","    def __init__(self, params, lr=required, warmup=-1, t_total=-1, schedule='warmup_linear',\n","                 b1=0.9, b2=0.999, e=1e-6, weight_decay=0.01, max_grad_norm=1.0, **kwargs):\n","        if lr is not required and lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n","        if not isinstance(schedule, _LRSchedule) and schedule not in SCHEDULES:\n","            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n","        if not 0.0 <= b1 < 1.0:\n","            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n","        if not 0.0 <= b2 < 1.0:\n","            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n","        if not e >= 0.0:\n","            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n","        # initialize schedule object\n","        if not isinstance(schedule, _LRSchedule):\n","            schedule_type = SCHEDULES[schedule]\n","            schedule = schedule_type(warmup=warmup, t_total=t_total)\n","        else:\n","            if warmup != -1 or t_total != -1:\n","                logger.warning(\"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"\n","                               \"Please specify custom warmup and t_total in _LRSchedule object.\")\n","        defaults = dict(lr=lr, schedule=schedule,\n","                        b1=b1, b2=b2, e=e, weight_decay=weight_decay,\n","                        max_grad_norm=max_grad_norm)\n","        super(BertAdam, self).__init__(params, defaults)\n","\n","    def get_lr(self):\n","        lr = []\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    return [0]\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","                lr.append(lr_scheduled)\n","        return lr\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['next_m'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['next_v'] = torch.zeros_like(p.data)\n","\n","                next_m, next_v = state['next_m'], state['next_v']\n","                beta1, beta2 = group['b1'], group['b2']\n","\n","                # Add grad clipping\n","                if group['max_grad_norm'] > 0:\n","                    clip_grad_norm_(p, group['max_grad_norm'])\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                next_m.mul_(beta1).add_(1 - beta1, grad)\n","                next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                update = next_m / (next_v.sqrt() + group['e'])\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want to decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                if group['weight_decay'] > 0.0:\n","                    update += group['weight_decay'] * p.data\n","\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","\n","                update_with_lr = lr_scheduled * update\n","                p.data.add_(-update_with_lr)\n","\n","                state['step'] += 1\n","\n","                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n","                # No bias correction\n","                # bias_correction1 = 1 - beta1 ** state['step']\n","                # bias_correction2 = 1 - beta2 ** state['step']\n","\n","        return loss"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1662343739099,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"BeUQgy1IRHVZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1662343739100,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"LAqZyzsuRHYD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tLO58NWP0vp7"},"source":["# Train"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1919,"status":"ok","timestamp":1662343741008,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"SfkB5kqOsOB5"},"outputs":[],"source":["import sys\n","import numpy as np\n","sys.path.append(\"/content/drive/My Drive/MIMIC/caml-mimic\")  # 注意，这里改变了地址了\n","import evaluation"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1662343741014,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"NPXdCZmwsOE5","outputId":"d1f50fcd-fd6d-48fe-f5fb-2cfcc6f95d9c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef get_f1_pre_re(y_target,y_output):\\n  # 计算 F1 ， precision , recall\\n  y_output = torch.tensor(y_output)\\n  ones = torch.ones_like(y_output)\\n  zeros = torch.zeros_like(y_output)\\n  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\\n  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\\n  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\\n  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\\n  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\\n  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\\n  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\\n  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\\n  print()\\n  print('The evluation from other code:')\\n  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\\n  print(evaluation.print_metrics(metrics))\\n  \\n  'acc_macro','prec_macro','rec_macro','f1_macro'\\n  'acc_micro','prec_micro','rec_micro','f1_micro',\\n  'rec_at_5','prec_at_5', 'f1_at_5' , \\n  'auc_macro','auc_micro'\\n  \\n  return metrics\\n\\n\\ndef epoch_perform(targets,outputs,name):\\n  performence = get_f1_pre_re(targets,outputs)\\n  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\\n  performence['auc'] = roc_auc\\n  performence['fpr'] = fpr\\n  performence['tpr'] = tpr\\n  print()\\n  print(name+' performence:')\\n  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\\n  print('precision(micro):',performence['precision micro'],\\n        '\\tprecison(macro):',performence['precision macro'],\\n        '\\trecall(micro):',performence['recall micro'],\\n        '\\trecall(macro):',performence['recall macro'],\\n        '\\tf_1 (micro):',performence['f1 micro'],\\n        '\\tf_1 (macro):',performence['f1 macro'])\\n  return performence\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["def get_roc_auc(val_targets,val_outputs):\n","  # input : val_targets 标签 ； val_outputs 模型的输出 (需要np.array类型)\n","  # output: return_fpr (micro,macro) , return_tpr (micro,macro) (list)\n","  # output: return_roc_auc (micro,macro)  (float)\n","  # Compute ROC curve and ROC area for each class\n","  n_classes = len(val_targets[0]) # [num_example,num_class] \n","  fpr = {}\n","  tpr = {}\n","  roc_auc = {}\n","  for i in range(n_classes):\n","    fpr_, tpr_, _ = roc_curve(val_targets[:, i], val_outputs[:, i])\n","    fpr[i] = fpr_.tolist()\n","    tpr[i] = tpr_.tolist()\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","  # Compute micro-average ROC curve and ROC area\n","  fpr_, tpr_, _ = roc_curve(val_targets.ravel(), val_outputs.ravel())\n","  fpr['micro'] = fpr_.tolist()\n","  tpr['micro'] = tpr_.tolist()\n","  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","  # Compute macro-average ROC curve and ROC area\n","  # First aggregate all false positive rates\n","  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","  # Then interpolate all ROC curves at this points\n","  mean_tpr = np.zeros_like(all_fpr)\n","  for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","  # Finally average it and compute AUC\n","  mean_tpr /= n_classes\n","  fpr[\"macro\"] = all_fpr.tolist()\n","  tpr[\"macro\"] = mean_tpr.tolist()\n","  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","  # 返回时，我们只需要micro,macro的信息即可\n","  return_fpr = {'macro':fpr['macro'],'micro':fpr['micro']}\n","  return_tpr = {'macro':tpr['macro'],'micro':tpr['micro']}\n","  return_roc_auc = {'macro':roc_auc['macro'],'micro':roc_auc['micro']}\n","  return return_fpr,return_tpr,return_roc_auc\n","\n","def epoch_perform(y_target,y_output):\n","  # 计算 prediction , 以 0.5 作为阈值\n","  # 输出 mretics\n","  '''\n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro','auc',\n","  'tpr','fpr',\n","  'prec_micro_curve','rec_micro,curve','ave_prec_micro'\n","  '''\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  y_output = y_output.cpu().detach().numpy()\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction.numpy(), y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  # 计算 tpr ,fpr, 用于画出 ROC_AUCROC_AUC\n","  fpr,tpr,roc_auc = get_roc_auc(y_target,y_output)\n","  metrics['auc'] = roc_auc\n","  metrics['fpr'] = fpr\n","  metrics['tpr'] = tpr\n","  print(metrics['auc'])\n","  print()\n","  # 计算 precision,recall ,用于画出 precision-recall curve\n","  precision ={}\n","  recall = {}\n","  average_precision = {}\n","  metrics['prec_micro_curve'], metrics['rec_micro,curve'], _ = precision_recall_curve(y_target.ravel(), y_output.ravel())\n","  metrics['ave_prec_micro'] = average_precision_score(y_target, y_output, average=\"micro\")\n","  return metrics\n","\n","'''\n","def get_f1_pre_re(y_target,y_output):\n","  # 计算 F1 ， precision , recall\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\n","  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\n","  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\n","  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\n","  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\n","  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\n","  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  \n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro'\n","  \n","  return metrics\n","\n","\n","def epoch_perform(targets,outputs,name):\n","  performence = get_f1_pre_re(targets,outputs)\n","  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\n","  performence['auc'] = roc_auc\n","  performence['fpr'] = fpr\n","  performence['tpr'] = tpr\n","  print()\n","  print(name+' performence:')\n","  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\n","  print('precision(micro):',performence['precision micro'],\n","        '\\tprecison(macro):',performence['precision macro'],\n","        '\\trecall(micro):',performence['recall micro'],\n","        '\\trecall(macro):',performence['recall macro'],\n","        '\\tf_1 (micro):',performence['f1 micro'],\n","        '\\tf_1 (macro):',performence['f1 macro'])\n","  return performence\n","'''"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1662343741016,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"V4aEOchqRU7j"},"outputs":[],"source":["def draw_pr_roc(test_performence,\n","                y_target,y_output,\n","                save_path,epoch,name,\n","                key):\n","  # fpr, tpr,roc_auc 三个字典，是 get_roc_auc的输出\n","  # y_target 标签 ； y_output 模型的输出\n","  # save_path 保存图片的地址 ； epoch,name 记录是哪一次的信息\n","  # 输出： 两张图表，roc曲线 和 precision_recall曲线\n","  # 画图，首先是左边，roc_auc 曲线\n","  fig, axs = plt.subplots(1, 2, figsize=(21, 10))\n","  axs[0].step(\n","      test_performence['fpr'][\"micro\"],\n","      test_performence['tpr'][\"micro\"],\n","      label=\"micro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  axs[0].step(\n","      test_performence['fpr'][\"macro\"],\n","      test_performence['tpr'][\"macro\"],\n","      label=\"macro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"macro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,\n","    ) \n","  axs[0].plot([0, 1], [0, 1], \"k--\", lw=2)\n","  axs[0].set_xlim([0.0, 1.0])\n","  axs[0].set_ylim([0.0, 1.05])\n","  axs[0].set_xlabel(\"False Positive Rate\")\n","  axs[0].set_ylabel(\"True Positive Rate\")\n","  axs[0].set_title(\"Receiver Operating Characteristic to multiclass\")\n","\n","  # 然后是右边，precision_recall curve\n","  f_scores = np.linspace(0.2, 0.8, num=4)\n","  lines, labels = [], []\n","  for f_score in f_scores:\n","      x = np.linspace(0.01, 1)\n","      y = f_score * x / (2 * x - f_score)\n","      (l,) = axs[1].plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n","      axs[1].annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n","\n","  display = PrecisionRecallDisplay(\n","      recall=test_performence['rec_micro,curve'],\n","      precision=test_performence['prec_micro_curve'],\n","      average_precision = test_performence['prec_micro'],\n","  )\n","  display.plot(ax=axs[1], name=\"Micro-average precision-recall\", \n","               color=\"#f97306\",linewidth=2) \n","\n","  # add the legend for the iso-f1 curves\n","  handles, labels = display.ax_.get_legend_handles_labels()\n","  handles.extend([l])\n","  labels.extend([\"iso-f1 curves\"])\n","  # set the legend and the axes\n","  axs[1].set_xlim([0.0, 1.0])\n","  axs[1].set_ylim([0.0, 1.05])\n","  axs[1].legend(handles=handles, labels=labels, loc=\"best\")\n","  axs[1].set_title(\"Micro-averaged Prcision-Recall Line\")\n","\n","  for ax in axs:\n","    ax.legend(loc=\"lower right\")\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/epoch_'+str(epoch)+'_'+name+'.png')\n","\n","#draw_pr_roc(return_fpr,return_tpr,return_roc_auc,Y,y_score,\n","#            save_path='/content/drive/My Drive/MIMIC',epoch=1,name='val')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1662343741019,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"yfbzrwlIRU96"},"outputs":[],"source":["def draw_loss(result_loss,save_path,key):\n","  fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n","  # 可视化 train_loss_batch\n","  x = np.arange(0,len(result_loss['train_loss_batch']),1)\n","  y = np.array(result_loss['train_loss_batch'])\n","  axs[0][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][0].set_xlim([0.0, 1.0])\n","  #axs[0][0].set_ylim([0.0, 1.05])\n","  axs[0][0].set_xlabel(\"epoch\")\n","  axs[0][0].set_ylabel(\"Loss\")\n","  axs[0][0].set_title(\"Train Loss per Batchs\")\n","  \n","  # 可视化 train_loss_epoch\n","  x = np.arange(0,len(result_loss['train_loss_epoch']),1)\n","  y = np.array(result_loss['train_loss_epoch'])\n","  print(x)\n","  print(y)\n","  axs[0][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][1].set_xlim([0.0, 1.0])\n","  #axs[0][1].set_ylim([0.0, 1.05])\n","  axs[0][1].set_xlabel(\"epoch\")\n","  axs[0][1].set_ylabel(\"Loss\")\n","  axs[0][1].set_title(\"Train Loss per Epoch\")\n","  \n","  # 可视化 test_loss_epoch\n","  x = np.arange(0,len(result_loss['test_loss_epoch']),1)\n","  y = np.array(result_loss['test_loss_epoch'])\n","  axs[0][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][0].set_xlim([0.0, 1.0])\n","  #axs[1][0].set_ylim([0.0, 1.05])\n","  axs[0][2].set_xlabel(\"epoch\")\n","  axs[0][2].set_ylabel(\"Loss\")\n","  axs[0][2].set_title(\"Test Loss per Epoch\")\n","  \n","  # 可视化 F 1\n","  x = np.arange(0,len(result_loss['test_macro_f1']),1)\n","  y = np.array(result_loss['test_macro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_f1']),1)\n","  y = np.array(result_loss['test_micro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][0].set_xlabel(\"epoch\")\n","  axs[1][0].set_ylabel(\"F 1 score\")\n","  axs[1][0].set_title(\"F 1 score per Epoch\")\n","  axs[1][0].legend()\n","\n","  # 可视化 AUC 得分\n","  x = np.arange(0,len(result_loss['test_macro_auc']),1)\n","  y = np.array(result_loss['test_macro_auc'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"auc (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_auc']),1)\n","  y = np.array(result_loss['test_micro_auc'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      label = \"auc (micro)\",\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][1].set_xlabel(\"epoch\")\n","  axs[1][1].set_ylabel(\"AUC score\")\n","  axs[1][1].set_title(\"AUC score per Epoch\")\n","  axs[1][1].legend()\n","  # 可视化 Precision\n","  x = np.arange(0,len(result_loss['test_macro_precision']),1)\n","  y = np.array(result_loss['test_macro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_precision']),1)\n","  y = np.array(result_loss['test_micro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][2].set_xlabel(\"epoch\")\n","  axs[1][2].set_ylabel(\"Precision score\")\n","  axs[1][2].set_title(\"Precision score per Epoch\")\n","  axs[1][2].legend()\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/loss_epoch_'+str(epoch)+'.png')\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1662343741021,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"YCssYugARVAV"},"outputs":[],"source":["# 设置参数\n","checkpoint_path = '/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_bert_heir/6BERT_DPCNN'\n","model_name = 'clinical-bert-CNN'\n","\n","LEARNING_RATE = 1e-05\n","\n","start_epochs = 1\n","n_epochs = 12\n","\n","# 损失函数\n","def loss_fn(outputs, targets):\n","    #return torch.nn.functional.cross_entropy(outputs, targets)\n","    return torch.nn.functional.binary_cross_entropy(outputs,targets)\n","\n","# 优化器，使用 warm up ,  AdmaW\n","# optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","# optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n","\n","#optimizer = BertAdam(optimizer_grouped_parameters,\n","#                      lr=LEARNING_RATE,\n","#                      warmup=0.05,\n","#                      t_total=len(train_iter) * n_epochs)\n","#sigmoid = torch.nn.Sigmoid()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1jP56xIQ9srirCsjXVAuuxyFlImS9EBwp"},"id":"mW1PyDvrRVCl","executionInfo":{"status":"ok","timestamp":1662360032078,"user_tz":-480,"elapsed":11712979,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"b78ca6a1-d762-4e21-b097-feca5de1ef5e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 正式开始训练\n","result_loss = {'train_loss_batch':[],'train_loss_epoch':[],'test_loss_epoch':[],\n","               'test_macro_f1':[],'test_macro_recall':[],'test_macro_precision':[],\n","               'test_micro_f1':[],'test_micro_recall':[],'test_micro_precision':[],\n","               'test_macro_auc':[],'test_micro_auc':[]}\n","\n","auc_macro_max  = 0  # 初始化最小的验证损失函数\n","for epoch in range(start_epochs, n_epochs+1):\n","  key = 0  # 用于提示合适保存图片\n","  test_targets = []\n","  test_outputs = []\n","  train_loss = 0\n","  test_loss = 0\n","\n","  ######################    \n","   # Train the model #\n","  ######################\n","  process_num = 0  \n","  model.train()\n","  print('###############   Epoch {}: Training Start   #############'.format(epoch))\n","  for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)  \n","\n","    optimizer.zero_grad()\n","    loss = loss_fn(outputs, targets)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","    # 记录信息\n","    process_num += batch_size\n","    if process_num % (64*20) == 0:  ############## 这里可以调\n","      print('already deal with '+ str(process_num)+' data','\\tloss:',loss.item())\n","      result_loss['train_loss_batch'].append(loss.item())\n","  train_loss = train_loss/len(train_iter)  # 计算平均训练损失\n","  result_loss['train_loss_epoch'].append(train_loss) # 放到记录字典里\n","  print('Epoch {}: Training End'.format(epoch))\n","\n","  ######################    \n","  # validate the model #\n","  ######################\n","  model.eval()\n","  with torch.no_grad():\n","    # 在 测试集上跑一遍\n","    for batch_idx, data in enumerate(test_iter, 0):\n","      ids = data['ids'].to(device, dtype = torch.long)\n","      mask = data['mask'].to(device, dtype = torch.long)\n","      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","      targets = data['targets'].to(device, dtype = torch.float)\n","\n","      outputs = model(ids, mask, token_type_ids)\n","\n","      loss = loss_fn(outputs, targets)\n","      test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.item() - test_loss))\n","      test_targets.extend(targets.cpu().detach().numpy())\n","      test_outputs.extend(outputs.cpu().detach().numpy())\n","    test_loss = test_loss / len(test_iter)\n","    result_loss['test_loss_epoch'].append(test_loss)\n","    print('Epoch {}: Validation End'.format(epoch))\n","    # 打印一下 三个损失函数 \n","    print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Test Loss: {:.6f}'.format(epoch, train_loss,test_loss))\n","\n","  #####################################\n","  ######### 记录结果, 保存模型  #########\n","  #####################################\n","  test_performence = epoch_perform(np.array(test_targets),np.array(test_outputs)) # 得到模型在test集合上的表现\n","  result_loss['test_macro_f1'].append(test_performence['f1_macro'])\n","  result_loss['test_micro_f1'].append(test_performence['f1_micro'])\n","  result_loss['test_macro_recall'].append(test_performence['rec_macro'])\n","  result_loss['test_micro_recall'].append(test_performence['rec_micro'])\n","  result_loss['test_macro_precision'].append(test_performence['prec_macro'])\n","  result_loss['test_micro_precision'].append(test_performence['prec_micro'])\n","  result_loss['test_macro_auc'].append(test_performence['auc_macro'])\n","  result_loss['test_micro_auc'].append(test_performence['auc_micro'])\n","\n","  # 下面要保存模型\n","  checkpoint = {\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'test_outputs':np.array(test_outputs),\n","            'test_targets':np.array(test_targets),\n","            'loss':result_loss,\n","            'test_performence':test_performence}\n","  if result_loss['test_macro_auc'][-1] > auc_macro_max:\n","    auc_macro_max = result_loss['test_macro_auc'][-1]\n","    if epoch > 3 :  # 这里是真的要保存了  # 记着设置保存条件\n","      # 保存模型\n","      save_ckp(checkpoint, checkpoint_path+'/checkpoint_epoch_'+ str(epoch) + '.pt' )\n","    # 保存test , loss 字典\n","    #test_json = json.dumps(test_performence,sort_keys=False, indent=4, separators=(',', ': '))\n","    #loss_json = json.dumps(result_loss,sort_keys=False, indent=4, separators=(',', ': '))\n","    #f = open(checkpoint_path + '/test_performence_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(test_json)\n","    #f = open(checkpoint_path + '/loss_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(loss_json)\n","\n","  #####################################\n","  ######### 可视化，打印  #########\n","  #####################################\n","  print('Visulization:')\n","  print(\"Loss :\")\n","  print(result_loss)\n","  draw_loss(result_loss,checkpoint_path,key)\n","  print('test: ')\n","  draw_pr_roc(test_performence,\n","              np.array(test_targets),np.array(test_outputs),   # np 优化\n","              checkpoint_path,epoch,'test',\n","              key)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"uf73gxz9sOHh","executionInfo":{"status":"ok","timestamp":1662360032079,"user_tz":-480,"elapsed":2,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jXgQaDcBnWlr"},"source":["# Evaluation "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"m6T1T5i0sOKN","executionInfo":{"status":"error","timestamp":1662360032916,"user_tz":-480,"elapsed":839,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"e59ba8c0-f24d-4546-9f68-68f80b854c95"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4f8fbcc412e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load_ckp(checkpoint_fpath, model, optimizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# load check point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# initialize state_dict from checkpoint to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/MIMIC/BERT_FineTune/clinical-bert/set_2/checkpoint_epoch_6.pt'"]}],"source":["checkpoint_fpath = \"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical-bert/set_2/checkpoint_epoch_6.pt\"\n","\n","\n","#load_ckp(checkpoint_fpath, model, optimizer)\n","# load check point\n","checkpoint = torch.load(checkpoint_fpath)\n","# initialize state_dict from checkpoint to model\n","model.load_state_dict(checkpoint['state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghars59ZsOMy","executionInfo":{"status":"aborted","timestamp":1662360032917,"user_tz":-480,"elapsed":4,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["valid_loss = 0\n","val_targets = []\n","val_outputs = []\n","with torch.no_grad():\n","  # 在 验证集上跑一遍\n","  for batch_idx, data in enumerate(val_iter, 0):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","\n","    loss = loss_fn(outputs, targets)\n","    #loss_list.append(loss)\n","    valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.i - valid_loss))\n","    val_targets.extend( targets.cpu().detach().numpy())\n","    val_outputs.extend( sigmoid(outputs).cpu().detach().numpy())  # 这里，由于我们没有使用激活函数，所以值可能为负数，为了计算F1,我们必须把它们变成正数\n","  valid_loss = valid_loss / len(val_iter)\n","  #result_loss['valid_loss_epoch'].append(valid_loss)\n","  print('valid loss:',valid_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADRNAxxvsOQP","executionInfo":{"status":"aborted","timestamp":1662360032918,"user_tz":-480,"elapsed":5,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","\n","roc_auc_score(val_targets, val_outputs, average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGYINcnBsOSA","executionInfo":{"status":"aborted","timestamp":1662360032920,"user_tz":-480,"elapsed":7,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Fixing random state for reproducibility\n","np.random.seed(19680801)\n","\n","# some random data\n","#x = np.random.randn(1000)\n","#y = np.random.randn(1000)\n","x = val_targets[:,0]\n","y = val_outputs[:,0]\n","\n","def scatter_hist(x, y, ax, ax_histx, ax_histy):\n","    # no labels\n","    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n","    ax_histy.tick_params(axis=\"y\", labelleft=False)\n","\n","    # the scatter plot:\n","    ax.scatter(x, y)\n","    ax_histx.hist(x, bins=10)\n","    ax_histy.hist(y, bins=20, orientation='horizontal')\n","\n","# definitions for the axes\n","left, width = 0.1, 0.65\n","bottom, height = 0.1, 0.65\n","spacing = 0.005\n","\n","\n","rect_scatter = [left, bottom, width, height]\n","rect_histx = [left, bottom + height + spacing, width, 0.2]\n","rect_histy = [left + width + spacing, bottom, 0.2, height]\n","\n","# start with a square Figure\n","fig = plt.figure(figsize=(12, 12))\n","\n","ax = fig.add_axes(rect_scatter)\n","ax_histx = fig.add_axes(rect_histx, sharex=ax)\n","ax_histy = fig.add_axes(rect_histy, sharey=ax)\n","\n","# use the previously defined function\n","scatter_hist(x, y, ax, ax_histx, ax_histy)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YcrhVUWsOUk","executionInfo":{"status":"aborted","timestamp":1662360032921,"user_tz":-480,"elapsed":8,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv2rp-9_sOXQ","executionInfo":{"status":"aborted","timestamp":1662360032923,"user_tz":-480,"elapsed":10,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lIxC3UUsOaB","executionInfo":{"status":"aborted","timestamp":1662360032924,"user_tz":-480,"elapsed":10,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zs90wHUMsOdO","executionInfo":{"status":"aborted","timestamp":1662360032925,"user_tz":-480,"elapsed":11,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5gawq7EsOfp","executionInfo":{"status":"aborted","timestamp":1662360032925,"user_tz":-480,"elapsed":11,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8Y2_zHPsOiW","executionInfo":{"status":"aborted","timestamp":1662360032926,"user_tz":-480,"elapsed":12,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTGOcyHwsOlV","executionInfo":{"status":"aborted","timestamp":1662360032927,"user_tz":-480,"elapsed":13,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tSFg6SQsOoG","executionInfo":{"status":"aborted","timestamp":1662360032928,"user_tz":-480,"elapsed":14,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-fZTXPnsOq2","executionInfo":{"status":"aborted","timestamp":1662360032929,"user_tz":-480,"elapsed":15,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPGKWc6ZsPBy","executionInfo":{"status":"aborted","timestamp":1662360032929,"user_tz":-480,"elapsed":15,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2_8p0gnsPEa","executionInfo":{"status":"aborted","timestamp":1662360032930,"user_tz":-480,"elapsed":16,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVliqREzsPHj","executionInfo":{"status":"aborted","timestamp":1662360032931,"user_tz":-480,"elapsed":17,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJSk3FP_sPJg","executionInfo":{"status":"aborted","timestamp":1662360032931,"user_tz":-480,"elapsed":17,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvjYp4jQsPMF","executionInfo":{"status":"aborted","timestamp":1662360032932,"user_tz":-480,"elapsed":18,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbAuKZFUsPOt","executionInfo":{"status":"aborted","timestamp":1662360032933,"user_tz":-480,"elapsed":19,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ljxy2gdsPRn","executionInfo":{"status":"aborted","timestamp":1662360032933,"user_tz":-480,"elapsed":18,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcZyErO0sPUG","executionInfo":{"status":"aborted","timestamp":1662360032934,"user_tz":-480,"elapsed":19,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9ug7DqrsPWm","executionInfo":{"status":"aborted","timestamp":1662360032934,"user_tz":-480,"elapsed":19,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUHeqV72sPtS","executionInfo":{"status":"aborted","timestamp":1662360032935,"user_tz":-480,"elapsed":20,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjnUJ3T9sPxz","executionInfo":{"status":"aborted","timestamp":1662360032935,"user_tz":-480,"elapsed":20,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YStspEPbsP0Y","executionInfo":{"status":"aborted","timestamp":1662360032936,"user_tz":-480,"elapsed":21,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_oksOhgsP3H","executionInfo":{"status":"aborted","timestamp":1662360032936,"user_tz":-480,"elapsed":21,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-PYDOl2sP5f","executionInfo":{"status":"aborted","timestamp":1662360032937,"user_tz":-480,"elapsed":22,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRJ0dPdgsP8I","executionInfo":{"status":"aborted","timestamp":1662360032938,"user_tz":-480,"elapsed":23,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zf0wG99hsP-k","executionInfo":{"status":"aborted","timestamp":1662360032939,"user_tz":-480,"elapsed":24,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-PrzxXSsQBb","executionInfo":{"status":"aborted","timestamp":1662360032940,"user_tz":-480,"elapsed":25,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8NJnecNsQEq","executionInfo":{"status":"aborted","timestamp":1662360032941,"user_tz":-480,"elapsed":26,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3mIcWbnsQHA","executionInfo":{"status":"aborted","timestamp":1662360032941,"user_tz":-480,"elapsed":26,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMDOCS+QOLWk3J7hYAbMbJl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
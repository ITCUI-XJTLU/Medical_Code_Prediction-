{"cells":[{"cell_type":"markdown","metadata":{"id":"2DqLxF_1a0Gv"},"source":["# Long Text Classification -----   Clinical-LongFormer"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30345,"status":"ok","timestamp":1661268489495,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"PxEl8RXHZ0Pm","outputId":"5d6ad77f-da43-4e6d-f3dc-5efd3e5b74c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["['checkpoint_epoch_3.pt',\n"," 'loss_epoch_3.png',\n"," 'epoch_3_test.png',\n"," 'checkpoint_epoch_4.pt',\n"," 'loss_epoch_4.png',\n"," 'epoch_4_test.png',\n"," 'checkpoint_epoch_5.pt',\n"," 'loss_epoch_5.png',\n"," 'epoch_5_test.png',\n"," 'checkpoint_epoch_6.pt',\n"," 'loss_epoch_6.png',\n"," 'epoch_6_test.png',\n"," 'checkpoint_epoch_7.pt',\n"," 'loss_epoch_7.png',\n"," 'epoch_7_test.png',\n"," 'checkpoint_epoch_8.pt',\n"," 'loss_epoch_8.png',\n"," 'epoch_8_test.png',\n"," 'checkpoint_epoch_9.pt',\n"," 'loss_epoch_9.png',\n"," 'epoch_9_test.png',\n"," 'checkpoint_epoch_10.pt',\n"," 'loss_epoch_10.png',\n"," 'epoch_10_test.png']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","\n","os.chdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_longformer\")\n","os.listdir(\"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_longformer\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1661268489497,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"FxLNxLr8cJeY","outputId":"db344970-5462-4bac-f531-2aa1b5d84645"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 23 15:28:08 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 产看配置\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":972},"executionInfo":{"elapsed":22141,"status":"ok","timestamp":1661268511627,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"cZOwBBQCbl4A","outputId":"9bfdd355-584c-4cae-cd57-aeb9e9b06058"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 39.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.0-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 42.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.0 tokenizers-0.12.1 transformers-4.21.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Collecting matplotlib\n","  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.36.0-py3-none-any.whl (950 kB)\n","\u001b[K     |████████████████████████████████| 950 kB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n","Installing collected packages: fonttools, matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","Successfully installed fonttools-4.36.0 matplotlib-3.5.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{}}],"source":["! pip install transformers\n","# ! pip install d2l\n","! pip install -U matplotlib"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6t8NgtCQauqD","executionInfo":{"status":"ok","timestamp":1661268515834,"user_tz":-480,"elapsed":4229,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","#from d2l import torch as d2l\n","import transformers\n","from transformers import BertTokenizer\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","import pandas as pd\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc,roc_auc_score,f1_score,precision_score,recall_score\n","from sklearn.metrics import precision_recall_curve,average_precision_score,PrecisionRecallDisplay\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"piQ9kx8fauw4","executionInfo":{"status":"ok","timestamp":1661268515836,"user_tz":-480,"elapsed":20,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"CjdnWRQNcSpT"},"source":["# utils"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hgreRzHPau04","executionInfo":{"status":"ok","timestamp":1661268515837,"user_tz":-480,"elapsed":19,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["# 自制数据集\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.title = dataframe['text']\n","        self.targets = dataframe['labels']\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","\n","        ids = inputs['input_ids']  # 将 input 中的词 encode,把一句话变为一个一维的tensor, 向量长度为max-length, 如果文本过段，用0填充。\n","        mask = inputs['attention_mask']  # 用于 truncation\n","        token_type_ids = inputs[\"token_type_ids\"]  # 第几句话\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),  # 数据 text ，经过encoder后的结果\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tWl3wx38au3N","executionInfo":{"status":"ok","timestamp":1661268515838,"user_tz":-480,"elapsed":20,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["# 加载模型\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into       \n","    optimizer: optimizer we defined in previous training\n","\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss \n","    return model, optimizer, checkpoint['epoch'], valid_loss_min\n","# 保存模型\n","def save_ckp(state, checkpoint_path):\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n"]},{"cell_type":"markdown","metadata":{"id":"1mZXAT3icZsm"},"source":["# Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JWnhCo3Yau51","executionInfo":{"status":"ok","timestamp":1661268521267,"user_tz":-480,"elapsed":5447,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["#################################### prepare data ###############################\n","# load raw data\n","train_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/train_50.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/test_50.csv')\n","val_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/dev_50.csv')\n","\n","# 首先收集所有的 top 50 的标签，做成列表\n","top_50_list = []\n","top_50_code = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv',header=None)\n","idx2code = {0: '038.9', 1: '244.9', 2: '250.00', 3: '272.0', 4: '272.4', 5: '276.1', 6: '276.2', 7: '285.1', 8: '285.9', 9: '287.5', 10: '305.1', 11: '311', 12: '33.24', 13: '36.15', 14: '37.22', 15: '37.23', 16: '38.91', 17: '38.93', 18: '39.61', 19: '39.95', 20: '401.9', \n","            21: '403.90', 22: '410.71', 23: '412', 24: '414.01', 25: '424.0', 26: '427.31', 27: '428.0', 28: '45.13', 29: '486', 30: '496', 31: '507.0', 32: '511.9', 33: '518.81', 34: '530.81', 35: '584.9', 36: '585.9', 37: '599.0', 38: '88.56', 39: '88.72', 40: '96.04', \n","            41: '96.6', 42: '96.71', 43: '96.72', 44: '99.04', 45: '99.15', 46: '995.92', 47: 'V15.82', 48: 'V45.81', 49: 'V58.61'}\n","for index in range(len(top_50_code[0])):\n","  #raw_info = top_50_code.iloc[index]\n","  #top_50_list.append(raw_info[0])\n","  top_50_list.append(idx2code[index])\n","\n","# 讲一条病人的数据，转化为向量\n","def data_2_label(data_text,top_50_list):\n","  label = []\n","  labels = data_text.split(';')\n","  for element in top_50_list:\n","    if element in labels:\n","      label.append(1)\n","    else:\n","      label.append(0)\n","  return label\n","\n","# 制作训练集\n","train_data_list = []\n","for index in range(len(train_data['LABELS'])):\n","  row_info = train_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  train_data_list.append([text,labels])\n","  \n","train_data_df = pd.DataFrame(train_data_list)\n","train_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作验证集\n","val_data_list = []\n","for index in range(len(val_data['LABELS'])):\n","  row_info = val_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  val_data_list.append([text,labels])\n","  \n","val_data_df = pd.DataFrame(val_data_list)\n","val_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作测试集\n","test_data_list = []\n","for index in range(len(test_data['LABELS'])):\n","  row_info = test_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  test_data_list.append([text,labels])\n","  \n","test_data_df = pd.DataFrame(test_data_list)\n","test_data_df.columns = [\"text\", \"labels\"]\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["2c203910a8ce49d893eb3ac245b476a9","887889dc6bb24e05892322109763ad84","cc1e62631ba644978c06420cac9c42eb","c1f67f48f19047328d7af711758f6111","ce8b35d7e9ff42528ba8caa715afc393","dc9b6fc1417445f9864cb66704fd48ae","f42cb4bec2b044e68fed8f31c034f0ca","441593dfb51640c1b12605580ae26835","154518a8bc0146d4a254c3cc347dad19","b10fc74623964f2f83ca2ae15a905289","78274b81244a47d3809fa362fe3b8692","524034429a834410a4f02d98d674dc29","62febe64eb3440f6a48603c173dc5e14","14621cedc8ba4f588993c8457617cc55","a86c8473f9554669996b19f589898a11","8abc7929e00d4cbcb421b2f86894b6c9","23f41cb65ac146bba653ff112ec1782e","c9f44a95cb104c9f8f03d5d7102e857b","f7a248bae90949c9b44d563e5c7fd47d","082732f50ea144cd801f5a428d36b9ff","4ef7ad7ab1b74a48bb4da1d825a083db","cd62bcf1e74644b29867f03c05848dd3","3f063df4130b4873afbe6f005b3f9fc3","9b63dc854cd2455da08d0752ee4f7214","d40af73a8397459ba70fc435bd39c1c3","e509122b5271464bba745b9f52833188","3e01c00c616743358d204132445547c9","5a5a19fa51d140869214b238c539236c","172d75efa1294ce58072f893d36d5c8c","e9ab02db0bb2435da1974576c2412da6","e55f12352f8a4923bd7ad1030677806a","c662e3e16beb4cf3aaac70a4b6153895","65e279ab6dba496ab7ed2174b8979f22","f8341421f0d34b1d862db5769f94a651","509eb38a18244f0da67ba6410cc7ebe1","0599aca910cf4fb587cdb9c10a0d4c5d","e892e974b1f048bc877a73b7e0208cb5","25df28086e4449c39392502074672c42","63aa4a296cff4e18b6ebbfe85a50b77e","dfdc24ca83074b388330ff62eb20b764","30efd3f205af4395aede9b28dc704fb0","d1f156b470724b589d89c11a99ff0425","196ae38e4447469191b2a1702c4b4558","9bdfde5dc68542ab974c2ae74a4424cc","8b3d26d77c974adea8a3d7d5b0f3a1d8","83791fc4cb03408e8d5d4418c43029eb","a98980875cf74baea428e2447ba81b9e","c8922b32b65c4503847fae3060b160b1","fe70ee663a38467eac2fc3d5cd8d0b10","2be54036b2c04ac5ac377afcc66ed617","a96919744cb7466fac740e84faf1f788","6bd9be9fee704726aef679d62ada14f4","dfc5addac8274be7bd86770c266d6065","da3223f9727c477c9b13218b651cc394","45acafb78bf6409683116f265f80c109"]},"executionInfo":{"elapsed":1680,"status":"ok","timestamp":1661268522928,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"IT4zywn7au8d","outputId":"76eacb2e-c8a8-4d4e-d33c-2530b6916566"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c203910a8ce49d893eb3ac245b476a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/780k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524034429a834410a4f02d98d674dc29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f063df4130b4873afbe6f005b3f9fc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8341421f0d34b1d862db5769f94a651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b3d26d77c974adea8a3d7d5b0f3a1d8"}},"metadata":{}}],"source":["#数据集的参数\n","# tokenizer = BertTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n","tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n","MAX_LEN = 4000\n","batch_size = 1\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","# 准备数据集 \n","training_set = CustomDataset(train_data_df, tokenizer, MAX_LEN)\n","val_set = CustomDataset(val_data_df, tokenizer, MAX_LEN)\n","test_set = CustomDataset(test_data_df, tokenizer, MAX_LEN)\n","\n","# 把数据集做成 batch_size 的形式\n","train_iter = torch.utils.data.DataLoader(training_set, batch_size, shuffle=True)\n","val_iter = torch.utils.data.DataLoader(val_set, batch_size)\n","test_iter = torch.utils.data.DataLoader(test_set, batch_size)"]},{"cell_type":"markdown","metadata":{"id":"oxnyA2CJgfG0"},"source":["# Model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"dOBieKjfau_J","executionInfo":{"status":"ok","timestamp":1661268522931,"user_tz":-480,"elapsed":34,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["# 微调 BERT\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        #self.bert = transformers.BertModel.from_pretrained(\"yikuan8/Clinical-Longformer\")\n","        self.bert = AutoModelForMaskedLM.from_pretrained(\"yikuan8/Clinical-Longformer\")\n","        self.dropout = torch.nn.Dropout(0.2)\n","        self.linear = torch.nn.Linear(50265 , 50)  # 50265\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","      # 使用三个Bert读取文本\n","      bert_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","      bert_output = bert_output['logits'][: , 0 , :]\n","      #bert_output = bert_output[1]\n","      #print(bert_output.shape)\n","      # dropout 层\n","      bert_dropout = self.dropout(bert_output)\n","      # 进入全连接层\n","      linear_output = self.linear(bert_dropout)\n","      sigmoid_output = self.sigmoid(linear_output)\n","      return sigmoid_output\n","        "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f30decd5080047a9be9e672e9a1071bc","21b434f2b9d54e22aac0f207b3fb3167","f073ca50ea004d6b9409659824bdcc8d","e30179ab582b48e6b45ac135f8095fd6","8610cd77984c4cf78c6e13014ca7b460","a466fe0786464a5e8484a78d94f731e5","894ec642992d415482c1b6228fd5cc2c","4cc7577d604649c8ab77cc7efbe31dd9","8fb621fd381c46489b260b31f9db0139","d46857ca1927470896b2aff9a77a25d3","1c57ba74a2884a84aa7e97669d10c503","fdcd3a8dca0b4a149cff39ef4f15662f","c533e04001cf4c6fbd047f4688e24916","9f5c3d8aa30a46da9ef1cae02152293c","50eb6dc303264800810a0508ce2c9bdd","95f262a0986f46c78ba62b52d145c978","82dcf28251724e08b08ed8ca7138d52e","2fc66034619446a3902b7af7cb92b280","8fd011e95def4e5bae2c56296b1baebd","a5afe9b347f14334922b58804cf89728","40e7534b55c84a0b906672145003e94e","c1cf4c9d5d5d4ba3a68d9e5f8b387c43"]},"executionInfo":{"elapsed":21915,"status":"ok","timestamp":1661268544816,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"JPOyLHkYavB9","outputId":"a2115c73-0849-431e-eaef-32ccbd8b2083"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f30decd5080047a9be9e672e9a1071bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/567M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdcd3a8dca0b4a149cff39ef4f15662f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at yikuan8/Clinical-Longformer were not used when initializing LongformerForMaskedLM: ['longformer.embeddings.position_ids']\n","- This IS expected if you are initializing LongformerForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (bert): LongformerForMaskedLM(\n","    (longformer): LongformerModel(\n","      (embeddings): LongformerEmbeddings(\n","        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","        (position_embeddings): Embedding(4098, 768, padding_idx=1)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): LongformerEncoder(\n","        (layer): ModuleList(\n","          (0): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): LongformerLayer(\n","            (attention): LongformerAttention(\n","              (self): LongformerSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (query_global): Linear(in_features=768, out_features=768, bias=True)\n","                (key_global): Linear(in_features=768, out_features=768, bias=True)\n","                (value_global): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (output): LongformerSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): LongformerIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): LongformerOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (lm_head): LongformerLMHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (decoder): Linear(in_features=768, out_features=50265, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (linear): Linear(in_features=50265, out_features=50, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":10}],"source":["model = BERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"o6-6xU8navFE","executionInfo":{"status":"ok","timestamp":1661268544818,"user_tz":-480,"elapsed":16,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"YEUXJTiOYl70"},"source":["# 优化器"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FkdgidOcYoIg","executionInfo":{"status":"ok","timestamp":1661268544820,"user_tz":-480,"elapsed":15,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["import math\n","import torch\n","from torch.optim import Optimizer\n","from torch.optim.optimizer import required\n","from torch.nn.utils import clip_grad_norm_\n","import logging\n","import abc\n","import sys\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","if sys.version_info >= (3, 4):\n","    ABC = abc.ABC\n","else:\n","    ABC = abc.ABCMeta('ABC', (), {})\n","\n","\n","class _LRSchedule(ABC):\n","    \"\"\" Parent of all LRSchedules here. \"\"\"\n","    warn_t_total = False        # is set to True for schedules where progressing beyond t_total steps doesn't make sense\n","    def __init__(self, warmup=0.002, t_total=-1, **kw):\n","        \"\"\"\n","        :param warmup:  what fraction of t_total steps will be used for linear warmup\n","        :param t_total: how many training steps (updates) are planned\n","        :param kw:\n","        \"\"\"\n","        super(_LRSchedule, self).__init__(**kw)\n","        if t_total < 0:\n","            logger.warning(\"t_total value of {} results in schedule not being applied\".format(t_total))\n","        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n","            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n","        warmup = max(warmup, 0.)\n","        self.warmup, self.t_total = float(warmup), float(t_total)\n","        self.warned_for_t_total_at_progress = -1\n","\n","    def get_lr(self, step, nowarn=False):\n","        \"\"\"\n","        :param step:    which of t_total steps we're on\n","        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n","        :return:        learning rate multiplier for current update\n","        \"\"\"\n","        if self.t_total < 0:\n","            return 1.\n","        progress = float(step) / self.t_total\n","        ret = self.get_lr_(progress)\n","        # warning for exceeding t_total (only active with warmup_linear\n","        if not nowarn and self.warn_t_total and progress > 1. and progress > self.warned_for_t_total_at_progress:\n","            logger.warning(\n","                \"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"\n","                    .format(ret, self.__class__.__name__))\n","            self.warned_for_t_total_at_progress = progress\n","        # end warning\n","        return ret\n","\n","    def get_lr_(self, progress):\n","        \"\"\"\n","        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n","        :return:            learning rate multiplier for current update\n","        \"\"\"\n","        return 1.\n","\n","\n","class ConstantLR(_LRSchedule):\n","    def get_lr_(self, progress):\n","        return 1.\n","\n","\n","class WarmupCosineSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Decreases learning rate from 1. to 0. over remaining `1 - warmup` steps following a cosine curve.\n","    If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n","    \"\"\"\n","    warn_t_total = True\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=.5, **kw):\n","        \"\"\"\n","        :param warmup:      see LRSchedule\n","        :param t_total:     see LRSchedule\n","        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n","        :param kw:\n","        \"\"\"\n","        super(WarmupCosineSchedule, self).__init__(warmup=warmup, t_total=t_total, **kw)\n","        self.cycles = cycles\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)   # progress after warmup\n","            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))\n","\n","\n","class WarmupCosineWithHardRestartsSchedule(WarmupCosineSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n","    learning rate (with hard restarts).\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        super(WarmupCosineWithHardRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","        assert(cycles >= 1.)\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * ((self.cycles * progress) % 1)))\n","            return ret\n","\n","\n","class WarmupCosineWithWarmupRestartsSchedule(WarmupCosineWithHardRestartsSchedule):\n","    \"\"\"\n","    All training progress is divided in `cycles` (default=1.) parts of equal length.\n","    Every part follows a schedule with the first `warmup` fraction of the training steps linearly increasing from 0. to 1.,\n","    followed by a learning rate decreasing from 1. to 0. following a cosine curve.\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        assert(warmup * cycles < 1.)\n","        warmup = warmup * cycles if warmup >= 0 else warmup\n","        super(WarmupCosineWithWarmupRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","\n","    def get_lr_(self, progress):\n","        progress = progress * self.cycles % 1.\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * progress))\n","            return ret\n","\n","\n","class WarmupConstantSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Keeps learning rate equal to 1. after warmup.\n","    \"\"\"\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return 1.\n","\n","\n","class WarmupLinearSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Linearly decreases learning rate from 1. to 0. over remaining `1 - warmup` steps.\n","    \"\"\"\n","    warn_t_total = True\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return max((progress - 1.) / (self.warmup - 1.), 0.)\n","\n","\n","SCHEDULES = {\n","    None:       ConstantLR,\n","    \"none\":     ConstantLR,\n","    \"warmup_cosine\": WarmupCosineSchedule,\n","    \"warmup_constant\": WarmupConstantSchedule,\n","    \"warmup_linear\": WarmupLinearSchedule\n","}\n","\n","\n","class BertAdam(Optimizer):\n","    \"\"\"Implements BERT version of Adam algorithm with weight decay fix.\n","    Params:\n","        lr: learning rate\n","        warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n","        t_total: total number of training steps for the learning\n","            rate schedule, -1  means constant learning rate of 1. (no warmup regardless of warmup setting). Default: -1\n","        schedule: schedule to use for the warmup (see above).\n","            Can be `'warmup_linear'`, `'warmup_constant'`, `'warmup_cosine'`, `'none'`, `None` or a `_LRSchedule` object (see below).\n","            If `None` or `'none'`, learning rate is always kept constant.\n","            Default : `'warmup_linear'`\n","        b1: Adams b1. Default: 0.9\n","        b2: Adams b2. Default: 0.999\n","        e: Adams epsilon. Default: 1e-6\n","        weight_decay: Weight decay. Default: 0.01\n","        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n","    \"\"\"\n","    def __init__(self, params, lr=required, warmup=-1, t_total=-1, schedule='warmup_linear',\n","                 b1=0.9, b2=0.999, e=1e-6, weight_decay=0.01, max_grad_norm=1.0, **kwargs):\n","        if lr is not required and lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n","        if not isinstance(schedule, _LRSchedule) and schedule not in SCHEDULES:\n","            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n","        if not 0.0 <= b1 < 1.0:\n","            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n","        if not 0.0 <= b2 < 1.0:\n","            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n","        if not e >= 0.0:\n","            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n","        # initialize schedule object\n","        if not isinstance(schedule, _LRSchedule):\n","            schedule_type = SCHEDULES[schedule]\n","            schedule = schedule_type(warmup=warmup, t_total=t_total)\n","        else:\n","            if warmup != -1 or t_total != -1:\n","                logger.warning(\"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"\n","                               \"Please specify custom warmup and t_total in _LRSchedule object.\")\n","        defaults = dict(lr=lr, schedule=schedule,\n","                        b1=b1, b2=b2, e=e, weight_decay=weight_decay,\n","                        max_grad_norm=max_grad_norm)\n","        super(BertAdam, self).__init__(params, defaults)\n","\n","    def get_lr(self):\n","        lr = []\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    return [0]\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","                lr.append(lr_scheduled)\n","        return lr\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['next_m'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['next_v'] = torch.zeros_like(p.data)\n","\n","                next_m, next_v = state['next_m'], state['next_v']\n","                beta1, beta2 = group['b1'], group['b2']\n","\n","                # Add grad clipping\n","                if group['max_grad_norm'] > 0:\n","                    clip_grad_norm_(p, group['max_grad_norm'])\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                next_m.mul_(beta1).add_(1 - beta1, grad)\n","                next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                update = next_m / (next_v.sqrt() + group['e'])\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want to decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                if group['weight_decay'] > 0.0:\n","                    update += group['weight_decay'] * p.data\n","\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","\n","                update_with_lr = lr_scheduled * update\n","                p.data.add_(-update_with_lr)\n","\n","                state['step'] += 1\n","\n","                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n","                # No bias correction\n","                # bias_correction1 = 1 - beta1 ** state['step']\n","                # bias_correction2 = 1 - beta2 ** state['step']\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"NEPLiHaXeYOt"},"source":["# Train "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"tbaITvqv_zCI","executionInfo":{"status":"ok","timestamp":1661268545954,"user_tz":-480,"elapsed":1147,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["import sys\n","import numpy as np\n","sys.path.append(\"/content/drive/My Drive/MIMIC/caml-mimic\")  # 注意，这里改变了地址了\n","import evaluation"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1661268545955,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"SLDfFEHy_zEn","outputId":"02da9db5-dbe9-427c-b55a-d0def3599841"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef get_f1_pre_re(y_target,y_output):\\n  # 计算 F1 ， precision , recall\\n  y_output = torch.tensor(y_output)\\n  ones = torch.ones_like(y_output)\\n  zeros = torch.zeros_like(y_output)\\n  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\\n  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\\n  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\\n  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\\n  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\\n  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\\n  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\\n  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\\n  print()\\n  print('The evluation from other code:')\\n  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\\n  print(evaluation.print_metrics(metrics))\\n  \\n  'acc_macro','prec_macro','rec_macro','f1_macro'\\n  'acc_micro','prec_micro','rec_micro','f1_micro',\\n  'rec_at_5','prec_at_5', 'f1_at_5' , \\n  'auc_macro','auc_micro'\\n  \\n  return metrics\\n\\n\\ndef epoch_perform(targets,outputs,name):\\n  performence = get_f1_pre_re(targets,outputs)\\n  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\\n  performence['auc'] = roc_auc\\n  performence['fpr'] = fpr\\n  performence['tpr'] = tpr\\n  print()\\n  print(name+' performence:')\\n  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\\n  print('precision(micro):',performence['precision micro'],\\n        '\\tprecison(macro):',performence['precision macro'],\\n        '\\trecall(micro):',performence['recall micro'],\\n        '\\trecall(macro):',performence['recall macro'],\\n        '\\tf_1 (micro):',performence['f1 micro'],\\n        '\\tf_1 (macro):',performence['f1 macro'])\\n  return performence\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["def get_roc_auc(val_targets,val_outputs):\n","  # input : val_targets 标签 ； val_outputs 模型的输出 (需要np.array类型)\n","  # output: return_fpr (micro,macro) , return_tpr (micro,macro) (list)\n","  # output: return_roc_auc (micro,macro)  (float)\n","  # Compute ROC curve and ROC area for each class\n","  n_classes = len(val_targets[0]) # [num_example,num_class] \n","  fpr = {}\n","  tpr = {}\n","  roc_auc = {}\n","  for i in range(n_classes):\n","    fpr_, tpr_, _ = roc_curve(val_targets[:, i], val_outputs[:, i])\n","    fpr[i] = fpr_.tolist()\n","    tpr[i] = tpr_.tolist()\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","  # Compute micro-average ROC curve and ROC area\n","  fpr_, tpr_, _ = roc_curve(val_targets.ravel(), val_outputs.ravel())\n","  fpr['micro'] = fpr_.tolist()\n","  tpr['micro'] = tpr_.tolist()\n","  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","  # Compute macro-average ROC curve and ROC area\n","  # First aggregate all false positive rates\n","  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","  # Then interpolate all ROC curves at this points\n","  mean_tpr = np.zeros_like(all_fpr)\n","  for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","  # Finally average it and compute AUC\n","  mean_tpr /= n_classes\n","  fpr[\"macro\"] = all_fpr.tolist()\n","  tpr[\"macro\"] = mean_tpr.tolist()\n","  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","  # 返回时，我们只需要micro,macro的信息即可\n","  return_fpr = {'macro':fpr['macro'],'micro':fpr['micro']}\n","  return_tpr = {'macro':tpr['macro'],'micro':tpr['micro']}\n","  return_roc_auc = {'macro':roc_auc['macro'],'micro':roc_auc['micro']}\n","  return return_fpr,return_tpr,return_roc_auc\n","\n","def epoch_perform(y_target,y_output):\n","  # 计算 prediction , 以 0.5 作为阈值\n","  # 输出 mretics\n","  '''\n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro','auc',\n","  'tpr','fpr',\n","  'prec_micro_curve','rec_micro,curve','ave_prec_micro'\n","  '''\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  y_output = y_output.cpu().detach().numpy()\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction.numpy(), y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  # 计算 tpr ,fpr, 用于画出 ROC_AUCROC_AUC\n","  fpr,tpr,roc_auc = get_roc_auc(y_target,y_output)\n","  metrics['auc'] = roc_auc\n","  metrics['fpr'] = fpr\n","  metrics['tpr'] = tpr\n","  print(metrics['auc'])\n","  print()\n","  # 计算 precision,recall ,用于画出 precision-recall curve\n","  precision ={}\n","  recall = {}\n","  average_precision = {}\n","  metrics['prec_micro_curve'], metrics['rec_micro,curve'], _ = precision_recall_curve(y_target.ravel(), y_output.ravel())\n","  metrics['ave_prec_micro'] = average_precision_score(y_target, y_output, average=\"micro\")\n","  return metrics\n","\n","'''\n","def get_f1_pre_re(y_target,y_output):\n","  # 计算 F1 ， precision , recall\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\n","  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\n","  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\n","  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\n","  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\n","  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\n","  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  \n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro'\n","  \n","  return metrics\n","\n","\n","def epoch_perform(targets,outputs,name):\n","  performence = get_f1_pre_re(targets,outputs)\n","  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\n","  performence['auc'] = roc_auc\n","  performence['fpr'] = fpr\n","  performence['tpr'] = tpr\n","  print()\n","  print(name+' performence:')\n","  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\n","  print('precision(micro):',performence['precision micro'],\n","        '\\tprecison(macro):',performence['precision macro'],\n","        '\\trecall(micro):',performence['recall micro'],\n","        '\\trecall(macro):',performence['recall macro'],\n","        '\\tf_1 (micro):',performence['f1 micro'],\n","        '\\tf_1 (macro):',performence['f1 macro'])\n","  return performence\n","'''"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cHmoEEyQ_1B_","executionInfo":{"status":"ok","timestamp":1661268545956,"user_tz":-480,"elapsed":11,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["def draw_pr_roc(test_performence,\n","                y_target,y_output,\n","                save_path,epoch,name,\n","                key):\n","  # fpr, tpr,roc_auc 三个字典，是 get_roc_auc的输出\n","  # y_target 标签 ； y_output 模型的输出\n","  # save_path 保存图片的地址 ； epoch,name 记录是哪一次的信息\n","  # 输出： 两张图表，roc曲线 和 precision_recall曲线\n","  # 画图，首先是左边，roc_auc 曲线\n","  fig, axs = plt.subplots(1, 2, figsize=(21, 10))\n","  axs[0].step(\n","      test_performence['fpr'][\"micro\"],\n","      test_performence['tpr'][\"micro\"],\n","      label=\"micro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  axs[0].step(\n","      test_performence['fpr'][\"macro\"],\n","      test_performence['tpr'][\"macro\"],\n","      label=\"macro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"macro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,\n","    ) \n","  axs[0].plot([0, 1], [0, 1], \"k--\", lw=2)\n","  axs[0].set_xlim([0.0, 1.0])\n","  axs[0].set_ylim([0.0, 1.05])\n","  axs[0].set_xlabel(\"False Positive Rate\")\n","  axs[0].set_ylabel(\"True Positive Rate\")\n","  axs[0].set_title(\"Receiver Operating Characteristic to multiclass\")\n","\n","  # 然后是右边，precision_recall curve\n","  f_scores = np.linspace(0.2, 0.8, num=4)\n","  lines, labels = [], []\n","  for f_score in f_scores:\n","      x = np.linspace(0.01, 1)\n","      y = f_score * x / (2 * x - f_score)\n","      (l,) = axs[1].plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n","      axs[1].annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n","\n","  display = PrecisionRecallDisplay(\n","      recall=test_performence['rec_micro,curve'],\n","      precision=test_performence['prec_micro_curve'],\n","      average_precision = test_performence['prec_micro'],\n","  )\n","  display.plot(ax=axs[1], name=\"Micro-average precision-recall\", \n","               color=\"#f97306\",linewidth=2) \n","\n","  # add the legend for the iso-f1 curves\n","  handles, labels = display.ax_.get_legend_handles_labels()\n","  handles.extend([l])\n","  labels.extend([\"iso-f1 curves\"])\n","  # set the legend and the axes\n","  axs[1].set_xlim([0.0, 1.0])\n","  axs[1].set_ylim([0.0, 1.05])\n","  axs[1].legend(handles=handles, labels=labels, loc=\"best\")\n","  axs[1].set_title(\"Micro-averaged Prcision-Recall Line\")\n","\n","  for ax in axs:\n","    ax.legend(loc=\"lower right\")\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/epoch_'+str(epoch)+'_'+name+'.png')\n","\n","#draw_pr_roc(return_fpr,return_tpr,return_roc_auc,Y,y_score,\n","#            save_path='/content/drive/My Drive/MIMIC',epoch=1,name='val')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"srtxAQhj_1FE","executionInfo":{"status":"ok","timestamp":1661268545957,"user_tz":-480,"elapsed":11,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["def draw_loss(result_loss,save_path,key):\n","  fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n","  # 可视化 train_loss_batch\n","  x = np.arange(0,len(result_loss['train_loss_batch']),1)\n","  y = np.array(result_loss['train_loss_batch'])\n","  axs[0][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][0].set_xlim([0.0, 1.0])\n","  #axs[0][0].set_ylim([0.0, 1.05])\n","  axs[0][0].set_xlabel(\"epoch\")\n","  axs[0][0].set_ylabel(\"Loss\")\n","  axs[0][0].set_title(\"Train Loss per Batchs\")\n","  \n","  # 可视化 train_loss_epoch\n","  x = np.arange(0,len(result_loss['train_loss_epoch']),1)\n","  y = np.array(result_loss['train_loss_epoch'])\n","  print(x)\n","  print(y)\n","  axs[0][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][1].set_xlim([0.0, 1.0])\n","  #axs[0][1].set_ylim([0.0, 1.05])\n","  axs[0][1].set_xlabel(\"epoch\")\n","  axs[0][1].set_ylabel(\"Loss\")\n","  axs[0][1].set_title(\"Train Loss per Epoch\")\n","  \n","  # 可视化 test_loss_epoch\n","  x = np.arange(0,len(result_loss['test_loss_epoch']),1)\n","  y = np.array(result_loss['test_loss_epoch'])\n","  axs[0][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][0].set_xlim([0.0, 1.0])\n","  #axs[1][0].set_ylim([0.0, 1.05])\n","  axs[0][2].set_xlabel(\"epoch\")\n","  axs[0][2].set_ylabel(\"Loss\")\n","  axs[0][2].set_title(\"Test Loss per Epoch\")\n","  \n","  # 可视化 F 1\n","  x = np.arange(0,len(result_loss['test_macro_f1']),1)\n","  y = np.array(result_loss['test_macro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_f1']),1)\n","  y = np.array(result_loss['test_micro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][0].set_xlabel(\"epoch\")\n","  axs[1][0].set_ylabel(\"F 1 score\")\n","  axs[1][0].set_title(\"F 1 score per Epoch\")\n","  axs[1][0].legend()\n","\n","  # 可视化 Recall\n","  x = np.arange(0,len(result_loss['test_macro_recall']),1)\n","  y = np.array(result_loss['test_macro_recall'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Recall (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_recall']),1)\n","  y = np.array(result_loss['test_micro_recall'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      label = \"Recall (micro)\",\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][1].set_xlabel(\"epoch\")\n","  axs[1][1].set_ylabel(\"Recall score\")\n","  axs[1][1].set_title(\"Recall score per Epoch\")\n","  axs[1][1].legend()\n","  # 可视化 Precision\n","  x = np.arange(0,len(result_loss['test_macro_precision']),1)\n","  y = np.array(result_loss['test_macro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_precision']),1)\n","  y = np.array(result_loss['test_micro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][2].set_xlabel(\"epoch\")\n","  axs[1][2].set_ylabel(\"Precision score\")\n","  axs[1][2].set_title(\"Precision score per Epoch\")\n","  axs[1][2].legend()\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/loss_epoch_'+str(epoch)+'.png')\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"f2d7xX0T_1IH","executionInfo":{"status":"ok","timestamp":1661268545958,"user_tz":-480,"elapsed":11,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["# 设置参数\n","checkpoint_path = '/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_longformer'\n","model_name = 'clinical_longformer'\n","\n","LEARNING_RATE = 2e-05\n","\n","start_epochs = 1\n","n_epochs = 20\n","\n","# 损失函数\n","def loss_fn(outputs, targets):\n","    #return torch.nn.functional.cross_entropy(outputs, targets)\n","    return torch.nn.functional.binary_cross_entropy(outputs,targets)\n","\n","# 优化器，使用 warm up ,  AdmaW\n","# optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","# optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n","\n","#optimizer = BertAdam(optimizer_grouped_parameters,\n","#                      lr=LEARNING_RATE,\n","#                      warmup=0.05,\n","#                      t_total=len(train_iter) * n_epochs)\n","#sigmoid = torch.nn.Sigmoid()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JzQsDDBqpi4kbxNo1l-kYxUcsoxMaOuD"},"id":"oUeyiQXU_8cn","outputId":"cb071c7e-abcb-4bc9-c1b8-232c30968303"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 正式开始训练\n","result_loss = {'train_loss_batch':[],'train_loss_epoch':[],'test_loss_epoch':[],\n","               'test_macro_f1':[],'test_macro_recall':[],'test_macro_precision':[],\n","               'test_micro_f1':[],'test_micro_recall':[],'test_micro_precision':[],\n","               'test_macro_auc':[],'test_micro_auc':[]}\n","\n","test_loss_min  = np.Inf  # 初始化最小的验证损失函数\n","for epoch in range(start_epochs, n_epochs+1):\n","  key = 0  # 用于提示合适保存图片\n","  test_targets = []\n","  test_outputs = []\n","  train_loss = 0\n","  test_loss = 0\n","\n","  ######################    \n","   # Train the model #\n","  ######################\n","  process_num = 0  \n","  model.train()\n","  print('###############   Epoch {}: Training Start   #############'.format(epoch))\n","  for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)  \n","\n","    optimizer.zero_grad()\n","    loss = loss_fn(outputs, targets)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","    # 记录信息\n","    process_num += batch_size\n","    if process_num % (64*20) == 0:  ############## 这里可以调\n","      print('already deal with '+ str(process_num)+' data','\\tloss:',loss.item())\n","      result_loss['train_loss_batch'].append(loss.item())\n","  train_loss = train_loss/len(train_iter)  # 计算平均训练损失\n","  result_loss['train_loss_epoch'].append(train_loss) # 放到记录字典里\n","  print('Epoch {}: Training End'.format(epoch))\n","\n","  ######################    \n","  # validate the model #\n","  ######################\n","  model.eval()\n","  with torch.no_grad():\n","    # 在 测试集上跑一遍\n","    for batch_idx, data in enumerate(test_iter, 0):\n","      ids = data['ids'].to(device, dtype = torch.long)\n","      mask = data['mask'].to(device, dtype = torch.long)\n","      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","      targets = data['targets'].to(device, dtype = torch.float)\n","\n","      outputs = model(ids, mask, token_type_ids)\n","\n","      loss = loss_fn(outputs, targets)\n","      test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.item() - test_loss))\n","      test_targets.extend(targets.cpu().detach().numpy())\n","      test_outputs.extend(outputs.cpu().detach().numpy())\n","    test_loss = test_loss / len(test_iter)\n","    result_loss['test_loss_epoch'].append(test_loss)\n","    print('Epoch {}: Validation End'.format(epoch))\n","    # 打印一下 三个损失函数 \n","    print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Test Loss: {:.6f}'.format(epoch, train_loss,test_loss))\n","\n","  #####################################\n","  ######### 记录结果, 保存模型  #########\n","  #####################################\n","  test_performence = epoch_perform(np.array(test_targets),np.array(test_outputs)) # 得到模型在test集合上的表现\n","  result_loss['test_macro_f1'].append(test_performence['f1_macro'])\n","  result_loss['test_micro_f1'].append(test_performence['f1_micro'])\n","  result_loss['test_macro_recall'].append(test_performence['rec_macro'])\n","  result_loss['test_micro_recall'].append(test_performence['rec_micro'])\n","  result_loss['test_macro_precision'].append(test_performence['prec_macro'])\n","  result_loss['test_micro_precision'].append(test_performence['prec_micro'])\n","  result_loss['test_macro_auc'].append(test_performence['auc_macro'])\n","  result_loss['test_micro_auc'].append(test_performence['auc_micro'])\n","\n","  # 下面要保存模型\n","  checkpoint = {\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'test_outputs':np.array(test_outputs),\n","            'test_targets':np.array(test_targets),\n","            'loss':result_loss,\n","            'test_performence':test_performence}\n","  if epoch % 1 == 0 and epoch > 2:  # 这里是真的要保存了  # 记着设置保存条件\n","    key = 1\n","    # 保存模型\n","    save_ckp(checkpoint, checkpoint_path+'/checkpoint_epoch_'+ str(epoch) + '.pt' )\n","    # 保存test , loss 字典\n","    #test_json = json.dumps(test_performence,sort_keys=False, indent=4, separators=(',', ': '))\n","    #loss_json = json.dumps(result_loss,sort_keys=False, indent=4, separators=(',', ': '))\n","    #f = open(checkpoint_path + '/test_performence_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(test_json)\n","    #f = open(checkpoint_path + '/loss_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(loss_json)\n","\n","  #####################################\n","  ######### 可视化，打印  #########\n","  #####################################\n","  print('Visulization:')\n","  print(\"Loss :\")\n","  print(result_loss)\n","  draw_loss(result_loss,checkpoint_path,key)\n","  print('test: ')\n","  draw_pr_roc(test_performence,\n","              np.array(test_targets),np.array(test_outputs),   # np 优化\n","              checkpoint_path,epoch,'test',\n","              key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_fgvLr9CkAC"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0oTrb76CkDA"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"zlcQncVECkx5"},"source":["# Evaluations:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"JPGQjeae_8fD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661268550240,"user_tz":-480,"elapsed":4292,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"086a3fda-6d2e-4d5c-b054-968de3073576"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":17}],"source":["checkpoint_fpath = \"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_longformer/checkpoint_epoch_10.pt\"\n","\n","\n","#load_ckp(checkpoint_fpath, model, optimizer)\n","# load check point\n","checkpoint = torch.load(checkpoint_fpath)\n","# initialize state_dict from checkpoint to model\n","model.load_state_dict(checkpoint['state_dict'])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Eo3UqXBG_8he","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661268938741,"user_tz":-480,"elapsed":388514,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"0a5fa806-bb60-47a7-c5d2-fa8de9814e07"},"outputs":[{"output_type":"stream","name":"stdout","text":["valid loss: 0.00016697355433018205\n"]}],"source":["valid_loss = 0\n","val_targets = []\n","val_outputs = []\n","with torch.no_grad():\n","  # 在 测试集上跑一遍\n","  for batch_idx, data in enumerate(val_iter, 0):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)\n","\n","    loss = loss_fn(outputs, targets)\n","    #loss_list.append(loss)\n","    valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","    val_targets.extend( targets.cpu().detach().numpy())\n","    val_outputs.extend( outputs.cpu().detach().numpy()) \n","  valid_loss = valid_loss / len(val_iter)\n","  #result_loss['valid_loss_epoch'].append(valid_loss)\n","  print('valid loss:',valid_loss)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"TQaEmD1I_8j4","executionInfo":{"status":"ok","timestamp":1661268938741,"user_tz":-480,"elapsed":15,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["val_targets = np.array(val_targets)\n","val_outputs = np.array(val_outputs)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"a3B_LRlF_8md","executionInfo":{"status":"ok","timestamp":1661268938742,"user_tz":-480,"elapsed":14,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}}},"outputs":[],"source":["# 利用 output 做出 prediction\n","ones = torch.ones_like(torch.tensor(val_outputs))\n","zeros = torch.zeros_like(torch.tensor(val_outputs))\n","val_prediction = torch.where(torch.tensor(val_outputs) > 0.5 , ones , zeros)\n","val_prediction = np.array(val_prediction)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"WtxqKY6H_8t0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661268938742,"user_tz":-480,"elapsed":13,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"f4ad0be3-2a7e-42d1-d1fc-3591f2732ffe"},"outputs":[{"output_type":"stream","name":"stdout","text":["AUC:\n","macro: 0.8687052403011967\n","micro: 0.8897533336890323\n","F1:\n","macro: 0.5075469357754632\n","micro: 0.5954940183397098\n"]}],"source":["from sklearn.metrics import roc_auc_score\n","\n","print('AUC:')\n","print('macro:',roc_auc_score(val_targets, val_outputs, average='macro'))\n","print('micro:',roc_auc_score(val_targets, val_outputs, average='micro'))\n","print('F1:')\n","print('macro:',f1_score(val_targets, val_prediction, average='macro'))\n","print('micro:',f1_score(val_targets, val_prediction, average='micro'))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Da1R1rJY_8rM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661268972230,"user_tz":-480,"elapsed":393,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"}},"outputId":"71b0164b-5140-4568-b6ec-5d8861ee1a9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Finish save rediction by checkpoint\n"]}],"source":["# 保存模型在 valid dataset 上得到的结果\n","path = \"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_longformer/\"\n","with open(path + 'clinicallong_val_targets.npy', 'wb') as f:  \n","  np.save(f, val_targets)\n","with open(path + 'clinicallong_val_predictions.npy', 'wb') as f:  \n","  np.save(f, val_prediction)\n","with open(path + 'clinicallong_val_outputs.npy', 'wb') as f:  \n","  np.save(f, val_outputs)\n","print('Finish save rediction by checkpoint')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APjGp-Xx_8wv"},"outputs":[],"source":["from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","for i in range(0,50):\n","  print('label ',i)\n","  y_true = val_targets[:,i]\n","  y_pred = val_prediction[:,i]\n","\n","  # 混淆矩阵\n","  ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n","  plt.show()\n","  #print(confusion_matrix(y_true, y_pred))\n","\n","  # precision,recall,f1\n","  target_names = ['class 0', 'class 1']\n","  print('report:')\n","  print(classification_report(y_true, y_pred, target_names=target_names))\n","  print()\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KK1emnFC_1Kf"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Fixing random state for reproducibility\n","def scatter_hist(x, y, ax, ax_histx, ax_histy):\n","    # no labels\n","    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n","    ax_histy.tick_params(axis=\"y\", labelleft=False)\n","\n","    # the scatter plot:\n","    ax.scatter(x, y,c=\"#01ff07\",)\n","    ax_histx.hist(x, bins=25)\n","    ax_histy.hist(y, bins=10, orientation='horizontal')\n","\n","for i in range(0,50):\n","  # some random data\n","  #x = np.random.randn(1000)\n","  #y = np.random.randn(1000)\n","  print()\n","  print(\"Below is label \"+ str(i) )\n","  y = val_targets[:,i]\n","  x = val_outputs[:,i]\n","\n","  # definitions for the axes\n","  left, width = 0.1, 0.65\n","  bottom, height = 0.1, 0.65\n","  spacing = 0.005\n","\n","  rect_scatter = [left, bottom, width, height]\n","  rect_histx = [left, bottom + height + spacing, width, 0.2]\n","  rect_histy = [left + width + spacing, bottom, 0.2, height]\n","\n","  # start with a square Figure\n","  fig = plt.figure(figsize=(12, 12))\n","\n","  ax = fig.add_axes(rect_scatter)\n","  ax_histx = fig.add_axes(rect_histx, sharex=ax)\n","  ax_histy = fig.add_axes(rect_histy, sharey=ax)\n","\n","  # use the previously defined function\n","  scatter_hist(x, y, ax, ax_histx, ax_histy)\n","\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ggp_e09Y_1Ms"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sN7aKYxu_1Qc"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mp-C_Fne_1Sd"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKbG8dnP5fuS"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkFogIvK5fwy"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8da06zM5f0d"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtFlrqPR5f_-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZx725B_5gDb"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Transformer_MCP_7.ipynb","provenance":[],"authorship_tag":"ABX9TyNPd7DlpkbVCWCsGOhumE5N"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c203910a8ce49d893eb3ac245b476a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_887889dc6bb24e05892322109763ad84","IPY_MODEL_cc1e62631ba644978c06420cac9c42eb","IPY_MODEL_c1f67f48f19047328d7af711758f6111"],"layout":"IPY_MODEL_ce8b35d7e9ff42528ba8caa715afc393"}},"887889dc6bb24e05892322109763ad84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9b6fc1417445f9864cb66704fd48ae","placeholder":"​","style":"IPY_MODEL_f42cb4bec2b044e68fed8f31c034f0ca","value":"Downloading tokenizer_config.json: 100%"}},"cc1e62631ba644978c06420cac9c42eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_441593dfb51640c1b12605580ae26835","max":347,"min":0,"orientation":"horizontal","style":"IPY_MODEL_154518a8bc0146d4a254c3cc347dad19","value":347}},"c1f67f48f19047328d7af711758f6111":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b10fc74623964f2f83ca2ae15a905289","placeholder":"​","style":"IPY_MODEL_78274b81244a47d3809fa362fe3b8692","value":" 347/347 [00:00&lt;00:00, 11.1kB/s]"}},"ce8b35d7e9ff42528ba8caa715afc393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc9b6fc1417445f9864cb66704fd48ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f42cb4bec2b044e68fed8f31c034f0ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"441593dfb51640c1b12605580ae26835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"154518a8bc0146d4a254c3cc347dad19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b10fc74623964f2f83ca2ae15a905289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78274b81244a47d3809fa362fe3b8692":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"524034429a834410a4f02d98d674dc29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62febe64eb3440f6a48603c173dc5e14","IPY_MODEL_14621cedc8ba4f588993c8457617cc55","IPY_MODEL_a86c8473f9554669996b19f589898a11"],"layout":"IPY_MODEL_8abc7929e00d4cbcb421b2f86894b6c9"}},"62febe64eb3440f6a48603c173dc5e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23f41cb65ac146bba653ff112ec1782e","placeholder":"​","style":"IPY_MODEL_c9f44a95cb104c9f8f03d5d7102e857b","value":"Downloading vocab.json: 100%"}},"14621cedc8ba4f588993c8457617cc55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a248bae90949c9b44d563e5c7fd47d","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_082732f50ea144cd801f5a428d36b9ff","value":798293}},"a86c8473f9554669996b19f589898a11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ef7ad7ab1b74a48bb4da1d825a083db","placeholder":"​","style":"IPY_MODEL_cd62bcf1e74644b29867f03c05848dd3","value":" 780k/780k [00:00&lt;00:00, 3.37MB/s]"}},"8abc7929e00d4cbcb421b2f86894b6c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f41cb65ac146bba653ff112ec1782e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9f44a95cb104c9f8f03d5d7102e857b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7a248bae90949c9b44d563e5c7fd47d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"082732f50ea144cd801f5a428d36b9ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ef7ad7ab1b74a48bb4da1d825a083db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd62bcf1e74644b29867f03c05848dd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f063df4130b4873afbe6f005b3f9fc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b63dc854cd2455da08d0752ee4f7214","IPY_MODEL_d40af73a8397459ba70fc435bd39c1c3","IPY_MODEL_e509122b5271464bba745b9f52833188"],"layout":"IPY_MODEL_3e01c00c616743358d204132445547c9"}},"9b63dc854cd2455da08d0752ee4f7214":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a5a19fa51d140869214b238c539236c","placeholder":"​","style":"IPY_MODEL_172d75efa1294ce58072f893d36d5c8c","value":"Downloading merges.txt: 100%"}},"d40af73a8397459ba70fc435bd39c1c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ab02db0bb2435da1974576c2412da6","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e55f12352f8a4923bd7ad1030677806a","value":456356}},"e509122b5271464bba745b9f52833188":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c662e3e16beb4cf3aaac70a4b6153895","placeholder":"​","style":"IPY_MODEL_65e279ab6dba496ab7ed2174b8979f22","value":" 446k/446k [00:00&lt;00:00, 4.71MB/s]"}},"3e01c00c616743358d204132445547c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a5a19fa51d140869214b238c539236c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172d75efa1294ce58072f893d36d5c8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ab02db0bb2435da1974576c2412da6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e55f12352f8a4923bd7ad1030677806a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c662e3e16beb4cf3aaac70a4b6153895":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e279ab6dba496ab7ed2174b8979f22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8341421f0d34b1d862db5769f94a651":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_509eb38a18244f0da67ba6410cc7ebe1","IPY_MODEL_0599aca910cf4fb587cdb9c10a0d4c5d","IPY_MODEL_e892e974b1f048bc877a73b7e0208cb5"],"layout":"IPY_MODEL_25df28086e4449c39392502074672c42"}},"509eb38a18244f0da67ba6410cc7ebe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63aa4a296cff4e18b6ebbfe85a50b77e","placeholder":"​","style":"IPY_MODEL_dfdc24ca83074b388330ff62eb20b764","value":"Downloading tokenizer.json: 100%"}},"0599aca910cf4fb587cdb9c10a0d4c5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30efd3f205af4395aede9b28dc704fb0","max":1355881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1f156b470724b589d89c11a99ff0425","value":1355881}},"e892e974b1f048bc877a73b7e0208cb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_196ae38e4447469191b2a1702c4b4558","placeholder":"​","style":"IPY_MODEL_9bdfde5dc68542ab974c2ae74a4424cc","value":" 1.29M/1.29M [00:00&lt;00:00, 4.53MB/s]"}},"25df28086e4449c39392502074672c42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63aa4a296cff4e18b6ebbfe85a50b77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfdc24ca83074b388330ff62eb20b764":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30efd3f205af4395aede9b28dc704fb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f156b470724b589d89c11a99ff0425":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"196ae38e4447469191b2a1702c4b4558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bdfde5dc68542ab974c2ae74a4424cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b3d26d77c974adea8a3d7d5b0f3a1d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83791fc4cb03408e8d5d4418c43029eb","IPY_MODEL_a98980875cf74baea428e2447ba81b9e","IPY_MODEL_c8922b32b65c4503847fae3060b160b1"],"layout":"IPY_MODEL_fe70ee663a38467eac2fc3d5cd8d0b10"}},"83791fc4cb03408e8d5d4418c43029eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2be54036b2c04ac5ac377afcc66ed617","placeholder":"​","style":"IPY_MODEL_a96919744cb7466fac740e84faf1f788","value":"Downloading special_tokens_map.json: 100%"}},"a98980875cf74baea428e2447ba81b9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bd9be9fee704726aef679d62ada14f4","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfc5addac8274be7bd86770c266d6065","value":239}},"c8922b32b65c4503847fae3060b160b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da3223f9727c477c9b13218b651cc394","placeholder":"​","style":"IPY_MODEL_45acafb78bf6409683116f265f80c109","value":" 239/239 [00:00&lt;00:00, 7.29kB/s]"}},"fe70ee663a38467eac2fc3d5cd8d0b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be54036b2c04ac5ac377afcc66ed617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a96919744cb7466fac740e84faf1f788":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bd9be9fee704726aef679d62ada14f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc5addac8274be7bd86770c266d6065":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da3223f9727c477c9b13218b651cc394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45acafb78bf6409683116f265f80c109":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f30decd5080047a9be9e672e9a1071bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21b434f2b9d54e22aac0f207b3fb3167","IPY_MODEL_f073ca50ea004d6b9409659824bdcc8d","IPY_MODEL_e30179ab582b48e6b45ac135f8095fd6"],"layout":"IPY_MODEL_8610cd77984c4cf78c6e13014ca7b460"}},"21b434f2b9d54e22aac0f207b3fb3167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a466fe0786464a5e8484a78d94f731e5","placeholder":"​","style":"IPY_MODEL_894ec642992d415482c1b6228fd5cc2c","value":"Downloading config.json: 100%"}},"f073ca50ea004d6b9409659824bdcc8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cc7577d604649c8ab77cc7efbe31dd9","max":929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fb621fd381c46489b260b31f9db0139","value":929}},"e30179ab582b48e6b45ac135f8095fd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d46857ca1927470896b2aff9a77a25d3","placeholder":"​","style":"IPY_MODEL_1c57ba74a2884a84aa7e97669d10c503","value":" 929/929 [00:00&lt;00:00, 18.5kB/s]"}},"8610cd77984c4cf78c6e13014ca7b460":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a466fe0786464a5e8484a78d94f731e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894ec642992d415482c1b6228fd5cc2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cc7577d604649c8ab77cc7efbe31dd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fb621fd381c46489b260b31f9db0139":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d46857ca1927470896b2aff9a77a25d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c57ba74a2884a84aa7e97669d10c503":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdcd3a8dca0b4a149cff39ef4f15662f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c533e04001cf4c6fbd047f4688e24916","IPY_MODEL_9f5c3d8aa30a46da9ef1cae02152293c","IPY_MODEL_50eb6dc303264800810a0508ce2c9bdd"],"layout":"IPY_MODEL_95f262a0986f46c78ba62b52d145c978"}},"c533e04001cf4c6fbd047f4688e24916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82dcf28251724e08b08ed8ca7138d52e","placeholder":"​","style":"IPY_MODEL_2fc66034619446a3902b7af7cb92b280","value":"Downloading pytorch_model.bin: 100%"}},"9f5c3d8aa30a46da9ef1cae02152293c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd011e95def4e5bae2c56296b1baebd","max":594988059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5afe9b347f14334922b58804cf89728","value":594988059}},"50eb6dc303264800810a0508ce2c9bdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40e7534b55c84a0b906672145003e94e","placeholder":"​","style":"IPY_MODEL_c1cf4c9d5d5d4ba3a68d9e5f8b387c43","value":" 567M/567M [00:14&lt;00:00, 47.0MB/s]"}},"95f262a0986f46c78ba62b52d145c978":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82dcf28251724e08b08ed8ca7138d52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fc66034619446a3902b7af7cb92b280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fd011e95def4e5bae2c56296b1baebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5afe9b347f14334922b58804cf89728":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40e7534b55c84a0b906672145003e94e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1cf4c9d5d5d4ba3a68d9e5f8b387c43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
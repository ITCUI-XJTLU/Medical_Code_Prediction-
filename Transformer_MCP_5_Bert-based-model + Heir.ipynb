{"cells":[{"cell_type":"markdown","metadata":{"id":"bNuDIttggsTF"},"source":["# Long Text Classification --- Bert-based-model + Heir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2397,"status":"ok","timestamp":1662449927868,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"SxdWfA2Y88lw","outputId":"b6cd6c2b-7c7c-4656-f230-7b12d2059a6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]},{"data":{"text/plain":["['Multi-Filter-Residual-Convolutional-Neural-Network',\n"," 'LAAT',\n"," 'LAAT_Run.ipynb',\n"," 'Process_Data',\n"," 'MResCNN_RUN.ipynb',\n"," 'BERT_FineTune',\n"," 'Transformer_MCP_1.ipynb',\n"," 'Bert-Chinese-Text-Classification-Pytorch',\n"," 'Transformer_MCP_3.ipynb',\n"," 'caml-mimic',\n"," 'MResCNN_RUN_2.ipynb',\n"," 'CALM_RUN.ipynb',\n"," 'Transformer_MCP_4.ipynb',\n"," 'Transformer_MCP_2.ipynb',\n"," 'FineTune_Visualization.ipynb',\n"," 'mca_bert',\n"," 'Does_Bert_Magic.ipynb',\n"," 'Find_MN.ipynb',\n"," 'transformersum',\n"," 'Transformer_MCP_6_ClinicalBert + Heir.ipynb',\n"," 'Data_Augmentation.ipynb',\n"," 'Transformer_MCP_7_longformer.ipynb',\n"," 'Transformer_MCP_8_ClinicalBert512 + Heir.ipynb',\n"," 'Transformer_MCP_5_Bert-based-model + Heir.ipynb']"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","\n","os.chdir(\"/content/drive/My Drive/MIMIC\")\n","os.listdir(\"/content/drive/My Drive/MIMIC\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11526,"status":"ok","timestamp":1662449939371,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"1RZfvkiXXarN","outputId":"8963c587-e3e4-448c-96f6-1519222fe737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.5.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.37.1)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib_inline in /usr/local/lib/python3.7/dist-packages (0.1.6)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from matplotlib_inline) (5.1.1)\n"]}],"source":["#! pip install d2l\n","! pip install transformers\n","! pip install -U matplotlib\n","! pip install matplotlib_inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6xm6VlI9e10"},"outputs":[],"source":["import math\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","#from d2l import torch as d2l\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import transformers\n","from transformers import BertTokenizer,AutoTokenizer\n","from torch.utils.data import Dataset\n","import json\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc,roc_auc_score,f1_score,precision_score,recall_score\n","from sklearn.metrics import precision_recall_curve,average_precision_score,PrecisionRecallDisplay\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1662449941396,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"D0IuaMh1deVe","outputId":"a6b97558-8206-42b8-8dbd-7e7721f5feba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Sep  6 07:38:59 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# 产看配置\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ui87akDDW6FW"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1' # 下面老是报错 shape 不一致"]},{"cell_type":"markdown","metadata":{"id":"xq3six4ghPEB"},"source":["# Practice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZuP6Ti3oUPv"},"outputs":[],"source":["def transpose_qkv(X, num_heads):\n","    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n","    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n","    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n","    # num_hiddens/num_heads)\n","    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n","\n","    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n","    # num_hiddens/num_heads)\n","    X = X.permute(0, 2, 1, 3)\n","\n","    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n","    # num_hiddens/num_heads)\n","    return X.reshape(-1, X.shape[2], X.shape[3])\n","\n","def transpose_output(X, num_heads):\n","    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n","    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n","    X = X.permute(0, 2, 1, 3)\n","    return X.reshape(X.shape[0], X.shape[1], -1)\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\"多头注意力\"\"\"\n","    def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 num_heads, dropout, bias=False, **kwargs):\n","        super(MultiHeadAttention, self).__init__(**kwargs)\n","        self.num_heads = num_heads\n","        self.attention = d2l.DotProductAttention(dropout)\n","        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n","        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n","        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n","        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n","\n","    def forward(self, queries, keys, values, valid_lens):\n","        # queries，keys，values的形状:\n","        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n","        # valid_lens　的形状:\n","        # (batch_size，)或(batch_size，查询的个数)\n","        # 经过变换后，输出的queries，keys，values　的形状:\n","        # (batch_size*num_heads，查询或者“键－值”对的个数，\n","        # num_hiddens/num_heads)\n","        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n","        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n","        values = transpose_qkv(self.W_v(values), self.num_heads)\n","\n","        if valid_lens is not None:\n","            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n","            # 然后如此复制第二项，然后诸如此类。\n","            valid_lens = torch.repeat_interleave(\n","                valid_lens, repeats=self.num_heads, dim=0)\n","\n","        # output的形状:(batch_size*num_heads，查询的个数，\n","        # num_hiddens/num_heads)\n","        output = self.attention(queries, keys, values, valid_lens)\n","\n","        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n","        output_concat = transpose_output(output, self.num_heads)\n","        return self.W_o(output_concat)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78,"status":"ok","timestamp":1662449941402,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"WJ90HGgpoftQ","outputId":"55356b48-b664-497a-8e72-2a7019c40ff2"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nnum_hiddens, num_heads = 100, 5\\nattention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\\n                               num_hiddens, num_heads, 0.5)\\nattention.eval()\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","num_hiddens, num_heads = 100, 5\n","attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n","                               num_hiddens, num_heads, 0.5)\n","attention.eval()\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76,"status":"ok","timestamp":1662449941404,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"P3YGaSG4okEi","outputId":"b3e4b1ea-11a8-4ef4-bbee-cd46ffc4d6f7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nbatch_size, num_queries = 2, 4\\nnum_kvpairs, valid_lens =  6, torch.tensor([3, 2])\\nX = torch.ones((batch_size, num_queries, num_hiddens))\\nY = torch.ones((batch_size, num_kvpairs, num_hiddens))\\nattention(X, Y, Y, valid_lens).shape\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","batch_size, num_queries = 2, 4\n","num_kvpairs, valid_lens =  6, torch.tensor([3, 2])\n","X = torch.ones((batch_size, num_queries, num_hiddens))\n","Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n","attention(X, Y, Y, valid_lens).shape\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAvSO2mdmo05"},"outputs":[],"source":["######## Transformer Module #############################\n","class PositionWiseFFN(nn.Module):\n","    \"\"\"基于位置的前馈网络\"\"\"\n","    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n","                 **kwargs):\n","        super(PositionWiseFFN, self).__init__(**kwargs)\n","        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n","        self.relu = nn.ReLU()\n","        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n","\n","    def forward(self, X):\n","        return self.dense2(self.relu(self.dense1(X)))\n","\n","class AddNorm(nn.Module):\n","    \"\"\"残差连接后进行层规范化\"\"\"\n","    def __init__(self, normalized_shape, dropout, **kwargs):\n","        super(AddNorm, self).__init__(**kwargs)\n","        self.dropout = nn.Dropout(dropout)\n","        self.ln = nn.LayerNorm(normalized_shape)\n","\n","    def forward(self, X, Y):\n","        return self.ln(self.dropout(Y) + X)\n","\n","class EncoderBlock(nn.Module):\n","    \"\"\"transformer编码器块\"\"\"\n","    def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 norm_shape, \n","                 ffn_num_input, ffn_num_hiddens, \n","                 num_heads,\n","                 dropout, use_bias=False, **kwargs):\n","        super(EncoderBlock, self).__init__(**kwargs)\n","        self.attention = d2l.MultiHeadAttention(\n","            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n","            use_bias)\n","        self.addnorm1 = AddNorm(norm_shape, dropout)\n","        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n","        self.addnorm2 = AddNorm(norm_shape, dropout)\n","\n","    def forward(self, X,valid_lens):\n","        mid = self.attention(X, X, X,valid_lens)\n","        print('mid:',mid)\n","        Y = self.addnorm1(X, mid)\n","        return self.addnorm2(Y, self.ffn(Y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76,"status":"ok","timestamp":1662449941408,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"JhJgMPtmm6e5","outputId":"00d39e44-a621-4dbd-e1ee-5573a5cd6ea5"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'X = torch.ones((2,4,768))\\nvalid_lens = torch.tensor([100, 100])\\nencoder_blk = EncoderBlock(768, 768, 768, 768, [4,768], 768, 768*2, 8, 0.5)\\nencoder_blk.eval()\\nencoder_blk(X, valid_lens).shape'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["'''X = torch.ones((2,4,768))\n","valid_lens = torch.tensor([100, 100])\n","encoder_blk = EncoderBlock(768, 768, 768, 768, [4,768], 768, 768*2, 8, 0.5)\n","encoder_blk.eval()\n","encoder_blk(X, valid_lens).shape'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1662449941410,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"8UjvFoynnsK7","outputId":"64a23501-987f-4b12-dff5-f759b9f50659"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'X = torch.ones((2,4,768))\\nvalid_lens = torch.tensor([0, 0])\\n\\nencoder_blk.eval()\\nencoder_blk(X, valid_lens).shape'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["'''X = torch.ones((2,4,768))\n","valid_lens = torch.tensor([0, 0])\n","\n","encoder_blk.eval()\n","encoder_blk(X, valid_lens).shape'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HdA0zZIYnsNz"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1662449941414,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"nIdY2C9HnsQy","outputId":"df474ba8-b221-4393-f477-a44a24e1a597"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nx = torch.tensor([0.0, 2.0, 8.0], requires_grad = True)\\ny = torch.tensor([5.0, 1.0, 7.0], requires_grad = True)\\nz = torch.tensor([[3.0, 4.0, 5.0]], requires_grad = True)\\nalpha = torch.tensor([33.0],requires_grad = True)\\n\\nx_y_mul = x*y\\nx_y_mul_add = x_y_mul.unsqueeze(dim=0)\\ncat_x_y = torch.cat([x_y_mul_add,z],dim=0)\\ncat_x_y = cat_x_y.view(-1)\\n\\nmul = cat_x_y * alpha\\nmul = mul.sum()\\nmul.backward()\\nprint(x.grad)\\nprint(y.grad)\\n\\nprint(x_y_mul.grad)\\nprint(x_y_mul_add.grad)\\n\\nprint(z.grad)\\nprint(cat_x_y.grad)\\n\\nprint(alpha.grad)\\n#z = x * y\\n#z.backward(torch.Tensor([1, 1, 1]))\\n\\n#print(x.grad, y.grad)\\n# outputs\\n#(tensor([5., 1., 7.]), tensor([0., 2., 8.]))'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","x = torch.tensor([0.0, 2.0, 8.0], requires_grad = True)\n","y = torch.tensor([5.0, 1.0, 7.0], requires_grad = True)\n","z = torch.tensor([[3.0, 4.0, 5.0]], requires_grad = True)\n","alpha = torch.tensor([33.0],requires_grad = True)\n","\n","x_y_mul = x*y\n","x_y_mul_add = x_y_mul.unsqueeze(dim=0)\n","cat_x_y = torch.cat([x_y_mul_add,z],dim=0)\n","cat_x_y = cat_x_y.view(-1)\n","\n","mul = cat_x_y * alpha\n","mul = mul.sum()\n","mul.backward()\n","print(x.grad)\n","print(y.grad)\n","\n","print(x_y_mul.grad)\n","print(x_y_mul_add.grad)\n","\n","print(z.grad)\n","print(cat_x_y.grad)\n","\n","print(alpha.grad)\n","#z = x * y\n","#z.backward(torch.Tensor([1, 1, 1]))\n","\n","#print(x.grad, y.grad)\n","# outputs\n","#(tensor([5., 1., 7.]), tensor([0., 2., 8.]))'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kdYpvMQDnsTy"},"outputs":[],"source":["#tensor1 = torch.tensor([[1,2],[3,4]])\n","#tensor2 = tensor1.unsqueeze(dim=1)\n","#print(tensor2.shape)\n","#tensor1.size()[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bc7GkdHk9CZD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"N37zT9wmm7U9"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19YzQUtLm-SA"},"outputs":[],"source":["# 自制数据集\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.title = dataframe['text']\n","        self.targets = dataframe['labels']\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","\n","        ids = inputs['input_ids']  # 将 input 中的词 encode,把一句话变为一个一维的tensor, 向量长度为max-length, 如果文本过段，用0填充。\n","        mask = inputs['attention_mask']  # 用于 truncation\n","        token_type_ids = inputs[\"token_type_ids\"]  # 第几句话\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),  # 数据 text ，经过encoder后的结果\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jc6dyokjm-Uw"},"outputs":[],"source":["# 加载模型\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","\n","    \"\"\"\n","    checkpoint_path: path to save checkpoint\n","    model: model that we want to load checkpoint parameters into       \n","    optimizer: optimizer we defined in previous training\n","\n","    \"\"\"\n","    # load check point\n","    checkpoint = torch.load(checkpoint_fpath)\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['state_dict'])\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    valid_loss_min = checkpoint['valid_loss_min']\n","    # return model, optimizer, epoch value, min validation loss \n","    return model, optimizer, checkpoint['epoch'], valid_loss_min\n","# 保存模型\n","def save_ckp(state, checkpoint_path):\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIsYSan9m-Xs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hssx4efdIeGQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Vqh51BVChBkX"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkwBnqBY9Cbg"},"outputs":[],"source":["#################################### prepare data ###############################\n","# load raw data\n","train_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/train_50.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/test_50.csv')\n","val_data = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/dev_50.csv')\n","\n","# 首先收集所有的 top 50 的标签，做成列表\n","top_50_list = []\n","top_50_code = pd.read_csv('/content/drive/My Drive/MIMIC/caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv',header=None)\n","idx2code = {0: '038.9', 1: '244.9', 2: '250.00', 3: '272.0', 4: '272.4', 5: '276.1', 6: '276.2', 7: '285.1', 8: '285.9', 9: '287.5', 10: '305.1', 11: '311', 12: '33.24', 13: '36.15', 14: '37.22', 15: '37.23', 16: '38.91', 17: '38.93', 18: '39.61', 19: '39.95', 20: '401.9', \n","            21: '403.90', 22: '410.71', 23: '412', 24: '414.01', 25: '424.0', 26: '427.31', 27: '428.0', 28: '45.13', 29: '486', 30: '496', 31: '507.0', 32: '511.9', 33: '518.81', 34: '530.81', 35: '584.9', 36: '585.9', 37: '599.0', 38: '88.56', 39: '88.72', 40: '96.04', \n","            41: '96.6', 42: '96.71', 43: '96.72', 44: '99.04', 45: '99.15', 46: '995.92', 47: 'V15.82', 48: 'V45.81', 49: 'V58.61'}\n","for index in range(len(top_50_code[0])):\n","  #raw_info = top_50_code.iloc[index]\n","  #top_50_list.append(raw_info[0])\n","  top_50_list.append(idx2code[index])\n","\n","# 讲一条病人的数据，转化为向量\n","def data_2_label(data_text,top_50_list):\n","  label = []\n","  labels = data_text.split(';')\n","  for element in top_50_list:\n","    if element in labels:\n","      label.append(1)\n","    else:\n","      label.append(0)\n","  return label\n","\n","# 制作训练集\n","train_data_list = []\n","for index in range(len(train_data['LABELS'])):\n","  row_info = train_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  train_data_list.append([text,labels])\n","  \n","train_data_df = pd.DataFrame(train_data_list)\n","train_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作验证集\n","val_data_list = []\n","for index in range(len(val_data['LABELS'])):\n","  row_info = val_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  val_data_list.append([text,labels])\n","  \n","val_data_df = pd.DataFrame(val_data_list)\n","val_data_df.columns = [\"text\", \"labels\"]\n","\n","# 制作测试集\n","test_data_list = []\n","for index in range(len(test_data['LABELS'])):\n","  row_info = test_data.iloc[index]\n","  text = row_info[2]\n","  labels = data_2_label(row_info[3],top_50_list)\n","  test_data_list.append([text,labels])\n","  \n","test_data_df = pd.DataFrame(test_data_list)\n","test_data_df.columns = [\"text\", \"labels\"]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1662449944225,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"59kJe7uupp43","outputId":"76c97f06-1a85-457d-800d-7cab9ca0a39c"},"outputs":[{"name":"stdout","output_type":"stream","text":["8066 1573 1729\n"]}],"source":["print(len(train_data_df),len(val_data_df),len(test_data_df))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAQ96dccpp7J"},"outputs":[],"source":["#数据集的参数\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","MAX_LEN = 2000\n","batch_size = 100\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n","# 准备数据集 \n","training_set = CustomDataset(train_data_df, tokenizer, MAX_LEN)\n","val_set = CustomDataset(val_data_df, tokenizer, MAX_LEN)\n","test_set = CustomDataset(test_data_df, tokenizer, MAX_LEN)\n","\n","# 把数据集做成 batch_size 的形式\n","train_iter = torch.utils.data.DataLoader(training_set, batch_size, shuffle=True)\n","val_iter = torch.utils.data.DataLoader(val_set, batch_size)\n","test_iter = torch.utils.data.DataLoader(test_set, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUWqdeWCiNC5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_8LoJ0-5hEh4"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kG6i66W9CWX"},"outputs":[],"source":["######## Transformer Module #############################\n","class PositionWiseFFN(nn.Module):\n","    \"\"\"基于位置的前馈网络\"\"\"\n","    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n","                 **kwargs):\n","        super(PositionWiseFFN, self).__init__(**kwargs)\n","        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n","        self.relu = nn.ReLU()\n","        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n","\n","    def forward(self, X):\n","        return self.dense2(self.relu(self.dense1(X)))\n","\n","class AddNorm(nn.Module):\n","    \"\"\"残差连接后进行层规范化\"\"\"\n","    def __init__(self, normalized_shape, dropout, **kwargs):\n","        super(AddNorm, self).__init__(**kwargs)\n","        self.dropout = nn.Dropout(dropout)\n","        self.ln = nn.LayerNorm(normalized_shape)\n","\n","    def forward(self, X, Y):\n","        return self.ln(self.dropout(Y) + X)\n","\n","class EncoderBlock(nn.Module):\n","    \"\"\"transformer编码器块\"\"\"\n","    def __init__(self, key_size, query_size, value_size, num_hiddens,\n","                 norm_shape, \n","                 ffn_num_input, ffn_num_hiddens, \n","                 num_heads,\n","                 dropout, use_bias=False, **kwargs):\n","        super(EncoderBlock, self).__init__(**kwargs)\n","        self.attention = d2l.MultiHeadAttention(\n","            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n","            use_bias)\n","        self.addnorm1 = AddNorm(norm_shape, dropout)\n","        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n","        self.addnorm2 = AddNorm(norm_shape, dropout)\n","\n","    def forward(self, X,valid_lens):\n","        mid = self.attention(X, X, X,valid_lens)\n","        print('mid:',mid)\n","        Y = self.addnorm1(X, mid)\n","        return self.addnorm2(Y, self.ffn(Y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1662449947153,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"UZi1oUJQ9ChA","outputId":"476fd2cb-f7be-4174-9cd1-780c14da3012"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nclass BERTClass(torch.nn.Module):\\n    def __init__(self):\\n        super(BERTClass, self).__init__()\\n        self.l1_bert1 = transformers.BertModel.from_pretrained('bert-base-uncased')  # output [ batch_size(自己定) , num_hidden(768) ]\\n        self.l1_bert2 = transformers.BertModel.from_pretrained('bert-base-uncased')\\n        self.l1_bert3 = transformers.BertModel.from_pretrained('bert-base-uncased')\\n        #self.l1_bert4 = transformers.BertModel.from_pretrained('bert-base-uncased')\\n\\n        # concat 后 的大小为： [batch_size(4), 4 , num_hidden(768)]\\n        # transformer 层\\n        #self.l2 = d2l.EncoderBlock(768,768,768,768,\\n        #                       [3,768],\\n        #                       768,768*2,\\n        #                       8,0.3)\\n        encoder_layers = nn.TransformerEncoderLayer(d_model=768, nhead=8)\\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\\n        # 全连接层\\n        self.l3 = torch.nn.Dropout(0.2)\\n        self.l4 = torch.nn.Linear(768, 50)\\n        self.l5 = torch.nn.Sigmoid()\\n\\n    def forward(self, ids, mask, token_type_ids):\\n        #print(ids.shape,mask.shape,token_type_ids.shape)\\n        output_all_bert1 = self.l1_bert1(ids[:,0:512*1], attention_mask = mask[:,0:512*1], token_type_ids = token_type_ids[:,0:512*1])\\n        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\\n        output_all_bert2 = self.l1_bert2(ids[:,512*1:512*2], attention_mask = mask[:,512*1:512*2], token_type_ids = token_type_ids[:,512*1:512*2])\\n        output_bert2 = output_all_bert2[0]\\n        output_all_bert3 = self.l1_bert3(ids[:,512*2:512*3], attention_mask = mask[:,512*2:512*3], token_type_ids = token_type_ids[:,512*2:512*3])\\n        output_bert3 = output_all_bert3[0]\\n        #output_all_bert4 = self.l1_bert4(ids[:,512*3:512*4], attention_mask = mask[:,512*3:512*4], token_type_ids = token_type_ids[:,512*3:512*4])\\n        #output_bert4 = output_all_bert4[1].unsqueeze(dim=1)\\n        # 拼接4个BERT的结果\\n        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3],dim=1)  # output_bert3,output_bert4\\n        #print('output_l1 shape: ',output_l1.shape)\\n\\n        # 进入transformer层        \\n        #valid_len = (torch.tensor([4.0]) * torch.ones(output_l1.size()[0])).to(device)\\n        #output_l2 = self.l2(output_l1,valid_len)\\n        #print('output_l2 shape:',output_l2.shape)\\n        #print(output_l2.shape)\\n        output_l1 = output_l1.permute(0,2,1)\\n        output_l1 = output_l1.permute(2,0,1)\\n        transformer_output = self.transformer_encoder(output_l1)\\n        transformer_output = transformer_output.permute(1,0,2)\\n        transformer_output = transformer_output.max(dim=1)[0]\\n\\n        # 进入全连接层\\n        # output_l2_view = output_l2.view(output_l2.size()[0],-1)\\n        output_l3 = self.l3(transformer_output)\\n        output_l4 = self.l4(output_l3)\\n        output_l5 = self.l5(output_l4)\\n        return output_l5\\n\""]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# 微调 BERT\n","# 使用论文 Does Bert Magic 里的网络架构\n","'''\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1_bert1 = transformers.BertModel.from_pretrained('bert-base-uncased')  # output [ batch_size(自己定) , num_hidden(768) ]\n","        self.l1_bert2 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l1_bert3 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        #self.l1_bert4 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","\n","        # concat 后 的大小为： [batch_size(4), 4 , num_hidden(768)]\n","        # transformer 层\n","        #self.l2 = d2l.EncoderBlock(768,768,768,768,\n","        #                       [3,768],\n","        #                       768,768*2,\n","        #                       8,0.3)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=768, nhead=8)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n","        # 全连接层\n","        self.l3 = torch.nn.Dropout(0.2)\n","        self.l4 = torch.nn.Linear(768, 50)\n","        self.l5 = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        #print(ids.shape,mask.shape,token_type_ids.shape)\n","        output_all_bert1 = self.l1_bert1(ids[:,0:512*1], attention_mask = mask[:,0:512*1], token_type_ids = token_type_ids[:,0:512*1])\n","        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","        output_all_bert2 = self.l1_bert2(ids[:,512*1:512*2], attention_mask = mask[:,512*1:512*2], token_type_ids = token_type_ids[:,512*1:512*2])\n","        output_bert2 = output_all_bert2[0]\n","        output_all_bert3 = self.l1_bert3(ids[:,512*2:512*3], attention_mask = mask[:,512*2:512*3], token_type_ids = token_type_ids[:,512*2:512*3])\n","        output_bert3 = output_all_bert3[0]\n","        #output_all_bert4 = self.l1_bert4(ids[:,512*3:512*4], attention_mask = mask[:,512*3:512*4], token_type_ids = token_type_ids[:,512*3:512*4])\n","        #output_bert4 = output_all_bert4[1].unsqueeze(dim=1)\n","        # 拼接4个BERT的结果\n","        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3],dim=1)  # output_bert3,output_bert4\n","        #print('output_l1 shape: ',output_l1.shape)\n","\n","        # 进入transformer层        \n","        #valid_len = (torch.tensor([4.0]) * torch.ones(output_l1.size()[0])).to(device)\n","        #output_l2 = self.l2(output_l1,valid_len)\n","        #print('output_l2 shape:',output_l2.shape)\n","        #print(output_l2.shape)\n","        output_l1 = output_l1.permute(0,2,1)\n","        output_l1 = output_l1.permute(2,0,1)\n","        transformer_output = self.transformer_encoder(output_l1)\n","        transformer_output = transformer_output.permute(1,0,2)\n","        transformer_output = transformer_output.max(dim=1)[0]\n","\n","        # 进入全连接层\n","        # output_l2_view = output_l2.view(output_l2.size()[0],-1)\n","        output_l3 = self.l3(transformer_output)\n","        output_l4 = self.l4(output_l3)\n","        output_l5 = self.l5(output_l4)\n","        return output_l5\n","'''        "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1662449947154,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"Hxk3mWCs0Ier","outputId":"2ac7a554-4210-45c2-9644-e4bfa33385da"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nclass BERTClass(torch.nn.Module):\\n    def __init__(self):\\n        super(BERTClass, self).__init__()\\n        self.l1_bert1 = transformers.BertModel.from_pretrained('bert-base-uncased')  # output [ batch_size(自己定) , num_hidden(768) ]\\n        self.l1_bert2 = transformers.BertModel.from_pretrained('bert-base-uncased')\\n        self.l1_bert3 = transformers.BertModel.from_pretrained('bert-base-uncased')\\n        for param in self.l1_bert1.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert2.parameters():\\n            param.requires_grad = True\\n        for param in self.l1_bert3.parameters():\\n            param.requires_grad = True\\n        # CNN 关键参数\\n        self.convs = nn.ModuleList([nn.Conv2d(1, 256, (k, 768)) for k in (2, 3, 4)])\\n        self.dropout = nn.Dropout(0.2)\\n        self.fc_cnn = nn.Linear(256 * 3, 50)\\n        self.sigmoid = torch.nn.Sigmoid()\\n\\n    def conv_and_pool(self, x, conv):\\n        x = F.relu(conv(x)).squeeze(3)\\n        x = F.max_pool1d(x, x.size(2)).squeeze(2)\\n        return x\\n\\n    def forward(self, ids, mask, token_type_ids):\\n        # 使用 3 个 BERT 读取文本\\n        output_all_bert1 = self.l1_bert1(ids[:,0:512*1], attention_mask = mask[:,0:512*1], token_type_ids = token_type_ids[:,0:512*1])\\n        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\\n        output_all_bert2 = self.l1_bert2(ids[:,512*1:512*2], attention_mask = mask[:,512*1:512*2], token_type_ids = token_type_ids[:,512*1:512*2])\\n        output_bert2 = output_all_bert2[0]\\n        output_all_bert3 = self.l1_bert3(ids[:,512*2:512*3], attention_mask = mask[:,512*2:512*3], token_type_ids = token_type_ids[:,512*2:512*3])\\n        output_bert3 = output_all_bert3[0]\\n        # 拼接 3 个BERT的结果\\n        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3],dim=1)  # output_bert3,output_bert4\\n        #print('output_l1 shape: ',output_l1.shape)\\n\\n        # 进入卷积层\\n        out = output_l1.unsqueeze(1)  #[batch_size, 1, sequence_length, hiden_dimmension]\\n        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\\n        out = self.dropout(out)\\n        out = self.fc_cnn(out)\\n        out = self.sigmoid(out)\\n        return out\\n\""]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# BERT + CNN 进行文本分类\n","'''\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1_bert1 = transformers.BertModel.from_pretrained('bert-base-uncased')  # output [ batch_size(自己定) , num_hidden(768) ]\n","        self.l1_bert2 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l1_bert3 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        for param in self.l1_bert1.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert2.parameters():\n","            param.requires_grad = True\n","        for param in self.l1_bert3.parameters():\n","            param.requires_grad = True\n","        # CNN 关键参数\n","        self.convs = nn.ModuleList([nn.Conv2d(1, 256, (k, 768)) for k in (2, 3, 4)])\n","        self.dropout = nn.Dropout(0.2)\n","        self.fc_cnn = nn.Linear(256 * 3, 50)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def conv_and_pool(self, x, conv):\n","        x = F.relu(conv(x)).squeeze(3)\n","        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n","        return x\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # 使用 3 个 BERT 读取文本\n","        output_all_bert1 = self.l1_bert1(ids[:,0:512*1], attention_mask = mask[:,0:512*1], token_type_ids = token_type_ids[:,0:512*1])\n","        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","        output_all_bert2 = self.l1_bert2(ids[:,512*1:512*2], attention_mask = mask[:,512*1:512*2], token_type_ids = token_type_ids[:,512*1:512*2])\n","        output_bert2 = output_all_bert2[0]\n","        output_all_bert3 = self.l1_bert3(ids[:,512*2:512*3], attention_mask = mask[:,512*2:512*3], token_type_ids = token_type_ids[:,512*2:512*3])\n","        output_bert3 = output_all_bert3[0]\n","        # 拼接 3 个BERT的结果\n","        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3],dim=1)  # output_bert3,output_bert4\n","        #print('output_l1 shape: ',output_l1.shape)\n","\n","        # 进入卷积层\n","        out = output_l1.unsqueeze(1)  #[batch_size, 1, sequence_length, hiden_dimmension]\n","        out = torch.cat([self.conv_and_pool(out, conv) for conv in self.convs], 1)\n","        out = self.dropout(out)\n","        out = self.fc_cnn(out)\n","        out = self.sigmoid(out)\n","        return out\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-4jFwJ4-Al-"},"outputs":[],"source":["# 3 BERT + DPCNN 深度金字塔卷积\n","\n","class BERTClass(nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        # 加载 BERT \n","        self.l1_bert1 = transformers.BertModel.from_pretrained('bert-base-uncased')  # output [ batch_size(自己定) , num_hidden(768) ]\n","        self.l1_bert2 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l1_bert3 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        for param in self.l1_bert1.parameters():\n","            param.requires_grad = False\n","        for param in self.l1_bert2.parameters():\n","            param.requires_grad = False\n","        for param in self.l1_bert3.parameters():\n","            param.requires_grad = False\n","        \n","        # self.fc = nn.Linear(config.hidden_size, config.num_classes)\n","        self.conv_region = nn.Conv2d(1, 250, (3, 768), stride=1)\n","        self.conv = nn.Conv2d(250, 250, (3, 1), stride=1)\n","        self.max_pool = nn.MaxPool2d(kernel_size=(3, 1), stride=2)\n","        self.padding1 = nn.ZeroPad2d((0, 0, 1, 1))  # top bottom\n","        self.padding2 = nn.ZeroPad2d((0, 0, 0, 1))  # bottom\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(250*2, 50)  # 因为最终残差网络会留到 seq-length = 2\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # 使用 3 个 BERT 读取文本\n","        output_all_bert1 = self.l1_bert1(ids[:,0:400], attention_mask = mask[:,0:400], token_type_ids = token_type_ids[:,0:400])\n","        output_bert1 = output_all_bert1[0]  # output_all_bert1[1].unsqueeze(dim=1)\n","        output_all_bert2 = self.l1_bert2(ids[:,400*1:400*2], attention_mask = mask[:,400*1:400*2], token_type_ids = token_type_ids[:,400*1:400*2])\n","        output_bert2 = output_all_bert2[0]\n","        output_all_bert3 = self.l1_bert3(ids[:,400*2:400*3], attention_mask = mask[:,400*2:400*3], token_type_ids = token_type_ids[:,400*2:400*3])\n","        output_bert3 = output_all_bert3[0]\n","        # 拼接 3 个BERT的结果\n","        output_l1 = torch.cat([output_bert1,output_bert2,output_bert3],dim=1)  # output_bert3,output_bert4\n","      \n","        # 进入 DPCNN 卷积层        \n","        x = output_l1.unsqueeze(1)  # [batch_size, 1, seq_len, embed]\n","        x = self.conv_region(x)  # [batch_size, 250, seq_len-3+1, 1\n","\n","        x = self.padding1(x)  # [batch_size, 250, seq_len, 1]\n","        x = self.relu(x)\n","        x = self.conv(x)  # [batch_size, 250, seq_len-3+1, 1]\n","        x = self.padding1(x)  # [batch_size, 250, seq_len, 1]\n","        x = self.relu(x)\n","        x = self.conv(x)  # [batch_size, 250, seq_len-3+1, 1]\n","        while x.size()[2] > 2:\n","            x = self._block(x)\n","        x = x.view(x.size()[0],-1)  # [batch_size, num_filters(250)*2]\n","        x = self.fc(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","    def _block(self, x):\n","        x = self.padding2(x)\n","        px = self.max_pool(x)\n","        x = self.padding1(px)\n","        x = F.relu(x)\n","        x = self.conv(x)\n","        x = self.padding1(x)\n","        x = F.relu(x)\n","        x = self.conv(x)\n","        x = x + px  # short cut\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8594,"status":"ok","timestamp":1662449956416,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"X-vwjBhu9CkB","outputId":"76c39056-7579-438b-a652-f7d86ab50002"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["BERTClass(\n","  (l1_bert1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert2): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l1_bert3): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (conv_region): Conv2d(1, 250, kernel_size=(3, 768), stride=(1, 1))\n","  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n","  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (padding1): ZeroPad2d((0, 0, 1, 1))\n","  (padding2): ZeroPad2d((0, 0, 0, 1))\n","  (relu): ReLU()\n","  (fc): Linear(in_features=500, out_features=50, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model = BERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8Yq_xy1Dy72"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88FqwDC1Dy-2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fN9M90QA9C3Q"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"jpmeK9ApraNW"},"source":["# 优化器"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4vELlEM9C56"},"outputs":[],"source":["import math\n","import torch\n","from torch.optim import Optimizer\n","from torch.optim.optimizer import required\n","from torch.nn.utils import clip_grad_norm_\n","import logging\n","import abc\n","import sys\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","if sys.version_info >= (3, 4):\n","    ABC = abc.ABC\n","else:\n","    ABC = abc.ABCMeta('ABC', (), {})\n","\n","\n","class _LRSchedule(ABC):\n","    \"\"\" Parent of all LRSchedules here. \"\"\"\n","    warn_t_total = False        # is set to True for schedules where progressing beyond t_total steps doesn't make sense\n","    def __init__(self, warmup=0.002, t_total=-1, **kw):\n","        \"\"\"\n","        :param warmup:  what fraction of t_total steps will be used for linear warmup\n","        :param t_total: how many training steps (updates) are planned\n","        :param kw:\n","        \"\"\"\n","        super(_LRSchedule, self).__init__(**kw)\n","        if t_total < 0:\n","            logger.warning(\"t_total value of {} results in schedule not being applied\".format(t_total))\n","        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n","            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n","        warmup = max(warmup, 0.)\n","        self.warmup, self.t_total = float(warmup), float(t_total)\n","        self.warned_for_t_total_at_progress = -1\n","\n","    def get_lr(self, step, nowarn=False):\n","        \"\"\"\n","        :param step:    which of t_total steps we're on\n","        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n","        :return:        learning rate multiplier for current update\n","        \"\"\"\n","        if self.t_total < 0:\n","            return 1.\n","        progress = float(step) / self.t_total\n","        ret = self.get_lr_(progress)\n","        # warning for exceeding t_total (only active with warmup_linear\n","        if not nowarn and self.warn_t_total and progress > 1. and progress > self.warned_for_t_total_at_progress:\n","            logger.warning(\n","                \"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"\n","                    .format(ret, self.__class__.__name__))\n","            self.warned_for_t_total_at_progress = progress\n","        # end warning\n","        return ret\n","\n","    def get_lr_(self, progress):\n","        \"\"\"\n","        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n","        :return:            learning rate multiplier for current update\n","        \"\"\"\n","        return 1.\n","\n","\n","class ConstantLR(_LRSchedule):\n","    def get_lr_(self, progress):\n","        return 1.\n","\n","\n","class WarmupCosineSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Decreases learning rate from 1. to 0. over remaining `1 - warmup` steps following a cosine curve.\n","    If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n","    \"\"\"\n","    warn_t_total = True\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=.5, **kw):\n","        \"\"\"\n","        :param warmup:      see LRSchedule\n","        :param t_total:     see LRSchedule\n","        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n","        :param kw:\n","        \"\"\"\n","        super(WarmupCosineSchedule, self).__init__(warmup=warmup, t_total=t_total, **kw)\n","        self.cycles = cycles\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)   # progress after warmup\n","            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))\n","\n","\n","class WarmupCosineWithHardRestartsSchedule(WarmupCosineSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n","    learning rate (with hard restarts).\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        super(WarmupCosineWithHardRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","        assert(cycles >= 1.)\n","\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * ((self.cycles * progress) % 1)))\n","            return ret\n","\n","\n","class WarmupCosineWithWarmupRestartsSchedule(WarmupCosineWithHardRestartsSchedule):\n","    \"\"\"\n","    All training progress is divided in `cycles` (default=1.) parts of equal length.\n","    Every part follows a schedule with the first `warmup` fraction of the training steps linearly increasing from 0. to 1.,\n","    followed by a learning rate decreasing from 1. to 0. following a cosine curve.\n","    \"\"\"\n","    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n","        assert(warmup * cycles < 1.)\n","        warmup = warmup * cycles if warmup >= 0 else warmup\n","        super(WarmupCosineWithWarmupRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n","\n","    def get_lr_(self, progress):\n","        progress = progress * self.cycles % 1.\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        else:\n","            progress = (progress - self.warmup) / (1 - self.warmup)     # progress after warmup\n","            ret = 0.5 * (1. + math.cos(math.pi * progress))\n","            return ret\n","\n","\n","class WarmupConstantSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Keeps learning rate equal to 1. after warmup.\n","    \"\"\"\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return 1.\n","\n","\n","class WarmupLinearSchedule(_LRSchedule):\n","    \"\"\"\n","    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n","    Linearly decreases learning rate from 1. to 0. over remaining `1 - warmup` steps.\n","    \"\"\"\n","    warn_t_total = True\n","    def get_lr_(self, progress):\n","        if progress < self.warmup:\n","            return progress / self.warmup\n","        return max((progress - 1.) / (self.warmup - 1.), 0.)\n","\n","\n","SCHEDULES = {\n","    None:       ConstantLR,\n","    \"none\":     ConstantLR,\n","    \"warmup_cosine\": WarmupCosineSchedule,\n","    \"warmup_constant\": WarmupConstantSchedule,\n","    \"warmup_linear\": WarmupLinearSchedule\n","}\n","\n","\n","class BertAdam(Optimizer):\n","    \"\"\"Implements BERT version of Adam algorithm with weight decay fix.\n","    Params:\n","        lr: learning rate\n","        warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n","        t_total: total number of training steps for the learning\n","            rate schedule, -1  means constant learning rate of 1. (no warmup regardless of warmup setting). Default: -1\n","        schedule: schedule to use for the warmup (see above).\n","            Can be `'warmup_linear'`, `'warmup_constant'`, `'warmup_cosine'`, `'none'`, `None` or a `_LRSchedule` object (see below).\n","            If `None` or `'none'`, learning rate is always kept constant.\n","            Default : `'warmup_linear'`\n","        b1: Adams b1. Default: 0.9\n","        b2: Adams b2. Default: 0.999\n","        e: Adams epsilon. Default: 1e-6\n","        weight_decay: Weight decay. Default: 0.01\n","        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n","    \"\"\"\n","    def __init__(self, params, lr=required, warmup=-1, t_total=-1, schedule='warmup_linear',\n","                 b1=0.9, b2=0.999, e=1e-6, weight_decay=0.01, max_grad_norm=1.0, **kwargs):\n","        if lr is not required and lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n","        if not isinstance(schedule, _LRSchedule) and schedule not in SCHEDULES:\n","            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n","        if not 0.0 <= b1 < 1.0:\n","            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n","        if not 0.0 <= b2 < 1.0:\n","            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n","        if not e >= 0.0:\n","            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n","        # initialize schedule object\n","        if not isinstance(schedule, _LRSchedule):\n","            schedule_type = SCHEDULES[schedule]\n","            schedule = schedule_type(warmup=warmup, t_total=t_total)\n","        else:\n","            if warmup != -1 or t_total != -1:\n","                logger.warning(\"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"\n","                               \"Please specify custom warmup and t_total in _LRSchedule object.\")\n","        defaults = dict(lr=lr, schedule=schedule,\n","                        b1=b1, b2=b2, e=e, weight_decay=weight_decay,\n","                        max_grad_norm=max_grad_norm)\n","        super(BertAdam, self).__init__(params, defaults)\n","\n","    def get_lr(self):\n","        lr = []\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    return [0]\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","                lr.append(lr_scheduled)\n","        return lr\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['next_m'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['next_v'] = torch.zeros_like(p.data)\n","\n","                next_m, next_v = state['next_m'], state['next_v']\n","                beta1, beta2 = group['b1'], group['b2']\n","\n","                # Add grad clipping\n","                if group['max_grad_norm'] > 0:\n","                    clip_grad_norm_(p, group['max_grad_norm'])\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                next_m.mul_(beta1).add_(1 - beta1, grad)\n","                next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                update = next_m / (next_v.sqrt() + group['e'])\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want to decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                if group['weight_decay'] > 0.0:\n","                    update += group['weight_decay'] * p.data\n","\n","                lr_scheduled = group['lr']\n","                lr_scheduled *= group['schedule'].get_lr(state['step'])\n","\n","                update_with_lr = lr_scheduled * update\n","                p.data.add_(-update_with_lr)\n","\n","                state['step'] += 1\n","\n","                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n","                # No bias correction\n","                # bias_correction1 = 1 - beta1 ** state['step']\n","                # bias_correction2 = 1 - beta2 ** state['step']\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"qGrRbjOYrhag"},"source":["# Train "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSEYkJPu9C84"},"outputs":[],"source":["import sys\n","import numpy as np\n","sys.path.append(\"/content/drive/My Drive/MIMIC/caml-mimic\")  # 注意，这里改变了地址了\n","import evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1662449956426,"user":{"displayName":"CUI TENGFEI","userId":"12310385898916684610"},"user_tz":-480},"id":"EbMKn4Eh9C_u","outputId":"1bc1e11b-d947-4289-ed57-5f908e5197d4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\ndef get_f1_pre_re(y_target,y_output):\\n  # 计算 F1 ， precision , recall\\n  y_output = torch.tensor(y_output)\\n  ones = torch.ones_like(y_output)\\n  zeros = torch.zeros_like(y_output)\\n  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\\n  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\\n  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\\n  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\\n  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\\n  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\\n  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\\n  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\\n  print()\\n  print('The evluation from other code:')\\n  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\\n  print(evaluation.print_metrics(metrics))\\n  \\n  'acc_macro','prec_macro','rec_macro','f1_macro'\\n  'acc_micro','prec_micro','rec_micro','f1_micro',\\n  'rec_at_5','prec_at_5', 'f1_at_5' , \\n  'auc_macro','auc_micro'\\n  \\n  return metrics\\n\\n\\ndef epoch_perform(targets,outputs,name):\\n  performence = get_f1_pre_re(targets,outputs)\\n  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\\n  performence['auc'] = roc_auc\\n  performence['fpr'] = fpr\\n  performence['tpr'] = tpr\\n  print()\\n  print(name+' performence:')\\n  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\\n  print('precision(micro):',performence['precision micro'],\\n        '\\tprecison(macro):',performence['precision macro'],\\n        '\\trecall(micro):',performence['recall micro'],\\n        '\\trecall(macro):',performence['recall macro'],\\n        '\\tf_1 (micro):',performence['f1 micro'],\\n        '\\tf_1 (macro):',performence['f1 macro'])\\n  return performence\\n\""]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["def get_roc_auc(val_targets,val_outputs):\n","  # input : val_targets 标签 ； val_outputs 模型的输出 (需要np.array类型)\n","  # output: return_fpr (micro,macro) , return_tpr (micro,macro) (list)\n","  # output: return_roc_auc (micro,macro)  (float)\n","  # Compute ROC curve and ROC area for each class\n","  n_classes = len(val_targets[0]) # [num_example,num_class] \n","  fpr = {}\n","  tpr = {}\n","  roc_auc = {}\n","  for i in range(n_classes):\n","    fpr_, tpr_, _ = roc_curve(val_targets[:, i], val_outputs[:, i])\n","    fpr[i] = fpr_.tolist()\n","    tpr[i] = tpr_.tolist()\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","  # Compute micro-average ROC curve and ROC area\n","  fpr_, tpr_, _ = roc_curve(val_targets.ravel(), val_outputs.ravel())\n","  fpr['micro'] = fpr_.tolist()\n","  tpr['micro'] = tpr_.tolist()\n","  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","  # Compute macro-average ROC curve and ROC area\n","  # First aggregate all false positive rates\n","  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","  # Then interpolate all ROC curves at this points\n","  mean_tpr = np.zeros_like(all_fpr)\n","  for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","  # Finally average it and compute AUC\n","  mean_tpr /= n_classes\n","  fpr[\"macro\"] = all_fpr.tolist()\n","  tpr[\"macro\"] = mean_tpr.tolist()\n","  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","  # 返回时，我们只需要micro,macro的信息即可\n","  return_fpr = {'macro':fpr['macro'],'micro':fpr['micro']}\n","  return_tpr = {'macro':tpr['macro'],'micro':tpr['micro']}\n","  return_roc_auc = {'macro':roc_auc['macro'],'micro':roc_auc['micro']}\n","  return return_fpr,return_tpr,return_roc_auc\n","\n","def epoch_perform(y_target,y_output):\n","  # 计算 prediction , 以 0.5 作为阈值\n","  # 输出 mretics\n","  '''\n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro','auc',\n","  'tpr','fpr',\n","  'prec_micro_curve','rec_micro,curve','ave_prec_micro'\n","  '''\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  y_output = y_output.cpu().detach().numpy()\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction.numpy(), y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  # 计算 tpr ,fpr, 用于画出 ROC_AUCROC_AUC\n","  fpr,tpr,roc_auc = get_roc_auc(y_target,y_output)\n","  metrics['auc'] = roc_auc\n","  metrics['fpr'] = fpr\n","  metrics['tpr'] = tpr\n","  print(metrics['auc'])\n","  print()\n","  # 计算 precision,recall ,用于画出 precision-recall curve\n","  precision ={}\n","  recall = {}\n","  average_precision = {}\n","  metrics['prec_micro_curve'], metrics['rec_micro,curve'], _ = precision_recall_curve(y_target.ravel(), y_output.ravel())\n","  metrics['ave_prec_micro'] = average_precision_score(y_target, y_output, average=\"micro\")\n","  return metrics\n","\n","'''\n","def get_f1_pre_re(y_target,y_output):\n","  # 计算 F1 ， precision , recall\n","  y_output = torch.tensor(y_output)\n","  ones = torch.ones_like(y_output)\n","  zeros = torch.zeros_like(y_output)\n","  y_prediction = torch.where(y_output > 0.5 , ones , zeros)\n","  # 为了与其他的模型比较效果，我们放弃直接使用skearn的函数，转而使用其他的函数\n","  result['f1 micro'] = f1_score(y_target, y_prediction, average='micro')\n","  result['f1 macro'] = f1_score(y_target, y_prediction, average='macro')\n","  result['precision micro'] = precision_score(y_target, y_prediction, average='micro')\n","  result['precision macro'] = precision_score(y_target, y_prediction, average='macro')\n","  result['recall micro'] = recall_score(y_target, y_prediction, average='micro')\n","  result['recall macro'] = recall_score(y_target, y_prediction, average='macro')\n","  print()\n","  print('The evluation from other code:')\n","  metrics = evaluation.all_metrics(y_prediction, y_target, k=5, yhat_raw= y_output)\n","  print(evaluation.print_metrics(metrics))\n","  \n","  'acc_macro','prec_macro','rec_macro','f1_macro'\n","  'acc_micro','prec_micro','rec_micro','f1_micro',\n","  'rec_at_5','prec_at_5', 'f1_at_5' , \n","  'auc_macro','auc_micro'\n","  \n","  return metrics\n","\n","\n","def epoch_perform(targets,outputs,name):\n","  performence = get_f1_pre_re(targets,outputs)\n","  fpr,tpr,roc_auc = get_roc_auc(targets,outputs)\n","  performence['auc'] = roc_auc\n","  performence['fpr'] = fpr\n","  performence['tpr'] = tpr\n","  print()\n","  print(name+' performence:')\n","  print('auc(micro): ',roc_auc['micro'],'\\tauc(macro):',roc_auc['macro'])\n","  print('precision(micro):',performence['precision micro'],\n","        '\\tprecison(macro):',performence['precision macro'],\n","        '\\trecall(micro):',performence['recall micro'],\n","        '\\trecall(macro):',performence['recall macro'],\n","        '\\tf_1 (micro):',performence['f1 micro'],\n","        '\\tf_1 (macro):',performence['f1 macro'])\n","  return performence\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wBVInBB9DCM"},"outputs":[],"source":["def draw_pr_roc(test_performence,\n","                y_target,y_output,\n","                save_path,epoch,name,\n","                key):\n","  # fpr, tpr,roc_auc 三个字典，是 get_roc_auc的输出\n","  # y_target 标签 ； y_output 模型的输出\n","  # save_path 保存图片的地址 ； epoch,name 记录是哪一次的信息\n","  # 输出： 两张图表，roc曲线 和 precision_recall曲线\n","  # 画图，首先是左边，roc_auc 曲线\n","  fig, axs = plt.subplots(1, 2, figsize=(21, 10))\n","  axs[0].step(\n","      test_performence['fpr'][\"micro\"],\n","      test_performence['tpr'][\"micro\"],\n","      label=\"micro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  axs[0].step(\n","      test_performence['fpr'][\"macro\"],\n","      test_performence['tpr'][\"macro\"],\n","      label=\"macro-average ROC curve (area = {0:0.2f})\".format(test_performence['auc'][\"macro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,\n","    ) \n","  axs[0].plot([0, 1], [0, 1], \"k--\", lw=2)\n","  axs[0].set_xlim([0.0, 1.0])\n","  axs[0].set_ylim([0.0, 1.05])\n","  axs[0].set_xlabel(\"False Positive Rate\")\n","  axs[0].set_ylabel(\"True Positive Rate\")\n","  axs[0].set_title(\"Receiver Operating Characteristic to multiclass\")\n","\n","  # 然后是右边，precision_recall curve\n","  f_scores = np.linspace(0.2, 0.8, num=4)\n","  lines, labels = [], []\n","  for f_score in f_scores:\n","      x = np.linspace(0.01, 1)\n","      y = f_score * x / (2 * x - f_score)\n","      (l,) = axs[1].plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n","      axs[1].annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n","\n","  display = PrecisionRecallDisplay(\n","      recall=test_performence['rec_micro,curve'],\n","      precision=test_performence['prec_micro_curve'],\n","      average_precision = test_performence['prec_micro'],\n","  )\n","  display.plot(ax=axs[1], name=\"Micro-average precision-recall\", \n","               color=\"#f97306\",linewidth=2) \n","\n","  # add the legend for the iso-f1 curves\n","  handles, labels = display.ax_.get_legend_handles_labels()\n","  handles.extend([l])\n","  labels.extend([\"iso-f1 curves\"])\n","  # set the legend and the axes\n","  axs[1].set_xlim([0.0, 1.0])\n","  axs[1].set_ylim([0.0, 1.05])\n","  axs[1].legend(handles=handles, labels=labels, loc=\"best\")\n","  axs[1].set_title(\"Micro-averaged Prcision-Recall Line\")\n","\n","  for ax in axs:\n","    ax.legend(loc=\"lower right\")\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/epoch_'+str(epoch)+'_'+name+'.png')\n","\n","#draw_pr_roc(return_fpr,return_tpr,return_roc_auc,Y,y_score,\n","#            save_path='/content/drive/My Drive/MIMIC',epoch=1,name='val')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRqWHB6g9DE6"},"outputs":[],"source":["def draw_loss(result_loss,save_path,key):\n","  fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n","  # 可视化 train_loss_batch\n","  x = np.arange(0,len(result_loss['train_loss_batch']),1)\n","  y = np.array(result_loss['train_loss_batch'])\n","  axs[0][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][0].set_xlim([0.0, 1.0])\n","  #axs[0][0].set_ylim([0.0, 1.05])\n","  axs[0][0].set_xlabel(\"epoch\")\n","  axs[0][0].set_ylabel(\"Loss\")\n","  axs[0][0].set_title(\"Train Loss per Batchs\")\n","  \n","  # 可视化 train_loss_epoch\n","  x = np.arange(0,len(result_loss['train_loss_epoch']),1)\n","  y = np.array(result_loss['train_loss_epoch'])\n","  print(x)\n","  print(y)\n","  axs[0][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[0][1].set_xlim([0.0, 1.0])\n","  #axs[0][1].set_ylim([0.0, 1.05])\n","  axs[0][1].set_xlabel(\"epoch\")\n","  axs[0][1].set_ylabel(\"Loss\")\n","  axs[0][1].set_title(\"Train Loss per Epoch\")\n","  \n","  # 可视化 test_loss_epoch\n","  x = np.arange(0,len(result_loss['test_loss_epoch']),1)\n","  y = np.array(result_loss['test_loss_epoch'])\n","  axs[0][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][0].set_xlim([0.0, 1.0])\n","  #axs[1][0].set_ylim([0.0, 1.05])\n","  axs[0][2].set_xlabel(\"epoch\")\n","  axs[0][2].set_ylabel(\"Loss\")\n","  axs[0][2].set_title(\"Test Loss per Epoch\")\n","  \n","  # 可视化 F 1\n","  x = np.arange(0,len(result_loss['test_macro_f1']),1)\n","  y = np.array(result_loss['test_macro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_f1']),1)\n","  y = np.array(result_loss['test_micro_f1'])\n","  axs[1][0].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"F1(micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][0].set_xlabel(\"epoch\")\n","  axs[1][0].set_ylabel(\"F 1 score\")\n","  axs[1][0].set_title(\"F 1 score per Epoch\")\n","  axs[1][0].legend()\n","\n","  # 可视化 AUC 得分\n","  x = np.arange(0,len(result_loss['test_macro_auc']),1)\n","  y = np.array(result_loss['test_macro_auc'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"auc (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_auc']),1)\n","  y = np.array(result_loss['test_micro_auc'])\n","  axs[1][1].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      label = \"auc (micro)\",\n","      #linestyle=\":\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][1].set_xlabel(\"epoch\")\n","  axs[1][1].set_ylabel(\"AUC Score\")\n","  axs[1][1].set_title(\"AUC score per Epoch\")\n","  axs[1][1].legend()\n","  # 可视化 Precision\n","  x = np.arange(0,len(result_loss['test_macro_precision']),1)\n","  y = np.array(result_loss['test_macro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#f97306', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (macro)\",\n","      linewidth=2,)\n","  x = np.arange(0,len(result_loss['test_micro_precision']),1)\n","  y = np.array(result_loss['test_micro_precision'])\n","  axs[1][2].plot( x, y,\n","      #label=\"micro-average ROC curve (area = {0:0.2f})\".format(return_roc_auc[\"micro\"]),\n","      color='#9a0eea', # \"deeppink\" 红，\"#01ff07\"绿,'#9a0eea'紫 ,'#f97306'橙\n","      #linestyle=\":\",\n","      label = \"Precision (micro)\",\n","      linewidth=2,)\n","  #axs[1][1].set_xlim([0.0, 1.0])\n","  #axs[1][1].set_ylim([0.0, 1.05])\n","  axs[1][2].set_xlabel(\"epoch\")\n","  axs[1][2].set_ylabel(\"Precision score\")\n","  axs[1][2].set_title(\"Precision score per Epoch\")\n","  axs[1][2].legend()\n","  plt.show()\n","  if key == 1:\n","    fig.savefig(fname =save_path+'/loss_epoch_'+str(epoch)+'.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwpOu4uu9DIH"},"outputs":[],"source":["# 设置参数\n","checkpoint_path = '/content/drive/My Drive/MIMIC/BERT_FineTune/bert_base_heir/BERT3d+DPCNN+freeze'\n","model_name = 'bert-base-heir'\n","\n","LEARNING_RATE = 1e-05\n","\n","start_epochs = 1\n","n_epochs = 100\n","\n","# 损失函数\n","def loss_fn(outputs, targets):\n","    #return torch.nn.functional.cross_entropy(outputs, targets)\n","    return torch.nn.functional.binary_cross_entropy(outputs,targets)\n","\n","# 优化器，使用 warm up ,  AdmaW\n","# optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","# optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n","\n","#optimizer = BertAdam(optimizer_grouped_parameters,\n","#                      lr=LEARNING_RATE,\n","#                      warmup=0.05,\n","#                      t_total=len(train_iter) * n_epochs)\n","#sigmoid = torch.nn.Sigmoid()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1urXDSjukxrpuRJpyg-aQhI7vGSfS1sq_"},"id":"nWjkms1p9DKy","outputId":"31f2905d-811c-4435-bfc5-e511ef7fbc28"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 正式开始训练\n","result_loss = {'train_loss_batch':[],'train_loss_epoch':[],'test_loss_epoch':[],\n","               'test_macro_f1':[],'test_macro_recall':[],'test_macro_precision':[],\n","               'test_micro_f1':[],'test_micro_recall':[],'test_micro_precision':[],\n","               'test_macro_auc':[],'test_micro_auc':[]}\n","\n","auc_macro_max  = 0  # 初始化最小的验证损失函数\n","for epoch in range(start_epochs, n_epochs+1):\n","  key = 0  # 用于提示合适保存图片\n","  test_targets = []\n","  test_outputs = []\n","  train_loss = 0\n","  test_loss = 0\n","\n","  ######################    \n","   # Train the model #\n","  ######################\n","  process_num = 0  \n","  model.train()\n","  print('###############   Epoch {}: Training Start   #############'.format(epoch))\n","  for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)  \n","\n","    optimizer.zero_grad()\n","    loss = loss_fn(outputs, targets)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","    # 记录信息\n","    process_num += batch_size\n","    if process_num % (500) == 0:  ############## 这里可以调\n","      print('already deal with '+ str(process_num)+' data','\\tloss:',loss.item())\n","      result_loss['train_loss_batch'].append(loss.item())\n","  train_loss = train_loss/len(train_iter)  # 计算平均训练损失\n","  result_loss['train_loss_epoch'].append(train_loss) # 放到记录字典里\n","  print('Epoch {}: Training End'.format(epoch))\n","\n","  ######################    \n","  # validate the model #\n","  ######################\n","  model.eval()\n","  with torch.no_grad():\n","    # 在 测试集上跑一遍\n","    for batch_idx, data in enumerate(test_iter, 0):\n","      ids = data['ids'].to(device, dtype = torch.long)\n","      mask = data['mask'].to(device, dtype = torch.long)\n","      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","      targets = data['targets'].to(device, dtype = torch.float)\n","\n","      outputs = model(ids, mask, token_type_ids)\n","\n","      loss = loss_fn(outputs, targets)\n","      test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.item() - test_loss))\n","      test_targets.extend(targets.cpu().detach().numpy())\n","      test_outputs.extend(outputs.cpu().detach().numpy())\n","    test_loss = test_loss / len(test_iter)\n","    result_loss['test_loss_epoch'].append(test_loss)\n","    print('Epoch {}: Validation End'.format(epoch))\n","    # 打印一下 三个损失函数 \n","    print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Test Loss: {:.6f}'.format(epoch, train_loss,test_loss))\n","\n","  #####################################\n","  ######### 记录结果, 保存模型  #########\n","  #####################################\n","  test_performence = epoch_perform(np.array(test_targets),np.array(test_outputs)) # 得到模型在test集合上的表现\n","  result_loss['test_macro_f1'].append(test_performence['f1_macro'])\n","  result_loss['test_micro_f1'].append(test_performence['f1_micro'])\n","  result_loss['test_macro_recall'].append(test_performence['rec_macro'])\n","  result_loss['test_micro_recall'].append(test_performence['rec_micro'])\n","  result_loss['test_macro_precision'].append(test_performence['prec_macro'])\n","  result_loss['test_micro_precision'].append(test_performence['prec_micro'])\n","  result_loss['test_macro_auc'].append(test_performence['auc_macro'])\n","  result_loss['test_micro_auc'].append(test_performence['auc_micro'])\n","\n","  # 下面要保存模型\n","  checkpoint = {\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'test_outputs':np.array(test_outputs),\n","            'test_targets':np.array(test_targets),\n","            'loss':result_loss,\n","            'test_performence':test_performence}\n","\n","  if result_loss['test_macro_auc'][-1] > auc_macro_max:\n","    auc_macro_max = result_loss['test_macro_auc'][-1]\n","    if epoch > 3 :  # 这里是真的要保存了  # 记着设置保存条件\n","      # 保存模型\n","      save_ckp(checkpoint, checkpoint_path+'/checkpoint_epoch_'+ str(epoch) + '.pt' )\n","    # 保存test , loss 字典\n","    #test_json = json.dumps(test_performence,sort_keys=False, indent=4, separators=(',', ': '))\n","    #loss_json = json.dumps(result_loss,sort_keys=False, indent=4, separators=(',', ': '))\n","    #f = open(checkpoint_path + '/test_performence_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(test_json)\n","    #f = open(checkpoint_path + '/loss_epoch_'+ str(epoch) +'.json', 'w')\n","    #f.write(loss_json)\n","\n","  #####################################\n","  ######### 可视化，打印  #########\n","  #####################################\n","  print('Visulization:')\n","  print(\"Loss :\")\n","  print(result_loss)\n","  draw_loss(result_loss,checkpoint_path,key)\n","  print('test: ')\n","  draw_pr_roc(test_performence,\n","              np.array(test_targets),np.array(test_outputs),   # np 优化\n","              checkpoint_path,epoch,'test',\n","              key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2-8uOvY9DQL"},"outputs":[],"source":["'''\n","first_outputs = 0\n","for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    outputs = model(ids, mask, token_type_ids)  \n","'''    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sR1Zpe6p9DTM"},"outputs":[],"source":["#my_bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n","#my_bert.to(device)\n","#first_outputs = 0\n","for batch_idx, data in enumerate(train_iter):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","\n","    first_outputs = model(ids, mask, token_type_ids)  \n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WSWnn0oW9DV6"},"outputs":[],"source":["first_outputs[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n39waBTI9DYu"},"outputs":[],"source":["first_outputs[1].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZ1OBzdD9Dbs"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8jD7xU16SLEQ"},"source":["# Evluation "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c3TUCZRSKgv"},"outputs":[],"source":["import torch\n","checkpoint_fpath = \"/content/drive/My Drive/MIMIC/BERT_FineTune/clinical_bert_heir/3BERT _2Transformer_lr2e-5/checkpoint_epoch_6.pt\"\n","#load_ckp(checkpoint_fpath, model, optimizer)\n","# load check point\n","checkpoint = torch.load(checkpoint_fpath,map_location=torch.device('cpu'))\n","# initialize state_dict from checkpoint to model\n","#model.load_state_dict(checkpoint['state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0SUK-tGSKjd"},"outputs":[],"source":["checkpoint['loss']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3V1ixubvSKlu"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Kb5Z_yJFPmtR"},"source":["# Result + Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZBPXjs89Dd-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6PwkKnM9Dhm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nzbyTLRt9DkM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQ_LGSVg9DnT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["xq3six4ghPEB","jpmeK9ApraNW"],"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNdHGEj0FkZ1WOTH2VEJXxO"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}